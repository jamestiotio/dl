{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866b19f8",
   "metadata": {},
   "source": [
    "# 6. Wasserstein GAN on MNIST with FC layers\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.1 (05/04/2022)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.9.6)\n",
    "- Matplotlib (tested on v3.5.1)\n",
    "- Numpy (tested on v1.22.1)\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d28b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "import torch.autograd as autograd\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2569c778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b1473",
   "metadata": {},
   "source": [
    "### Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c9680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transform to be applied to dataset\n",
    "# - Tensor conversion\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95021a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST train dataset\n",
    "mnist = torchvision.datasets.MNIST(root = './data/',\n",
    "                                   train = True,\n",
    "                                   transform = transform,\n",
    "                                   download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0c4823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a457b",
   "metadata": {},
   "source": [
    "### Critic model as a set of FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2ef6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class Dicriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, image_size):\n",
    "        # Init from nn.Module\n",
    "        super().__init__()\n",
    "        \n",
    "        # FC layers\n",
    "        self.D = nn.Sequential(nn.Linear(image_size, hidden_size),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "                               nn.Linear(hidden_size, 1),\n",
    "                               nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.D(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7da5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic\n",
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, image_size):\n",
    "        # Init from nn.Module\n",
    "        super().__init__()\n",
    "        \n",
    "        # FC layers\n",
    "        self.D = nn.Sequential(nn.Linear(image_size, hidden_size),\n",
    "                               nn.LeakyReLU(0.2),\n",
    "                               nn.Linear(hidden_size, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.D(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a2b44a",
   "metadata": {},
   "source": [
    "### Generator model as a set of FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04431258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_size, hidden_size, image_size):\n",
    "        # Init from nn.Module\n",
    "        super().__init__()\n",
    "        \n",
    "        # FC layers\n",
    "        self.G = nn.Sequential(nn.Linear(latent_size, hidden_size),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Linear(hidden_size, image_size),\n",
    "                               nn.Tanh())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.G(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c447cc",
   "metadata": {},
   "source": [
    "### Trainer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172b145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for model generation and training\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 300\n",
    "batch_size = 32\n",
    "lambda_val = 0 #0.01\n",
    "n_critic = 5\n",
    "n_generator = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d2ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (D): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create discriminator model\n",
    "f = Critic(hidden_size, image_size)\n",
    "f.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86d5852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (G): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=784, bias=True)\n",
       "    (3): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create generator model\n",
    "G = Generator(latent_size, hidden_size, image_size)\n",
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9af55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Losses and optimizers\n",
    "d_optimizer = torch.optim.Adam(f.parameters(), lr = 0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99f82aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History trackers for training curves\n",
    "# Keeping track of losses\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077c494",
   "metadata": {},
   "source": [
    "**Note: running the cell below (our trainer function) will take a long time!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "069467d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/300], Step [200/1875], d_loss: 0.2480, g_loss: -0.5578\n",
      "Epoch [0/300], Step [400/1875], d_loss: -0.3291, g_loss: 0.2361\n",
      "Epoch [0/300], Step [600/1875], d_loss: 0.0516, g_loss: 0.3762\n",
      "Epoch [0/300], Step [800/1875], d_loss: -0.0299, g_loss: 0.1022\n",
      "Epoch [0/300], Step [1000/1875], d_loss: -0.1928, g_loss: -0.1463\n",
      "Epoch [0/300], Step [1200/1875], d_loss: -0.5706, g_loss: 0.4576\n",
      "Epoch [0/300], Step [1400/1875], d_loss: -0.0829, g_loss: 0.1535\n",
      "Epoch [0/300], Step [1600/1875], d_loss: -0.0340, g_loss: -0.0305\n",
      "Epoch [0/300], Step [1800/1875], d_loss: 0.0039, g_loss: -0.0556\n",
      "Epoch [1/300], Step [200/1875], d_loss: 0.0132, g_loss: 0.0157\n",
      "Epoch [1/300], Step [400/1875], d_loss: 0.1563, g_loss: -0.6379\n",
      "Epoch [1/300], Step [600/1875], d_loss: -0.2212, g_loss: -0.3267\n",
      "Epoch [1/300], Step [800/1875], d_loss: -0.4175, g_loss: -0.2164\n",
      "Epoch [1/300], Step [1000/1875], d_loss: 0.2079, g_loss: 0.8056\n",
      "Epoch [1/300], Step [1200/1875], d_loss: -0.0496, g_loss: -0.0304\n",
      "Epoch [1/300], Step [1400/1875], d_loss: -0.0033, g_loss: 0.2878\n",
      "Epoch [1/300], Step [1600/1875], d_loss: -0.2439, g_loss: 0.0825\n",
      "Epoch [1/300], Step [1800/1875], d_loss: -0.0203, g_loss: -0.6658\n",
      "Epoch [2/300], Step [200/1875], d_loss: -0.2259, g_loss: -0.0611\n",
      "Epoch [2/300], Step [400/1875], d_loss: -0.0328, g_loss: -0.0016\n",
      "Epoch [2/300], Step [600/1875], d_loss: -0.3729, g_loss: -0.0255\n",
      "Epoch [2/300], Step [800/1875], d_loss: -0.0201, g_loss: 0.3945\n",
      "Epoch [2/300], Step [1000/1875], d_loss: -0.1229, g_loss: 0.1922\n",
      "Epoch [2/300], Step [1200/1875], d_loss: -0.2607, g_loss: 0.4199\n",
      "Epoch [2/300], Step [1400/1875], d_loss: 0.2585, g_loss: -0.4534\n",
      "Epoch [2/300], Step [1600/1875], d_loss: -0.5420, g_loss: -1.1884\n",
      "Epoch [2/300], Step [1800/1875], d_loss: -0.2349, g_loss: -0.2234\n",
      "Epoch [3/300], Step [200/1875], d_loss: -0.5329, g_loss: -0.5185\n",
      "Epoch [3/300], Step [400/1875], d_loss: 0.8667, g_loss: 1.7389\n",
      "Epoch [3/300], Step [600/1875], d_loss: 0.5735, g_loss: -1.0704\n",
      "Epoch [3/300], Step [800/1875], d_loss: -0.0320, g_loss: -0.0234\n",
      "Epoch [3/300], Step [1000/1875], d_loss: -0.0276, g_loss: -0.0634\n",
      "Epoch [3/300], Step [1200/1875], d_loss: -0.1359, g_loss: 0.6810\n",
      "Epoch [3/300], Step [1400/1875], d_loss: -0.0785, g_loss: 0.0837\n",
      "Epoch [3/300], Step [1600/1875], d_loss: -0.1037, g_loss: 0.0929\n",
      "Epoch [3/300], Step [1800/1875], d_loss: -0.0287, g_loss: -0.1033\n",
      "Epoch [4/300], Step [200/1875], d_loss: -0.0480, g_loss: 0.1027\n",
      "Epoch [4/300], Step [400/1875], d_loss: -0.0335, g_loss: -0.0426\n",
      "Epoch [4/300], Step [600/1875], d_loss: -0.0651, g_loss: 0.1052\n",
      "Epoch [4/300], Step [800/1875], d_loss: -0.0479, g_loss: -0.0151\n",
      "Epoch [4/300], Step [1000/1875], d_loss: -0.0151, g_loss: 0.0667\n",
      "Epoch [4/300], Step [1200/1875], d_loss: -0.0493, g_loss: 0.0302\n",
      "Epoch [4/300], Step [1400/1875], d_loss: -0.0811, g_loss: 0.0168\n",
      "Epoch [4/300], Step [1600/1875], d_loss: -0.0261, g_loss: 0.0996\n",
      "Epoch [4/300], Step [1800/1875], d_loss: -0.0295, g_loss: -0.0188\n",
      "Epoch [5/300], Step [200/1875], d_loss: -0.0473, g_loss: 0.1888\n",
      "Epoch [5/300], Step [400/1875], d_loss: 0.0453, g_loss: -0.2202\n",
      "Epoch [5/300], Step [600/1875], d_loss: -0.0523, g_loss: -0.0408\n",
      "Epoch [5/300], Step [800/1875], d_loss: 0.0328, g_loss: 0.3506\n",
      "Epoch [5/300], Step [1000/1875], d_loss: -0.1178, g_loss: 0.3188\n",
      "Epoch [5/300], Step [1200/1875], d_loss: 0.0021, g_loss: -0.1534\n",
      "Epoch [5/300], Step [1400/1875], d_loss: -0.0735, g_loss: -0.0615\n",
      "Epoch [5/300], Step [1600/1875], d_loss: -0.1375, g_loss: 0.1653\n",
      "Epoch [5/300], Step [1800/1875], d_loss: -0.1091, g_loss: 0.2547\n",
      "Epoch [6/300], Step [200/1875], d_loss: -0.0780, g_loss: 0.0479\n",
      "Epoch [6/300], Step [400/1875], d_loss: -0.0630, g_loss: -0.1053\n",
      "Epoch [6/300], Step [600/1875], d_loss: -0.0151, g_loss: 0.0541\n",
      "Epoch [6/300], Step [800/1875], d_loss: -0.0268, g_loss: 0.0533\n",
      "Epoch [6/300], Step [1000/1875], d_loss: -0.0285, g_loss: -0.0445\n",
      "Epoch [6/300], Step [1200/1875], d_loss: -0.0189, g_loss: -0.0333\n",
      "Epoch [6/300], Step [1400/1875], d_loss: 0.0477, g_loss: 0.2407\n",
      "Epoch [6/300], Step [1600/1875], d_loss: -0.1055, g_loss: 0.2424\n",
      "Epoch [6/300], Step [1800/1875], d_loss: -0.1479, g_loss: -0.0503\n",
      "Epoch [7/300], Step [200/1875], d_loss: -0.1799, g_loss: -0.2101\n",
      "Epoch [7/300], Step [400/1875], d_loss: -0.1930, g_loss: 0.1750\n",
      "Epoch [7/300], Step [600/1875], d_loss: -0.0542, g_loss: 0.1334\n",
      "Epoch [7/300], Step [800/1875], d_loss: -0.1024, g_loss: -0.0119\n",
      "Epoch [7/300], Step [1000/1875], d_loss: -0.0008, g_loss: 0.0628\n",
      "Epoch [7/300], Step [1200/1875], d_loss: -0.1021, g_loss: -0.0798\n",
      "Epoch [7/300], Step [1400/1875], d_loss: -0.0926, g_loss: -0.0063\n",
      "Epoch [7/300], Step [1600/1875], d_loss: -0.0191, g_loss: -0.0547\n",
      "Epoch [7/300], Step [1800/1875], d_loss: -0.0546, g_loss: -0.0381\n",
      "Epoch [8/300], Step [200/1875], d_loss: -0.1108, g_loss: -0.0491\n",
      "Epoch [8/300], Step [400/1875], d_loss: -0.0702, g_loss: 0.0026\n",
      "Epoch [8/300], Step [600/1875], d_loss: 0.0684, g_loss: 0.0072\n",
      "Epoch [8/300], Step [800/1875], d_loss: -0.0995, g_loss: 0.1109\n",
      "Epoch [8/300], Step [1000/1875], d_loss: 0.0342, g_loss: -0.1589\n",
      "Epoch [8/300], Step [1200/1875], d_loss: 0.2096, g_loss: -0.7115\n",
      "Epoch [8/300], Step [1400/1875], d_loss: 0.0058, g_loss: -1.3531\n",
      "Epoch [8/300], Step [1600/1875], d_loss: 0.3272, g_loss: -1.5707\n",
      "Epoch [8/300], Step [1800/1875], d_loss: -0.1056, g_loss: -0.1829\n",
      "Epoch [9/300], Step [200/1875], d_loss: -0.1093, g_loss: -0.7190\n",
      "Epoch [9/300], Step [400/1875], d_loss: 0.2484, g_loss: 0.1862\n",
      "Epoch [9/300], Step [600/1875], d_loss: -0.1473, g_loss: 0.8189\n",
      "Epoch [9/300], Step [800/1875], d_loss: 0.2844, g_loss: -1.6184\n",
      "Epoch [9/300], Step [1000/1875], d_loss: -0.7184, g_loss: -0.6139\n",
      "Epoch [9/300], Step [1200/1875], d_loss: 0.2054, g_loss: 0.5608\n",
      "Epoch [9/300], Step [1400/1875], d_loss: -0.3655, g_loss: 1.5026\n",
      "Epoch [9/300], Step [1600/1875], d_loss: 0.1671, g_loss: -2.0401\n",
      "Epoch [9/300], Step [1800/1875], d_loss: -0.0597, g_loss: -0.0071\n",
      "Epoch [10/300], Step [200/1875], d_loss: -0.1704, g_loss: 0.9703\n",
      "Epoch [10/300], Step [400/1875], d_loss: -0.0095, g_loss: -0.7446\n",
      "Epoch [10/300], Step [600/1875], d_loss: 0.0104, g_loss: 0.6521\n",
      "Epoch [10/300], Step [800/1875], d_loss: -0.0311, g_loss: -0.0672\n",
      "Epoch [10/300], Step [1000/1875], d_loss: -0.0185, g_loss: -0.1121\n",
      "Epoch [10/300], Step [1200/1875], d_loss: -0.0341, g_loss: 0.1234\n",
      "Epoch [10/300], Step [1400/1875], d_loss: -0.0357, g_loss: -0.1067\n",
      "Epoch [10/300], Step [1600/1875], d_loss: -0.0350, g_loss: 0.0948\n",
      "Epoch [10/300], Step [1800/1875], d_loss: -0.0909, g_loss: 0.0030\n",
      "Epoch [11/300], Step [200/1875], d_loss: 0.0254, g_loss: 0.0660\n",
      "Epoch [11/300], Step [400/1875], d_loss: -0.0567, g_loss: -0.0907\n",
      "Epoch [11/300], Step [600/1875], d_loss: -0.0214, g_loss: 0.0416\n",
      "Epoch [11/300], Step [800/1875], d_loss: -0.0835, g_loss: -0.1778\n",
      "Epoch [11/300], Step [1000/1875], d_loss: -0.0511, g_loss: 0.1922\n",
      "Epoch [11/300], Step [1200/1875], d_loss: 0.0469, g_loss: -0.0777\n",
      "Epoch [11/300], Step [1400/1875], d_loss: -0.1421, g_loss: -0.2890\n",
      "Epoch [11/300], Step [1600/1875], d_loss: -0.2355, g_loss: -0.3905\n",
      "Epoch [11/300], Step [1800/1875], d_loss: -0.1673, g_loss: -0.1264\n",
      "Epoch [12/300], Step [200/1875], d_loss: -0.4596, g_loss: -0.6083\n",
      "Epoch [12/300], Step [400/1875], d_loss: 0.0742, g_loss: 0.0215\n",
      "Epoch [12/300], Step [600/1875], d_loss: -0.5820, g_loss: 1.9955\n",
      "Epoch [12/300], Step [800/1875], d_loss: 0.2315, g_loss: -0.9536\n",
      "Epoch [12/300], Step [1000/1875], d_loss: -0.1848, g_loss: -0.2057\n",
      "Epoch [12/300], Step [1200/1875], d_loss: -0.5085, g_loss: 2.5668\n",
      "Epoch [12/300], Step [1400/1875], d_loss: -0.2834, g_loss: -1.5091\n",
      "Epoch [12/300], Step [1600/1875], d_loss: -0.1366, g_loss: 0.4820\n",
      "Epoch [12/300], Step [1800/1875], d_loss: -0.0306, g_loss: -0.2177\n",
      "Epoch [13/300], Step [200/1875], d_loss: -0.1306, g_loss: 0.1647\n",
      "Epoch [13/300], Step [400/1875], d_loss: -0.0351, g_loss: -0.1237\n",
      "Epoch [13/300], Step [600/1875], d_loss: -0.0378, g_loss: 0.0069\n",
      "Epoch [13/300], Step [800/1875], d_loss: -0.0543, g_loss: 0.0772\n",
      "Epoch [13/300], Step [1000/1875], d_loss: -0.0254, g_loss: -0.0300\n",
      "Epoch [13/300], Step [1200/1875], d_loss: -0.0910, g_loss: 0.1004\n",
      "Epoch [13/300], Step [1400/1875], d_loss: -0.0156, g_loss: -0.0132\n",
      "Epoch [13/300], Step [1600/1875], d_loss: -0.0307, g_loss: -0.0334\n",
      "Epoch [13/300], Step [1800/1875], d_loss: -0.0615, g_loss: 0.0492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/300], Step [200/1875], d_loss: -0.0376, g_loss: 0.0013\n",
      "Epoch [14/300], Step [400/1875], d_loss: -0.0364, g_loss: 0.0973\n",
      "Epoch [14/300], Step [600/1875], d_loss: -0.0266, g_loss: -0.1739\n",
      "Epoch [14/300], Step [800/1875], d_loss: 0.0450, g_loss: -0.0377\n",
      "Epoch [14/300], Step [1000/1875], d_loss: -0.0114, g_loss: 0.1143\n",
      "Epoch [14/300], Step [1200/1875], d_loss: -0.0513, g_loss: -0.1968\n",
      "Epoch [14/300], Step [1400/1875], d_loss: -0.0204, g_loss: 0.0850\n",
      "Epoch [14/300], Step [1600/1875], d_loss: -0.1855, g_loss: 0.2613\n",
      "Epoch [14/300], Step [1800/1875], d_loss: -0.0861, g_loss: -0.1845\n",
      "Epoch [15/300], Step [200/1875], d_loss: -0.0911, g_loss: 0.0485\n",
      "Epoch [15/300], Step [400/1875], d_loss: -0.0031, g_loss: 0.0236\n",
      "Epoch [15/300], Step [600/1875], d_loss: -0.0279, g_loss: 0.0110\n",
      "Epoch [15/300], Step [800/1875], d_loss: -0.0610, g_loss: -0.0237\n",
      "Epoch [15/300], Step [1000/1875], d_loss: -0.0557, g_loss: -0.0054\n",
      "Epoch [15/300], Step [1200/1875], d_loss: -0.0713, g_loss: -0.0181\n",
      "Epoch [15/300], Step [1400/1875], d_loss: 0.1156, g_loss: -0.3953\n",
      "Epoch [15/300], Step [1600/1875], d_loss: -0.1401, g_loss: -0.1883\n",
      "Epoch [15/300], Step [1800/1875], d_loss: -0.0003, g_loss: 0.0548\n",
      "Epoch [16/300], Step [200/1875], d_loss: -0.3400, g_loss: -0.7726\n",
      "Epoch [16/300], Step [400/1875], d_loss: -0.2865, g_loss: -0.3925\n",
      "Epoch [16/300], Step [600/1875], d_loss: 0.3948, g_loss: 0.6223\n",
      "Epoch [16/300], Step [800/1875], d_loss: -0.3007, g_loss: 1.7755\n",
      "Epoch [16/300], Step [1000/1875], d_loss: 0.0815, g_loss: -2.0963\n",
      "Epoch [16/300], Step [1200/1875], d_loss: -0.0640, g_loss: -0.0611\n",
      "Epoch [16/300], Step [1400/1875], d_loss: -0.1060, g_loss: 0.7641\n",
      "Epoch [16/300], Step [1600/1875], d_loss: -0.2710, g_loss: -0.6347\n",
      "Epoch [16/300], Step [1800/1875], d_loss: -0.2044, g_loss: 0.7137\n",
      "Epoch [17/300], Step [200/1875], d_loss: -0.0543, g_loss: -0.1699\n",
      "Epoch [17/300], Step [400/1875], d_loss: -0.0113, g_loss: -0.0818\n",
      "Epoch [17/300], Step [600/1875], d_loss: -0.0106, g_loss: 0.0232\n",
      "Epoch [17/300], Step [800/1875], d_loss: -0.0745, g_loss: 0.0419\n",
      "Epoch [17/300], Step [1000/1875], d_loss: -0.1059, g_loss: 0.1711\n",
      "Epoch [17/300], Step [1200/1875], d_loss: -0.0703, g_loss: -0.0928\n",
      "Epoch [17/300], Step [1400/1875], d_loss: -0.1232, g_loss: 0.0953\n",
      "Epoch [17/300], Step [1600/1875], d_loss: -0.2073, g_loss: 0.0301\n",
      "Epoch [17/300], Step [1800/1875], d_loss: -0.0696, g_loss: -0.1081\n",
      "Epoch [18/300], Step [200/1875], d_loss: -0.1226, g_loss: 0.1234\n",
      "Epoch [18/300], Step [400/1875], d_loss: 0.0459, g_loss: -0.1397\n",
      "Epoch [18/300], Step [600/1875], d_loss: -0.1793, g_loss: 0.2019\n",
      "Epoch [18/300], Step [800/1875], d_loss: 0.0033, g_loss: -0.0507\n",
      "Epoch [18/300], Step [1000/1875], d_loss: -0.0314, g_loss: -0.0623\n",
      "Epoch [18/300], Step [1200/1875], d_loss: -0.0218, g_loss: 0.0205\n",
      "Epoch [18/300], Step [1400/1875], d_loss: -0.0587, g_loss: 0.0142\n",
      "Epoch [18/300], Step [1600/1875], d_loss: -0.0752, g_loss: -0.0155\n",
      "Epoch [18/300], Step [1800/1875], d_loss: -0.0136, g_loss: 0.0231\n",
      "Epoch [19/300], Step [200/1875], d_loss: -0.1073, g_loss: 0.1170\n",
      "Epoch [19/300], Step [400/1875], d_loss: 0.0326, g_loss: 0.1007\n",
      "Epoch [19/300], Step [600/1875], d_loss: -0.0721, g_loss: -0.2155\n",
      "Epoch [19/300], Step [800/1875], d_loss: -0.0169, g_loss: -0.0253\n",
      "Epoch [19/300], Step [1000/1875], d_loss: -0.0048, g_loss: 0.0864\n",
      "Epoch [19/300], Step [1200/1875], d_loss: -0.0467, g_loss: -0.0613\n",
      "Epoch [19/300], Step [1400/1875], d_loss: -0.0709, g_loss: -0.2849\n",
      "Epoch [19/300], Step [1600/1875], d_loss: -0.1414, g_loss: -0.2744\n",
      "Epoch [19/300], Step [1800/1875], d_loss: -0.2342, g_loss: -0.3562\n",
      "Epoch [20/300], Step [200/1875], d_loss: -0.0913, g_loss: -1.3741\n",
      "Epoch [20/300], Step [400/1875], d_loss: -0.3128, g_loss: -0.4656\n",
      "Epoch [20/300], Step [600/1875], d_loss: 0.0204, g_loss: 1.1771\n",
      "Epoch [20/300], Step [800/1875], d_loss: -0.0518, g_loss: 0.3460\n",
      "Epoch [20/300], Step [1000/1875], d_loss: -0.4618, g_loss: -0.8725\n",
      "Epoch [20/300], Step [1200/1875], d_loss: -0.1401, g_loss: 1.2307\n",
      "Epoch [20/300], Step [1400/1875], d_loss: 0.2850, g_loss: -1.8244\n",
      "Epoch [20/300], Step [1600/1875], d_loss: -0.1183, g_loss: -0.0679\n",
      "Epoch [20/300], Step [1800/1875], d_loss: -0.0491, g_loss: 0.1774\n",
      "Epoch [21/300], Step [200/1875], d_loss: 0.1575, g_loss: -1.1907\n",
      "Epoch [21/300], Step [400/1875], d_loss: 0.2239, g_loss: 0.3163\n",
      "Epoch [21/300], Step [600/1875], d_loss: -0.1318, g_loss: 0.2750\n",
      "Epoch [21/300], Step [800/1875], d_loss: -0.2327, g_loss: -0.3346\n",
      "Epoch [21/300], Step [1000/1875], d_loss: -0.1795, g_loss: 0.5325\n",
      "Epoch [21/300], Step [1200/1875], d_loss: -0.1798, g_loss: -0.2182\n",
      "Epoch [21/300], Step [1400/1875], d_loss: 0.0248, g_loss: 0.1800\n",
      "Epoch [21/300], Step [1600/1875], d_loss: 0.0972, g_loss: -0.3069\n",
      "Epoch [21/300], Step [1800/1875], d_loss: -0.2177, g_loss: 0.2918\n",
      "Epoch [22/300], Step [200/1875], d_loss: -0.1446, g_loss: 0.5297\n",
      "Epoch [22/300], Step [400/1875], d_loss: 0.0322, g_loss: -0.2137\n",
      "Epoch [22/300], Step [600/1875], d_loss: -0.0624, g_loss: 0.0229\n",
      "Epoch [22/300], Step [800/1875], d_loss: -0.0167, g_loss: 0.1642\n",
      "Epoch [22/300], Step [1000/1875], d_loss: -0.1089, g_loss: -0.2641\n",
      "Epoch [22/300], Step [1200/1875], d_loss: -0.0436, g_loss: 0.1616\n",
      "Epoch [22/300], Step [1400/1875], d_loss: 0.0053, g_loss: -0.1210\n",
      "Epoch [22/300], Step [1600/1875], d_loss: -0.0482, g_loss: 0.0040\n",
      "Epoch [22/300], Step [1800/1875], d_loss: -0.0866, g_loss: 0.1357\n",
      "Epoch [23/300], Step [200/1875], d_loss: -0.2090, g_loss: 0.2218\n",
      "Epoch [23/300], Step [400/1875], d_loss: -0.0275, g_loss: -0.2052\n",
      "Epoch [23/300], Step [600/1875], d_loss: -0.0749, g_loss: 0.1148\n",
      "Epoch [23/300], Step [800/1875], d_loss: -0.0456, g_loss: -0.0283\n",
      "Epoch [23/300], Step [1000/1875], d_loss: -0.0235, g_loss: 0.0600\n",
      "Epoch [23/300], Step [1200/1875], d_loss: -0.0339, g_loss: -0.0647\n",
      "Epoch [23/300], Step [1400/1875], d_loss: -0.0118, g_loss: -0.0952\n",
      "Epoch [23/300], Step [1600/1875], d_loss: -0.1245, g_loss: -0.1235\n",
      "Epoch [23/300], Step [1800/1875], d_loss: -0.0229, g_loss: -0.0104\n",
      "Epoch [24/300], Step [200/1875], d_loss: -0.1024, g_loss: -0.1102\n",
      "Epoch [24/300], Step [400/1875], d_loss: -0.0006, g_loss: 0.0192\n",
      "Epoch [24/300], Step [600/1875], d_loss: 0.1996, g_loss: 0.4750\n",
      "Epoch [24/300], Step [800/1875], d_loss: -0.3048, g_loss: 1.1469\n",
      "Epoch [24/300], Step [1000/1875], d_loss: -0.1562, g_loss: 0.5125\n",
      "Epoch [24/300], Step [1200/1875], d_loss: -0.0788, g_loss: -1.6068\n",
      "Epoch [24/300], Step [1400/1875], d_loss: -0.2172, g_loss: -0.2865\n",
      "Epoch [24/300], Step [1600/1875], d_loss: -0.1304, g_loss: 1.9973\n",
      "Epoch [24/300], Step [1800/1875], d_loss: 0.1109, g_loss: -2.4146\n",
      "Epoch [25/300], Step [200/1875], d_loss: -0.1714, g_loss: -0.3425\n",
      "Epoch [25/300], Step [400/1875], d_loss: -0.2458, g_loss: 1.8050\n",
      "Epoch [25/300], Step [600/1875], d_loss: 0.0069, g_loss: -1.9570\n",
      "Epoch [25/300], Step [800/1875], d_loss: 0.2409, g_loss: 1.3421\n",
      "Epoch [25/300], Step [1000/1875], d_loss: 0.2814, g_loss: -1.3688\n",
      "Epoch [25/300], Step [1200/1875], d_loss: -0.0654, g_loss: -0.0205\n",
      "Epoch [25/300], Step [1400/1875], d_loss: -0.3485, g_loss: 2.2356\n",
      "Epoch [25/300], Step [1600/1875], d_loss: 0.2501, g_loss: -2.3079\n",
      "Epoch [25/300], Step [1800/1875], d_loss: 0.0966, g_loss: 0.2694\n",
      "Epoch [26/300], Step [200/1875], d_loss: -0.2103, g_loss: 1.3271\n",
      "Epoch [26/300], Step [400/1875], d_loss: -0.2451, g_loss: -0.7452\n",
      "Epoch [26/300], Step [600/1875], d_loss: -0.5542, g_loss: 1.9588\n",
      "Epoch [26/300], Step [800/1875], d_loss: 0.0264, g_loss: -1.3917\n",
      "Epoch [26/300], Step [1000/1875], d_loss: -0.0738, g_loss: 0.2086\n",
      "Epoch [26/300], Step [1200/1875], d_loss: -0.1016, g_loss: 0.1171\n",
      "Epoch [26/300], Step [1400/1875], d_loss: -0.0317, g_loss: 0.0842\n",
      "Epoch [26/300], Step [1600/1875], d_loss: -0.0218, g_loss: -0.0469\n",
      "Epoch [26/300], Step [1800/1875], d_loss: -0.0191, g_loss: 0.0535\n",
      "Epoch [27/300], Step [200/1875], d_loss: -0.0204, g_loss: -0.2350\n",
      "Epoch [27/300], Step [400/1875], d_loss: -0.0267, g_loss: 0.1101\n",
      "Epoch [27/300], Step [600/1875], d_loss: -0.0066, g_loss: 0.0087\n",
      "Epoch [27/300], Step [800/1875], d_loss: -0.0625, g_loss: -0.1470\n",
      "Epoch [27/300], Step [1000/1875], d_loss: -0.1629, g_loss: -0.1744\n",
      "Epoch [27/300], Step [1200/1875], d_loss: -0.1119, g_loss: 0.2023\n",
      "Epoch [27/300], Step [1400/1875], d_loss: -0.0602, g_loss: 0.0926\n",
      "Epoch [27/300], Step [1600/1875], d_loss: 0.0013, g_loss: -0.0701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/300], Step [1800/1875], d_loss: -0.0161, g_loss: -0.0035\n",
      "Epoch [28/300], Step [200/1875], d_loss: -0.0137, g_loss: -0.1327\n",
      "Epoch [28/300], Step [400/1875], d_loss: -0.0205, g_loss: 0.1408\n",
      "Epoch [28/300], Step [600/1875], d_loss: 0.0235, g_loss: -0.1545\n",
      "Epoch [28/300], Step [800/1875], d_loss: -0.0707, g_loss: -0.1033\n",
      "Epoch [28/300], Step [1000/1875], d_loss: 0.0363, g_loss: 0.0331\n",
      "Epoch [28/300], Step [1200/1875], d_loss: -0.0487, g_loss: 0.4407\n",
      "Epoch [28/300], Step [1400/1875], d_loss: -0.0723, g_loss: 0.3963\n",
      "Epoch [28/300], Step [1600/1875], d_loss: 0.0979, g_loss: -0.5155\n",
      "Epoch [28/300], Step [1800/1875], d_loss: -0.1257, g_loss: -0.6772\n",
      "Epoch [29/300], Step [200/1875], d_loss: 0.0009, g_loss: -0.7256\n",
      "Epoch [29/300], Step [400/1875], d_loss: -0.0636, g_loss: -0.1146\n",
      "Epoch [29/300], Step [600/1875], d_loss: 0.0005, g_loss: 0.8335\n",
      "Epoch [29/300], Step [800/1875], d_loss: -0.0039, g_loss: -0.2202\n",
      "Epoch [29/300], Step [1000/1875], d_loss: -0.0028, g_loss: 0.0111\n",
      "Epoch [29/300], Step [1200/1875], d_loss: -0.0525, g_loss: -0.2250\n",
      "Epoch [29/300], Step [1400/1875], d_loss: -0.0758, g_loss: 0.1405\n",
      "Epoch [29/300], Step [1600/1875], d_loss: -0.0790, g_loss: -0.0217\n",
      "Epoch [29/300], Step [1800/1875], d_loss: -0.0630, g_loss: 0.1564\n",
      "Epoch [30/300], Step [200/1875], d_loss: -0.1053, g_loss: 0.1132\n",
      "Epoch [30/300], Step [400/1875], d_loss: 0.0373, g_loss: -0.2808\n",
      "Epoch [30/300], Step [600/1875], d_loss: -0.0799, g_loss: 0.1570\n",
      "Epoch [30/300], Step [800/1875], d_loss: 0.0674, g_loss: -0.4343\n",
      "Epoch [30/300], Step [1000/1875], d_loss: -0.1625, g_loss: 0.1761\n",
      "Epoch [30/300], Step [1200/1875], d_loss: -0.0195, g_loss: 0.1066\n",
      "Epoch [30/300], Step [1400/1875], d_loss: -0.0712, g_loss: -0.0582\n",
      "Epoch [30/300], Step [1600/1875], d_loss: 0.0078, g_loss: -0.0802\n",
      "Epoch [30/300], Step [1800/1875], d_loss: -0.1011, g_loss: -0.0566\n",
      "Epoch [31/300], Step [200/1875], d_loss: -0.0537, g_loss: -0.0516\n",
      "Epoch [31/300], Step [400/1875], d_loss: -0.0399, g_loss: 0.0000\n",
      "Epoch [31/300], Step [600/1875], d_loss: -0.0465, g_loss: -0.0489\n",
      "Epoch [31/300], Step [800/1875], d_loss: 0.0003, g_loss: -0.0023\n",
      "Epoch [31/300], Step [1000/1875], d_loss: -0.0899, g_loss: 0.0015\n",
      "Epoch [31/300], Step [1200/1875], d_loss: 0.0035, g_loss: -0.0831\n",
      "Epoch [31/300], Step [1400/1875], d_loss: -0.0434, g_loss: 0.2296\n",
      "Epoch [31/300], Step [1600/1875], d_loss: -0.0102, g_loss: -0.0472\n",
      "Epoch [31/300], Step [1800/1875], d_loss: -0.0483, g_loss: 0.1422\n",
      "Epoch [32/300], Step [200/1875], d_loss: 0.0003, g_loss: 0.0355\n",
      "Epoch [32/300], Step [400/1875], d_loss: -0.0090, g_loss: -0.1445\n",
      "Epoch [32/300], Step [600/1875], d_loss: -0.0577, g_loss: 0.2264\n",
      "Epoch [32/300], Step [800/1875], d_loss: -0.0424, g_loss: -0.2552\n",
      "Epoch [32/300], Step [1000/1875], d_loss: 0.0433, g_loss: 0.1806\n",
      "Epoch [32/300], Step [1200/1875], d_loss: -0.0500, g_loss: -0.1049\n",
      "Epoch [32/300], Step [1400/1875], d_loss: 0.0276, g_loss: -0.0559\n",
      "Epoch [32/300], Step [1600/1875], d_loss: -0.1319, g_loss: 0.1382\n",
      "Epoch [32/300], Step [1800/1875], d_loss: 0.1311, g_loss: -0.2723\n",
      "Epoch [33/300], Step [200/1875], d_loss: 0.0397, g_loss: -0.0915\n",
      "Epoch [33/300], Step [400/1875], d_loss: -0.1032, g_loss: -0.0355\n",
      "Epoch [33/300], Step [600/1875], d_loss: 0.0268, g_loss: 0.0652\n",
      "Epoch [33/300], Step [800/1875], d_loss: -0.0887, g_loss: 0.0576\n",
      "Epoch [33/300], Step [1000/1875], d_loss: 0.0383, g_loss: -0.2047\n",
      "Epoch [33/300], Step [1200/1875], d_loss: -0.1088, g_loss: -0.3157\n",
      "Epoch [33/300], Step [1400/1875], d_loss: 0.0375, g_loss: 0.0732\n",
      "Epoch [33/300], Step [1600/1875], d_loss: -0.2049, g_loss: 0.8945\n",
      "Epoch [33/300], Step [1800/1875], d_loss: 0.0857, g_loss: -0.2178\n",
      "Epoch [34/300], Step [200/1875], d_loss: 0.0012, g_loss: -0.0171\n",
      "Epoch [34/300], Step [400/1875], d_loss: -0.1709, g_loss: -0.6669\n",
      "Epoch [34/300], Step [600/1875], d_loss: 0.1419, g_loss: 0.3121\n",
      "Epoch [34/300], Step [800/1875], d_loss: -0.4158, g_loss: 1.5071\n",
      "Epoch [34/300], Step [1000/1875], d_loss: 0.1661, g_loss: -1.5518\n",
      "Epoch [34/300], Step [1200/1875], d_loss: 0.0297, g_loss: 0.0362\n",
      "Epoch [34/300], Step [1400/1875], d_loss: -0.2214, g_loss: 1.2373\n",
      "Epoch [34/300], Step [1600/1875], d_loss: -0.1266, g_loss: -1.4175\n",
      "Epoch [34/300], Step [1800/1875], d_loss: 0.1043, g_loss: 1.4032\n",
      "Epoch [35/300], Step [200/1875], d_loss: -0.0317, g_loss: 0.0881\n",
      "Epoch [35/300], Step [400/1875], d_loss: 0.0311, g_loss: 0.0623\n",
      "Epoch [35/300], Step [600/1875], d_loss: -0.0083, g_loss: -0.9439\n",
      "Epoch [35/300], Step [800/1875], d_loss: 0.0172, g_loss: 0.3413\n",
      "Epoch [35/300], Step [1000/1875], d_loss: -0.0578, g_loss: -0.1711\n",
      "Epoch [35/300], Step [1200/1875], d_loss: -0.1192, g_loss: 0.1030\n",
      "Epoch [35/300], Step [1400/1875], d_loss: -0.0455, g_loss: -0.2540\n",
      "Epoch [35/300], Step [1600/1875], d_loss: -0.0798, g_loss: 0.2117\n",
      "Epoch [35/300], Step [1800/1875], d_loss: 0.0381, g_loss: -0.0234\n",
      "Epoch [36/300], Step [200/1875], d_loss: -0.0283, g_loss: -0.0161\n",
      "Epoch [36/300], Step [400/1875], d_loss: -0.1519, g_loss: -0.2071\n",
      "Epoch [36/300], Step [600/1875], d_loss: 0.0445, g_loss: -0.0374\n",
      "Epoch [36/300], Step [800/1875], d_loss: -0.2201, g_loss: 0.4496\n",
      "Epoch [36/300], Step [1000/1875], d_loss: -0.0008, g_loss: -0.3374\n",
      "Epoch [36/300], Step [1200/1875], d_loss: -0.0559, g_loss: 0.1616\n",
      "Epoch [36/300], Step [1400/1875], d_loss: -0.1401, g_loss: -0.0702\n",
      "Epoch [36/300], Step [1600/1875], d_loss: -0.0620, g_loss: 0.2026\n",
      "Epoch [36/300], Step [1800/1875], d_loss: -0.1119, g_loss: -0.2744\n",
      "Epoch [37/300], Step [200/1875], d_loss: 0.0190, g_loss: 0.0459\n",
      "Epoch [37/300], Step [400/1875], d_loss: -0.1444, g_loss: 0.2640\n",
      "Epoch [37/300], Step [600/1875], d_loss: -0.0245, g_loss: -0.0365\n",
      "Epoch [37/300], Step [800/1875], d_loss: 0.0672, g_loss: -0.4765\n",
      "Epoch [37/300], Step [1000/1875], d_loss: -0.2285, g_loss: -0.2854\n",
      "Epoch [37/300], Step [1200/1875], d_loss: 0.0495, g_loss: 0.0180\n",
      "Epoch [37/300], Step [1400/1875], d_loss: -0.1342, g_loss: 0.7128\n",
      "Epoch [37/300], Step [1600/1875], d_loss: -0.0082, g_loss: 0.0298\n",
      "Epoch [37/300], Step [1800/1875], d_loss: 0.0103, g_loss: -0.7813\n",
      "Epoch [38/300], Step [200/1875], d_loss: -0.0984, g_loss: -1.1974\n",
      "Epoch [38/300], Step [400/1875], d_loss: 0.0007, g_loss: -0.0167\n",
      "Epoch [38/300], Step [600/1875], d_loss: -0.1847, g_loss: 1.5198\n",
      "Epoch [38/300], Step [800/1875], d_loss: 0.3703, g_loss: -1.6036\n",
      "Epoch [38/300], Step [1000/1875], d_loss: 0.1252, g_loss: 0.1920\n",
      "Epoch [38/300], Step [1200/1875], d_loss: -0.0963, g_loss: 0.6462\n",
      "Epoch [38/300], Step [1400/1875], d_loss: -0.4354, g_loss: -0.8809\n",
      "Epoch [38/300], Step [1600/1875], d_loss: -0.6356, g_loss: 1.6260\n",
      "Epoch [38/300], Step [1800/1875], d_loss: 0.0627, g_loss: -1.7025\n",
      "Epoch [39/300], Step [200/1875], d_loss: 0.0636, g_loss: 0.5944\n",
      "Epoch [39/300], Step [400/1875], d_loss: 0.1310, g_loss: -1.2059\n",
      "Epoch [39/300], Step [600/1875], d_loss: 0.0464, g_loss: 0.3197\n",
      "Epoch [39/300], Step [800/1875], d_loss: 0.0470, g_loss: -0.6595\n",
      "Epoch [39/300], Step [1000/1875], d_loss: 0.0681, g_loss: 0.2006\n",
      "Epoch [39/300], Step [1200/1875], d_loss: -0.0403, g_loss: -0.3405\n",
      "Epoch [39/300], Step [1400/1875], d_loss: -0.0033, g_loss: 0.2802\n",
      "Epoch [39/300], Step [1600/1875], d_loss: -0.1349, g_loss: 0.1061\n",
      "Epoch [39/300], Step [1800/1875], d_loss: -0.0297, g_loss: -0.1864\n",
      "Epoch [40/300], Step [200/1875], d_loss: -0.0867, g_loss: 0.1050\n",
      "Epoch [40/300], Step [400/1875], d_loss: 0.0041, g_loss: -0.0142\n",
      "Epoch [40/300], Step [600/1875], d_loss: 0.0278, g_loss: -0.0792\n",
      "Epoch [40/300], Step [800/1875], d_loss: -0.0673, g_loss: 0.0746\n",
      "Epoch [40/300], Step [1000/1875], d_loss: 0.0262, g_loss: -0.1105\n",
      "Epoch [40/300], Step [1200/1875], d_loss: -0.0537, g_loss: -0.0017\n",
      "Epoch [40/300], Step [1400/1875], d_loss: -0.0071, g_loss: -0.0001\n",
      "Epoch [40/300], Step [1600/1875], d_loss: -0.0029, g_loss: -0.0210\n",
      "Epoch [40/300], Step [1800/1875], d_loss: -0.1093, g_loss: 0.1392\n",
      "Epoch [41/300], Step [200/1875], d_loss: -0.0556, g_loss: 0.1420\n",
      "Epoch [41/300], Step [400/1875], d_loss: -0.0540, g_loss: 0.1812\n",
      "Epoch [41/300], Step [600/1875], d_loss: 0.0812, g_loss: -0.3986\n",
      "Epoch [41/300], Step [800/1875], d_loss: -0.2046, g_loss: -0.0992\n",
      "Epoch [41/300], Step [1000/1875], d_loss: 0.0863, g_loss: 0.0394\n",
      "Epoch [41/300], Step [1200/1875], d_loss: -0.1600, g_loss: 0.6723\n",
      "Epoch [41/300], Step [1400/1875], d_loss: 0.0612, g_loss: -0.5025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/300], Step [1600/1875], d_loss: -0.0851, g_loss: -0.1278\n",
      "Epoch [41/300], Step [1800/1875], d_loss: -0.0315, g_loss: 0.5999\n",
      "Epoch [42/300], Step [200/1875], d_loss: 0.0985, g_loss: 0.6036\n",
      "Epoch [42/300], Step [400/1875], d_loss: 0.0059, g_loss: -0.0151\n",
      "Epoch [42/300], Step [600/1875], d_loss: -0.1546, g_loss: -0.5204\n",
      "Epoch [42/300], Step [800/1875], d_loss: 0.1185, g_loss: 0.2139\n",
      "Epoch [42/300], Step [1000/1875], d_loss: -0.0658, g_loss: 0.1825\n",
      "Epoch [42/300], Step [1200/1875], d_loss: -0.1080, g_loss: -0.6830\n",
      "Epoch [42/300], Step [1400/1875], d_loss: 0.1974, g_loss: 0.4327\n",
      "Epoch [42/300], Step [1600/1875], d_loss: -0.0879, g_loss: 0.2345\n",
      "Epoch [42/300], Step [1800/1875], d_loss: -0.3958, g_loss: -0.5521\n",
      "Epoch [43/300], Step [200/1875], d_loss: -0.0455, g_loss: -0.1170\n",
      "Epoch [43/300], Step [400/1875], d_loss: -0.1736, g_loss: 0.4615\n",
      "Epoch [43/300], Step [600/1875], d_loss: -0.1637, g_loss: -0.6451\n",
      "Epoch [43/300], Step [800/1875], d_loss: 0.0992, g_loss: 0.4300\n",
      "Epoch [43/300], Step [1000/1875], d_loss: -0.0292, g_loss: -0.0260\n",
      "Epoch [43/300], Step [1200/1875], d_loss: -0.0664, g_loss: 0.0500\n",
      "Epoch [43/300], Step [1400/1875], d_loss: -0.1218, g_loss: -0.2483\n",
      "Epoch [43/300], Step [1600/1875], d_loss: 0.0548, g_loss: -0.0556\n",
      "Epoch [43/300], Step [1800/1875], d_loss: -0.0624, g_loss: -0.0492\n",
      "Epoch [44/300], Step [200/1875], d_loss: 0.0127, g_loss: -0.2693\n",
      "Epoch [44/300], Step [400/1875], d_loss: -0.0355, g_loss: 0.0150\n",
      "Epoch [44/300], Step [600/1875], d_loss: -0.0669, g_loss: 0.0275\n",
      "Epoch [44/300], Step [800/1875], d_loss: 0.1207, g_loss: -0.1037\n",
      "Epoch [44/300], Step [1000/1875], d_loss: -0.1083, g_loss: -0.1215\n",
      "Epoch [44/300], Step [1200/1875], d_loss: 0.0308, g_loss: 0.1993\n",
      "Epoch [44/300], Step [1400/1875], d_loss: -0.0599, g_loss: 0.0196\n",
      "Epoch [44/300], Step [1600/1875], d_loss: -0.0595, g_loss: -0.0476\n",
      "Epoch [44/300], Step [1800/1875], d_loss: -0.0580, g_loss: 0.0391\n",
      "Epoch [45/300], Step [200/1875], d_loss: -0.0659, g_loss: -0.0337\n",
      "Epoch [45/300], Step [400/1875], d_loss: -0.0616, g_loss: -0.0049\n",
      "Epoch [45/300], Step [600/1875], d_loss: -0.0496, g_loss: 0.0689\n",
      "Epoch [45/300], Step [800/1875], d_loss: -0.0959, g_loss: 0.0159\n",
      "Epoch [45/300], Step [1000/1875], d_loss: -0.0863, g_loss: 0.1058\n",
      "Epoch [45/300], Step [1200/1875], d_loss: 0.0170, g_loss: -0.0653\n",
      "Epoch [45/300], Step [1400/1875], d_loss: -0.0688, g_loss: 0.0072\n",
      "Epoch [45/300], Step [1600/1875], d_loss: -0.0334, g_loss: -0.0619\n",
      "Epoch [45/300], Step [1800/1875], d_loss: -0.0822, g_loss: -0.0575\n",
      "Epoch [46/300], Step [200/1875], d_loss: -0.0750, g_loss: 0.0123\n",
      "Epoch [46/300], Step [400/1875], d_loss: -0.0444, g_loss: -0.0065\n",
      "Epoch [46/300], Step [600/1875], d_loss: -0.1172, g_loss: -0.0677\n",
      "Epoch [46/300], Step [800/1875], d_loss: -0.0458, g_loss: 0.0677\n",
      "Epoch [46/300], Step [1000/1875], d_loss: 0.0014, g_loss: 0.3309\n",
      "Epoch [46/300], Step [1200/1875], d_loss: -0.0400, g_loss: 0.1358\n",
      "Epoch [46/300], Step [1400/1875], d_loss: -0.0654, g_loss: -0.1547\n",
      "Epoch [46/300], Step [1600/1875], d_loss: 0.0025, g_loss: -0.0193\n",
      "Epoch [46/300], Step [1800/1875], d_loss: -0.0927, g_loss: 0.3363\n",
      "Epoch [47/300], Step [200/1875], d_loss: -0.1747, g_loss: 0.4551\n",
      "Epoch [47/300], Step [400/1875], d_loss: 0.1606, g_loss: -0.3239\n",
      "Epoch [47/300], Step [600/1875], d_loss: -0.1655, g_loss: -0.3167\n",
      "Epoch [47/300], Step [800/1875], d_loss: 0.0725, g_loss: 0.5147\n",
      "Epoch [47/300], Step [1000/1875], d_loss: -0.0387, g_loss: 0.1664\n",
      "Epoch [47/300], Step [1200/1875], d_loss: -0.2018, g_loss: -0.4966\n",
      "Epoch [47/300], Step [1400/1875], d_loss: 0.1273, g_loss: 0.3331\n",
      "Epoch [47/300], Step [1600/1875], d_loss: -0.1424, g_loss: 0.2719\n",
      "Epoch [47/300], Step [1800/1875], d_loss: -0.2204, g_loss: -0.4711\n",
      "Epoch [48/300], Step [200/1875], d_loss: -0.3360, g_loss: -0.3844\n",
      "Epoch [48/300], Step [400/1875], d_loss: 0.1296, g_loss: 0.3143\n",
      "Epoch [48/300], Step [600/1875], d_loss: -0.0746, g_loss: 0.3966\n",
      "Epoch [48/300], Step [800/1875], d_loss: -0.1063, g_loss: -0.6835\n",
      "Epoch [48/300], Step [1000/1875], d_loss: 0.0648, g_loss: 0.0686\n",
      "Epoch [48/300], Step [1200/1875], d_loss: -0.1690, g_loss: 0.6838\n",
      "Epoch [48/300], Step [1400/1875], d_loss: 0.0348, g_loss: -0.6576\n",
      "Epoch [48/300], Step [1600/1875], d_loss: 0.1717, g_loss: 0.4083\n",
      "Epoch [48/300], Step [1800/1875], d_loss: -0.1430, g_loss: 0.5726\n",
      "Epoch [49/300], Step [200/1875], d_loss: -0.0150, g_loss: 0.0579\n",
      "Epoch [49/300], Step [400/1875], d_loss: -0.2356, g_loss: -0.5648\n",
      "Epoch [49/300], Step [600/1875], d_loss: -0.1715, g_loss: 1.2814\n",
      "Epoch [49/300], Step [800/1875], d_loss: 0.2518, g_loss: -0.7749\n",
      "Epoch [49/300], Step [1000/1875], d_loss: 0.0406, g_loss: 0.4234\n",
      "Epoch [49/300], Step [1200/1875], d_loss: 0.1519, g_loss: -0.5938\n",
      "Epoch [49/300], Step [1400/1875], d_loss: 0.0902, g_loss: 0.2337\n",
      "Epoch [49/300], Step [1600/1875], d_loss: -0.4772, g_loss: 1.0344\n",
      "Epoch [49/300], Step [1800/1875], d_loss: -0.1538, g_loss: -1.1270\n",
      "Epoch [50/300], Step [200/1875], d_loss: -0.1947, g_loss: -0.4715\n",
      "Epoch [50/300], Step [400/1875], d_loss: -0.4063, g_loss: 1.2665\n",
      "Epoch [50/300], Step [600/1875], d_loss: -0.1745, g_loss: -1.1401\n",
      "Epoch [50/300], Step [800/1875], d_loss: -0.2241, g_loss: 1.3424\n",
      "Epoch [50/300], Step [1000/1875], d_loss: 0.1363, g_loss: -1.2057\n",
      "Epoch [50/300], Step [1200/1875], d_loss: -0.1087, g_loss: 0.3197\n",
      "Epoch [50/300], Step [1400/1875], d_loss: 0.0272, g_loss: 0.1669\n",
      "Epoch [50/300], Step [1600/1875], d_loss: 0.0000, g_loss: -0.1045\n",
      "Epoch [50/300], Step [1800/1875], d_loss: -0.0464, g_loss: 0.2495\n",
      "Epoch [51/300], Step [200/1875], d_loss: -0.0544, g_loss: 0.1811\n",
      "Epoch [51/300], Step [400/1875], d_loss: -0.1104, g_loss: -0.2629\n",
      "Epoch [51/300], Step [600/1875], d_loss: -0.0095, g_loss: 0.1424\n",
      "Epoch [51/300], Step [800/1875], d_loss: -0.0655, g_loss: -0.1165\n",
      "Epoch [51/300], Step [1000/1875], d_loss: -0.0886, g_loss: 0.2169\n",
      "Epoch [51/300], Step [1200/1875], d_loss: 0.0367, g_loss: -0.0177\n",
      "Epoch [51/300], Step [1400/1875], d_loss: -0.0760, g_loss: -0.0374\n",
      "Epoch [51/300], Step [1600/1875], d_loss: -0.0076, g_loss: 0.0012\n",
      "Epoch [51/300], Step [1800/1875], d_loss: -0.0002, g_loss: -0.2090\n",
      "Epoch [52/300], Step [200/1875], d_loss: -0.0665, g_loss: -0.0389\n",
      "Epoch [52/300], Step [400/1875], d_loss: -0.1053, g_loss: 0.0094\n",
      "Epoch [52/300], Step [600/1875], d_loss: -0.0674, g_loss: -0.0658\n",
      "Epoch [52/300], Step [800/1875], d_loss: -0.0094, g_loss: 0.0003\n",
      "Epoch [52/300], Step [1000/1875], d_loss: 0.0399, g_loss: -0.0022\n",
      "Epoch [52/300], Step [1200/1875], d_loss: -0.0385, g_loss: -0.0614\n",
      "Epoch [52/300], Step [1400/1875], d_loss: -0.1285, g_loss: 0.0684\n",
      "Epoch [52/300], Step [1600/1875], d_loss: -0.1090, g_loss: -0.0286\n",
      "Epoch [52/300], Step [1800/1875], d_loss: -0.0318, g_loss: -0.0708\n",
      "Epoch [53/300], Step [200/1875], d_loss: -0.0734, g_loss: 0.0591\n",
      "Epoch [53/300], Step [400/1875], d_loss: -0.1021, g_loss: 0.1829\n",
      "Epoch [53/300], Step [600/1875], d_loss: -0.0090, g_loss: -0.2141\n",
      "Epoch [53/300], Step [800/1875], d_loss: 0.0228, g_loss: 0.2298\n",
      "Epoch [53/300], Step [1000/1875], d_loss: -0.0633, g_loss: 0.1493\n",
      "Epoch [53/300], Step [1200/1875], d_loss: -0.0651, g_loss: -0.1429\n",
      "Epoch [53/300], Step [1400/1875], d_loss: -0.0009, g_loss: 0.0961\n",
      "Epoch [53/300], Step [1600/1875], d_loss: 0.0455, g_loss: -0.1124\n",
      "Epoch [53/300], Step [1800/1875], d_loss: -0.0888, g_loss: 0.2445\n",
      "Epoch [54/300], Step [200/1875], d_loss: 0.0360, g_loss: -0.0985\n",
      "Epoch [54/300], Step [400/1875], d_loss: -0.0803, g_loss: -0.2279\n",
      "Epoch [54/300], Step [600/1875], d_loss: -0.0554, g_loss: 0.1504\n",
      "Epoch [54/300], Step [800/1875], d_loss: 0.0526, g_loss: 0.0348\n",
      "Epoch [54/300], Step [1000/1875], d_loss: -0.0672, g_loss: -0.2231\n",
      "Epoch [54/300], Step [1200/1875], d_loss: -0.1634, g_loss: 0.4913\n",
      "Epoch [54/300], Step [1400/1875], d_loss: 0.0350, g_loss: -0.2719\n",
      "Epoch [54/300], Step [1600/1875], d_loss: -0.0864, g_loss: -0.4875\n",
      "Epoch [54/300], Step [1800/1875], d_loss: -0.0784, g_loss: -0.1616\n",
      "Epoch [55/300], Step [200/1875], d_loss: -0.2644, g_loss: -0.2813\n",
      "Epoch [55/300], Step [400/1875], d_loss: 0.2171, g_loss: 0.5843\n",
      "Epoch [55/300], Step [600/1875], d_loss: -0.0364, g_loss: 0.1653\n",
      "Epoch [55/300], Step [800/1875], d_loss: -0.2486, g_loss: -0.6499\n",
      "Epoch [55/300], Step [1000/1875], d_loss: -0.1116, g_loss: 0.2666\n",
      "Epoch [55/300], Step [1200/1875], d_loss: -0.0779, g_loss: -0.2603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/300], Step [1400/1875], d_loss: -0.0496, g_loss: 0.0525\n",
      "Epoch [55/300], Step [1600/1875], d_loss: -0.0338, g_loss: -0.0006\n",
      "Epoch [55/300], Step [1800/1875], d_loss: -0.0372, g_loss: 0.0469\n",
      "Epoch [56/300], Step [200/1875], d_loss: 0.0101, g_loss: 0.0453\n",
      "Epoch [56/300], Step [400/1875], d_loss: -0.0865, g_loss: 0.0681\n",
      "Epoch [56/300], Step [600/1875], d_loss: -0.0782, g_loss: -0.0333\n",
      "Epoch [56/300], Step [800/1875], d_loss: -0.0401, g_loss: -0.0186\n",
      "Epoch [56/300], Step [1000/1875], d_loss: 0.0031, g_loss: 0.1390\n",
      "Epoch [56/300], Step [1200/1875], d_loss: -0.0702, g_loss: -0.0736\n",
      "Epoch [56/300], Step [1400/1875], d_loss: -0.0493, g_loss: -0.1312\n",
      "Epoch [56/300], Step [1600/1875], d_loss: -0.0774, g_loss: 0.1367\n",
      "Epoch [56/300], Step [1800/1875], d_loss: -0.0133, g_loss: -0.0697\n",
      "Epoch [57/300], Step [200/1875], d_loss: -0.0363, g_loss: 0.0475\n",
      "Epoch [57/300], Step [400/1875], d_loss: -0.0709, g_loss: -0.0325\n",
      "Epoch [57/300], Step [600/1875], d_loss: -0.0685, g_loss: 0.0786\n",
      "Epoch [57/300], Step [800/1875], d_loss: -0.0024, g_loss: -0.0679\n",
      "Epoch [57/300], Step [1000/1875], d_loss: -0.0333, g_loss: -0.0081\n",
      "Epoch [57/300], Step [1200/1875], d_loss: -0.1191, g_loss: -0.1147\n",
      "Epoch [57/300], Step [1400/1875], d_loss: -0.0357, g_loss: 0.0433\n",
      "Epoch [57/300], Step [1600/1875], d_loss: -0.0301, g_loss: -0.1694\n",
      "Epoch [57/300], Step [1800/1875], d_loss: -0.0956, g_loss: 0.1954\n",
      "Epoch [58/300], Step [200/1875], d_loss: -0.0318, g_loss: -0.0852\n",
      "Epoch [58/300], Step [400/1875], d_loss: -0.0965, g_loss: 0.0121\n",
      "Epoch [58/300], Step [600/1875], d_loss: -0.0533, g_loss: 0.0041\n",
      "Epoch [58/300], Step [800/1875], d_loss: -0.0480, g_loss: -0.0237\n",
      "Epoch [58/300], Step [1000/1875], d_loss: -0.0844, g_loss: -0.0239\n",
      "Epoch [58/300], Step [1200/1875], d_loss: -0.1093, g_loss: -0.0023\n",
      "Epoch [58/300], Step [1400/1875], d_loss: 0.0028, g_loss: -0.1177\n",
      "Epoch [58/300], Step [1600/1875], d_loss: -0.0559, g_loss: 0.1335\n",
      "Epoch [58/300], Step [1800/1875], d_loss: -0.0370, g_loss: 0.1640\n",
      "Epoch [59/300], Step [200/1875], d_loss: 0.0101, g_loss: -0.1192\n",
      "Epoch [59/300], Step [400/1875], d_loss: -0.0725, g_loss: 0.0300\n",
      "Epoch [59/300], Step [600/1875], d_loss: 0.0225, g_loss: -0.0582\n",
      "Epoch [59/300], Step [800/1875], d_loss: -0.0692, g_loss: 0.1155\n",
      "Epoch [59/300], Step [1000/1875], d_loss: 0.0136, g_loss: -0.0424\n",
      "Epoch [59/300], Step [1200/1875], d_loss: -0.0525, g_loss: -0.0966\n",
      "Epoch [59/300], Step [1400/1875], d_loss: -0.1820, g_loss: 0.1921\n",
      "Epoch [59/300], Step [1600/1875], d_loss: 0.0308, g_loss: -0.0325\n",
      "Epoch [59/300], Step [1800/1875], d_loss: -0.0367, g_loss: -0.0058\n",
      "Epoch [60/300], Step [200/1875], d_loss: 0.0721, g_loss: 0.0853\n",
      "Epoch [60/300], Step [400/1875], d_loss: -0.0227, g_loss: 0.1385\n",
      "Epoch [60/300], Step [600/1875], d_loss: -0.0529, g_loss: -0.1274\n",
      "Epoch [60/300], Step [800/1875], d_loss: -0.0493, g_loss: -0.0344\n",
      "Epoch [60/300], Step [1000/1875], d_loss: -0.0219, g_loss: 0.0130\n",
      "Epoch [60/300], Step [1200/1875], d_loss: -0.0122, g_loss: -0.0790\n",
      "Epoch [60/300], Step [1400/1875], d_loss: -0.0227, g_loss: -0.0316\n",
      "Epoch [60/300], Step [1600/1875], d_loss: -0.0077, g_loss: -0.0022\n",
      "Epoch [60/300], Step [1800/1875], d_loss: -0.0155, g_loss: -0.0383\n",
      "Epoch [61/300], Step [200/1875], d_loss: -0.0892, g_loss: 0.0456\n",
      "Epoch [61/300], Step [400/1875], d_loss: -0.0132, g_loss: -0.0043\n",
      "Epoch [61/300], Step [600/1875], d_loss: -0.0594, g_loss: -0.0006\n",
      "Epoch [61/300], Step [800/1875], d_loss: -0.0432, g_loss: 0.0563\n",
      "Epoch [61/300], Step [1000/1875], d_loss: 0.0195, g_loss: -0.1132\n",
      "Epoch [61/300], Step [1200/1875], d_loss: -0.0508, g_loss: 0.0086\n",
      "Epoch [61/300], Step [1400/1875], d_loss: 0.0163, g_loss: -0.0035\n",
      "Epoch [61/300], Step [1600/1875], d_loss: -0.0341, g_loss: 0.0131\n",
      "Epoch [61/300], Step [1800/1875], d_loss: -0.0756, g_loss: -0.0342\n",
      "Epoch [62/300], Step [200/1875], d_loss: -0.0477, g_loss: -0.0522\n",
      "Epoch [62/300], Step [400/1875], d_loss: -0.0006, g_loss: 0.0236\n",
      "Epoch [62/300], Step [600/1875], d_loss: -0.0107, g_loss: -0.0467\n",
      "Epoch [62/300], Step [800/1875], d_loss: -0.0852, g_loss: 0.1179\n",
      "Epoch [62/300], Step [1000/1875], d_loss: -0.1416, g_loss: 0.0016\n",
      "Epoch [62/300], Step [1200/1875], d_loss: 0.0980, g_loss: -0.0400\n",
      "Epoch [62/300], Step [1400/1875], d_loss: -0.0584, g_loss: 0.3823\n",
      "Epoch [62/300], Step [1600/1875], d_loss: 0.0057, g_loss: -0.0680\n",
      "Epoch [62/300], Step [1800/1875], d_loss: -0.1018, g_loss: -0.2158\n",
      "Epoch [63/300], Step [200/1875], d_loss: -0.0720, g_loss: -0.1969\n",
      "Epoch [63/300], Step [400/1875], d_loss: 0.0243, g_loss: 0.1238\n",
      "Epoch [63/300], Step [600/1875], d_loss: -0.0521, g_loss: 0.1300\n",
      "Epoch [63/300], Step [800/1875], d_loss: -0.1318, g_loss: -0.1905\n",
      "Epoch [63/300], Step [1000/1875], d_loss: 0.0473, g_loss: 0.0266\n",
      "Epoch [63/300], Step [1200/1875], d_loss: -0.1303, g_loss: 0.3006\n",
      "Epoch [63/300], Step [1400/1875], d_loss: 0.0796, g_loss: -0.2795\n",
      "Epoch [63/300], Step [1600/1875], d_loss: -0.0492, g_loss: -0.0529\n",
      "Epoch [63/300], Step [1800/1875], d_loss: -0.0017, g_loss: 0.1911\n",
      "Epoch [64/300], Step [200/1875], d_loss: -0.0820, g_loss: 0.1925\n",
      "Epoch [64/300], Step [400/1875], d_loss: 0.0813, g_loss: -0.1077\n",
      "Epoch [64/300], Step [600/1875], d_loss: -0.0065, g_loss: -0.0100\n",
      "Epoch [64/300], Step [800/1875], d_loss: -0.0430, g_loss: 0.1453\n",
      "Epoch [64/300], Step [1000/1875], d_loss: -0.0517, g_loss: -0.1984\n",
      "Epoch [64/300], Step [1200/1875], d_loss: 0.0361, g_loss: 0.1913\n",
      "Epoch [64/300], Step [1400/1875], d_loss: -0.0723, g_loss: -0.2113\n",
      "Epoch [64/300], Step [1600/1875], d_loss: -0.0782, g_loss: 0.1258\n",
      "Epoch [64/300], Step [1800/1875], d_loss: -0.0547, g_loss: -0.0928\n",
      "Epoch [65/300], Step [200/1875], d_loss: -0.0513, g_loss: 0.0625\n",
      "Epoch [65/300], Step [400/1875], d_loss: -0.0624, g_loss: -0.0825\n",
      "Epoch [65/300], Step [600/1875], d_loss: -0.0312, g_loss: 0.1966\n",
      "Epoch [65/300], Step [800/1875], d_loss: -0.0534, g_loss: -0.1369\n",
      "Epoch [65/300], Step [1000/1875], d_loss: -0.0643, g_loss: 0.1142\n",
      "Epoch [65/300], Step [1200/1875], d_loss: -0.0295, g_loss: -0.0939\n",
      "Epoch [65/300], Step [1400/1875], d_loss: -0.0358, g_loss: 0.0573\n",
      "Epoch [65/300], Step [1600/1875], d_loss: -0.0121, g_loss: -0.0928\n",
      "Epoch [65/300], Step [1800/1875], d_loss: -0.0725, g_loss: 0.0889\n",
      "Epoch [66/300], Step [200/1875], d_loss: -0.0393, g_loss: -0.0385\n",
      "Epoch [66/300], Step [400/1875], d_loss: -0.0837, g_loss: -0.0060\n",
      "Epoch [66/300], Step [600/1875], d_loss: -0.0496, g_loss: 0.1250\n",
      "Epoch [66/300], Step [800/1875], d_loss: 0.1361, g_loss: -0.4079\n",
      "Epoch [66/300], Step [1000/1875], d_loss: -0.2541, g_loss: 0.0168\n",
      "Epoch [66/300], Step [1200/1875], d_loss: 0.0528, g_loss: 0.0652\n",
      "Epoch [66/300], Step [1400/1875], d_loss: -0.2118, g_loss: 0.7323\n",
      "Epoch [66/300], Step [1600/1875], d_loss: 0.1242, g_loss: -0.3650\n",
      "Epoch [66/300], Step [1800/1875], d_loss: -0.2960, g_loss: -0.0122\n",
      "Epoch [67/300], Step [200/1875], d_loss: 0.0804, g_loss: 0.0623\n",
      "Epoch [67/300], Step [400/1875], d_loss: -0.0515, g_loss: 0.1032\n",
      "Epoch [67/300], Step [600/1875], d_loss: -0.0369, g_loss: -0.1363\n",
      "Epoch [67/300], Step [800/1875], d_loss: -0.0833, g_loss: 0.4341\n",
      "Epoch [67/300], Step [1000/1875], d_loss: -0.0744, g_loss: -0.2993\n",
      "Epoch [67/300], Step [1200/1875], d_loss: -0.2880, g_loss: 0.8019\n",
      "Epoch [67/300], Step [1400/1875], d_loss: 0.2200, g_loss: -0.8885\n",
      "Epoch [67/300], Step [1600/1875], d_loss: 0.0113, g_loss: 0.2467\n",
      "Epoch [67/300], Step [1800/1875], d_loss: 0.0660, g_loss: -0.4005\n",
      "Epoch [68/300], Step [200/1875], d_loss: 0.0125, g_loss: 0.1819\n",
      "Epoch [68/300], Step [400/1875], d_loss: -0.0956, g_loss: -0.1321\n",
      "Epoch [68/300], Step [600/1875], d_loss: 0.0347, g_loss: 0.0852\n",
      "Epoch [68/300], Step [800/1875], d_loss: -0.0732, g_loss: -0.1335\n",
      "Epoch [68/300], Step [1000/1875], d_loss: -0.0575, g_loss: -0.0038\n",
      "Epoch [68/300], Step [1200/1875], d_loss: -0.0323, g_loss: 0.1533\n",
      "Epoch [68/300], Step [1400/1875], d_loss: -0.0251, g_loss: -0.1113\n",
      "Epoch [68/300], Step [1600/1875], d_loss: -0.0508, g_loss: -0.0569\n",
      "Epoch [68/300], Step [1800/1875], d_loss: -0.0647, g_loss: 0.0559\n",
      "Epoch [69/300], Step [200/1875], d_loss: 0.0046, g_loss: -0.0188\n",
      "Epoch [69/300], Step [400/1875], d_loss: -0.0620, g_loss: 0.0090\n",
      "Epoch [69/300], Step [600/1875], d_loss: -0.0242, g_loss: -0.0659\n",
      "Epoch [69/300], Step [800/1875], d_loss: 0.0373, g_loss: 0.0252\n",
      "Epoch [69/300], Step [1000/1875], d_loss: -0.1157, g_loss: -0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/300], Step [1200/1875], d_loss: -0.0601, g_loss: 0.1457\n",
      "Epoch [69/300], Step [1400/1875], d_loss: -0.0347, g_loss: -0.1007\n",
      "Epoch [69/300], Step [1600/1875], d_loss: -0.0054, g_loss: 0.0338\n",
      "Epoch [69/300], Step [1800/1875], d_loss: -0.0530, g_loss: -0.0563\n",
      "Epoch [70/300], Step [200/1875], d_loss: -0.0862, g_loss: 0.0543\n",
      "Epoch [70/300], Step [400/1875], d_loss: -0.0654, g_loss: 0.0075\n",
      "Epoch [70/300], Step [600/1875], d_loss: -0.0467, g_loss: -0.0134\n",
      "Epoch [70/300], Step [800/1875], d_loss: -0.1186, g_loss: -0.0536\n",
      "Epoch [70/300], Step [1000/1875], d_loss: -0.0778, g_loss: 0.0925\n",
      "Epoch [70/300], Step [1200/1875], d_loss: 0.0433, g_loss: -0.1432\n",
      "Epoch [70/300], Step [1400/1875], d_loss: 0.0859, g_loss: -0.0704\n",
      "Epoch [70/300], Step [1600/1875], d_loss: -0.0073, g_loss: 0.0595\n",
      "Epoch [70/300], Step [1800/1875], d_loss: -0.1015, g_loss: 0.1430\n",
      "Epoch [71/300], Step [200/1875], d_loss: -0.1135, g_loss: 0.1264\n",
      "Epoch [71/300], Step [400/1875], d_loss: 0.0578, g_loss: -0.1171\n",
      "Epoch [71/300], Step [600/1875], d_loss: -0.0602, g_loss: 0.0850\n",
      "Epoch [71/300], Step [800/1875], d_loss: 0.0431, g_loss: -0.0653\n",
      "Epoch [71/300], Step [1000/1875], d_loss: -0.1373, g_loss: 0.0770\n",
      "Epoch [71/300], Step [1200/1875], d_loss: -0.0408, g_loss: -0.0614\n",
      "Epoch [71/300], Step [1400/1875], d_loss: -0.0783, g_loss: 0.1553\n",
      "Epoch [71/300], Step [1600/1875], d_loss: -0.1477, g_loss: -0.3061\n",
      "Epoch [71/300], Step [1800/1875], d_loss: 0.1378, g_loss: 0.0712\n",
      "Epoch [72/300], Step [200/1875], d_loss: 0.1269, g_loss: 0.1820\n",
      "Epoch [72/300], Step [400/1875], d_loss: -0.0300, g_loss: 0.0328\n",
      "Epoch [72/300], Step [600/1875], d_loss: -0.1539, g_loss: -0.1731\n",
      "Epoch [72/300], Step [800/1875], d_loss: 0.0820, g_loss: 0.2966\n",
      "Epoch [72/300], Step [1000/1875], d_loss: 0.0628, g_loss: -0.2430\n",
      "Epoch [72/300], Step [1200/1875], d_loss: -0.1575, g_loss: -0.1708\n",
      "Epoch [72/300], Step [1400/1875], d_loss: -0.1433, g_loss: 0.4676\n",
      "Epoch [72/300], Step [1600/1875], d_loss: -0.0533, g_loss: -0.3190\n",
      "Epoch [72/300], Step [1800/1875], d_loss: 0.0573, g_loss: 0.2808\n",
      "Epoch [73/300], Step [200/1875], d_loss: -0.0344, g_loss: 0.3091\n",
      "Epoch [73/300], Step [400/1875], d_loss: 0.0244, g_loss: -0.1227\n",
      "Epoch [73/300], Step [600/1875], d_loss: 0.0135, g_loss: -0.0083\n",
      "Epoch [73/300], Step [800/1875], d_loss: -0.0788, g_loss: 0.1230\n",
      "Epoch [73/300], Step [1000/1875], d_loss: -0.0029, g_loss: -0.0806\n",
      "Epoch [73/300], Step [1200/1875], d_loss: -0.0637, g_loss: -0.0536\n",
      "Epoch [73/300], Step [1400/1875], d_loss: -0.0286, g_loss: 0.0440\n",
      "Epoch [73/300], Step [1600/1875], d_loss: -0.0740, g_loss: -0.0006\n",
      "Epoch [73/300], Step [1800/1875], d_loss: -0.0132, g_loss: -0.0659\n",
      "Epoch [74/300], Step [200/1875], d_loss: -0.0303, g_loss: 0.0254\n",
      "Epoch [74/300], Step [400/1875], d_loss: -0.0948, g_loss: -0.0055\n",
      "Epoch [74/300], Step [600/1875], d_loss: -0.0702, g_loss: -0.0123\n",
      "Epoch [74/300], Step [800/1875], d_loss: -0.0522, g_loss: -0.0084\n",
      "Epoch [74/300], Step [1000/1875], d_loss: -0.0765, g_loss: 0.1134\n",
      "Epoch [74/300], Step [1200/1875], d_loss: -0.0649, g_loss: 0.0087\n",
      "Epoch [74/300], Step [1400/1875], d_loss: 0.0103, g_loss: 0.1241\n",
      "Epoch [74/300], Step [1600/1875], d_loss: -0.0614, g_loss: -0.0163\n",
      "Epoch [74/300], Step [1800/1875], d_loss: 0.0139, g_loss: -0.0333\n",
      "Epoch [75/300], Step [200/1875], d_loss: -0.0322, g_loss: 0.1535\n",
      "Epoch [75/300], Step [400/1875], d_loss: -0.0006, g_loss: -0.1618\n",
      "Epoch [75/300], Step [600/1875], d_loss: -0.0574, g_loss: -0.0304\n",
      "Epoch [75/300], Step [800/1875], d_loss: -0.0313, g_loss: -0.0397\n",
      "Epoch [75/300], Step [1000/1875], d_loss: -0.0050, g_loss: -0.1090\n",
      "Epoch [75/300], Step [1200/1875], d_loss: -0.0721, g_loss: 0.1329\n",
      "Epoch [75/300], Step [1400/1875], d_loss: -0.0361, g_loss: -0.1019\n",
      "Epoch [75/300], Step [1600/1875], d_loss: -0.0332, g_loss: 0.1271\n",
      "Epoch [75/300], Step [1800/1875], d_loss: -0.0329, g_loss: -0.1344\n",
      "Epoch [76/300], Step [200/1875], d_loss: -0.1029, g_loss: 0.0419\n",
      "Epoch [76/300], Step [400/1875], d_loss: -0.0103, g_loss: -0.0571\n",
      "Epoch [76/300], Step [600/1875], d_loss: -0.1039, g_loss: 0.0664\n",
      "Epoch [76/300], Step [800/1875], d_loss: -0.0272, g_loss: -0.0952\n",
      "Epoch [76/300], Step [1000/1875], d_loss: -0.0525, g_loss: 0.1457\n",
      "Epoch [76/300], Step [1200/1875], d_loss: 0.0104, g_loss: -0.1992\n",
      "Epoch [76/300], Step [1400/1875], d_loss: -0.1114, g_loss: 0.1160\n",
      "Epoch [76/300], Step [1600/1875], d_loss: 0.0128, g_loss: -0.0630\n",
      "Epoch [76/300], Step [1800/1875], d_loss: -0.0814, g_loss: 0.1431\n",
      "Epoch [77/300], Step [200/1875], d_loss: -0.0234, g_loss: -0.0216\n",
      "Epoch [77/300], Step [400/1875], d_loss: -0.0996, g_loss: -0.0265\n",
      "Epoch [77/300], Step [600/1875], d_loss: 0.0510, g_loss: 0.0737\n",
      "Epoch [77/300], Step [800/1875], d_loss: -0.0965, g_loss: -0.0503\n",
      "Epoch [77/300], Step [1000/1875], d_loss: -0.0719, g_loss: 0.0497\n",
      "Epoch [77/300], Step [1200/1875], d_loss: -0.0876, g_loss: 0.0230\n",
      "Epoch [77/300], Step [1400/1875], d_loss: -0.0046, g_loss: 0.0705\n",
      "Epoch [77/300], Step [1600/1875], d_loss: -0.0720, g_loss: -0.1457\n",
      "Epoch [77/300], Step [1800/1875], d_loss: -0.0520, g_loss: 0.1275\n",
      "Epoch [78/300], Step [200/1875], d_loss: -0.0411, g_loss: 0.0157\n",
      "Epoch [78/300], Step [400/1875], d_loss: -0.0924, g_loss: 0.0068\n",
      "Epoch [78/300], Step [600/1875], d_loss: -0.0305, g_loss: -0.0407\n",
      "Epoch [78/300], Step [800/1875], d_loss: -0.0568, g_loss: 0.0059\n",
      "Epoch [78/300], Step [1000/1875], d_loss: -0.0759, g_loss: 0.0243\n",
      "Epoch [78/300], Step [1200/1875], d_loss: -0.0433, g_loss: -0.0070\n",
      "Epoch [78/300], Step [1400/1875], d_loss: -0.0623, g_loss: 0.0472\n",
      "Epoch [78/300], Step [1600/1875], d_loss: -0.0241, g_loss: -0.1017\n",
      "Epoch [78/300], Step [1800/1875], d_loss: -0.0608, g_loss: 0.0975\n",
      "Epoch [79/300], Step [200/1875], d_loss: -0.1235, g_loss: 0.0575\n",
      "Epoch [79/300], Step [400/1875], d_loss: -0.0295, g_loss: 0.0095\n",
      "Epoch [79/300], Step [600/1875], d_loss: -0.0738, g_loss: -0.0369\n",
      "Epoch [79/300], Step [800/1875], d_loss: -0.0376, g_loss: 0.0828\n",
      "Epoch [79/300], Step [1000/1875], d_loss: -0.0373, g_loss: 0.0290\n",
      "Epoch [79/300], Step [1200/1875], d_loss: -0.0104, g_loss: -0.1306\n",
      "Epoch [79/300], Step [1400/1875], d_loss: -0.0305, g_loss: 0.0446\n",
      "Epoch [79/300], Step [1600/1875], d_loss: -0.0534, g_loss: 0.0221\n",
      "Epoch [79/300], Step [1800/1875], d_loss: -0.0224, g_loss: -0.0490\n",
      "Epoch [80/300], Step [200/1875], d_loss: -0.0858, g_loss: -0.1178\n",
      "Epoch [80/300], Step [400/1875], d_loss: -0.0115, g_loss: 0.0556\n",
      "Epoch [80/300], Step [600/1875], d_loss: -0.1267, g_loss: -0.1249\n",
      "Epoch [80/300], Step [800/1875], d_loss: 0.1138, g_loss: 0.1310\n",
      "Epoch [80/300], Step [1000/1875], d_loss: -0.0645, g_loss: 0.1162\n",
      "Epoch [80/300], Step [1200/1875], d_loss: 0.1672, g_loss: -0.3803\n",
      "Epoch [80/300], Step [1400/1875], d_loss: -0.1727, g_loss: -0.0448\n",
      "Epoch [80/300], Step [1600/1875], d_loss: 0.0835, g_loss: -0.0712\n",
      "Epoch [80/300], Step [1800/1875], d_loss: -0.2068, g_loss: 0.6969\n",
      "Epoch [81/300], Step [200/1875], d_loss: -0.1685, g_loss: 0.7683\n",
      "Epoch [81/300], Step [400/1875], d_loss: 0.1476, g_loss: -0.6539\n",
      "Epoch [81/300], Step [600/1875], d_loss: -0.1959, g_loss: -0.1569\n",
      "Epoch [81/300], Step [800/1875], d_loss: -0.1228, g_loss: 0.7760\n",
      "Epoch [81/300], Step [1000/1875], d_loss: 0.1055, g_loss: -0.3262\n",
      "Epoch [81/300], Step [1200/1875], d_loss: -0.1413, g_loss: -0.3387\n",
      "Epoch [81/300], Step [1400/1875], d_loss: -0.1055, g_loss: 0.9556\n",
      "Epoch [81/300], Step [1600/1875], d_loss: 0.1459, g_loss: -0.6297\n",
      "Epoch [81/300], Step [1800/1875], d_loss: -0.0770, g_loss: -0.2052\n",
      "Epoch [82/300], Step [200/1875], d_loss: 0.0683, g_loss: 0.3448\n",
      "Epoch [82/300], Step [400/1875], d_loss: -0.1138, g_loss: 0.4273\n",
      "Epoch [82/300], Step [600/1875], d_loss: -0.3816, g_loss: -0.8823\n",
      "Epoch [82/300], Step [800/1875], d_loss: -0.1157, g_loss: 1.3742\n",
      "Epoch [82/300], Step [1000/1875], d_loss: 0.1472, g_loss: -1.2838\n",
      "Epoch [82/300], Step [1200/1875], d_loss: 0.0844, g_loss: 0.3605\n",
      "Epoch [82/300], Step [1400/1875], d_loss: -0.0212, g_loss: 0.1389\n",
      "Epoch [82/300], Step [1600/1875], d_loss: -0.0274, g_loss: -0.1285\n",
      "Epoch [82/300], Step [1800/1875], d_loss: 0.0178, g_loss: -0.1256\n",
      "Epoch [83/300], Step [200/1875], d_loss: -0.0063, g_loss: -0.0101\n",
      "Epoch [83/300], Step [400/1875], d_loss: -0.0846, g_loss: -0.2728\n",
      "Epoch [83/300], Step [600/1875], d_loss: -0.0863, g_loss: 0.3245\n",
      "Epoch [83/300], Step [800/1875], d_loss: -0.0419, g_loss: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/300], Step [1000/1875], d_loss: -0.0176, g_loss: -0.0225\n",
      "Epoch [83/300], Step [1200/1875], d_loss: -0.0135, g_loss: -0.0360\n",
      "Epoch [83/300], Step [1400/1875], d_loss: -0.0245, g_loss: -0.0047\n",
      "Epoch [83/300], Step [1600/1875], d_loss: -0.0271, g_loss: 0.0156\n",
      "Epoch [83/300], Step [1800/1875], d_loss: -0.0182, g_loss: -0.0130\n",
      "Epoch [84/300], Step [200/1875], d_loss: 0.0065, g_loss: -0.0018\n",
      "Epoch [84/300], Step [400/1875], d_loss: -0.0234, g_loss: 0.0889\n",
      "Epoch [84/300], Step [600/1875], d_loss: -0.0432, g_loss: -0.0010\n",
      "Epoch [84/300], Step [800/1875], d_loss: -0.0541, g_loss: 0.0008\n",
      "Epoch [84/300], Step [1000/1875], d_loss: 0.0128, g_loss: 0.0351\n",
      "Epoch [84/300], Step [1200/1875], d_loss: -0.0276, g_loss: -0.0542\n",
      "Epoch [84/300], Step [1400/1875], d_loss: -0.0420, g_loss: 0.0059\n",
      "Epoch [84/300], Step [1600/1875], d_loss: -0.0345, g_loss: 0.0380\n",
      "Epoch [84/300], Step [1800/1875], d_loss: -0.0221, g_loss: -0.0114\n",
      "Epoch [85/300], Step [200/1875], d_loss: -0.0870, g_loss: -0.0183\n",
      "Epoch [85/300], Step [400/1875], d_loss: 0.0020, g_loss: -0.1036\n",
      "Epoch [85/300], Step [600/1875], d_loss: -0.0873, g_loss: -0.0114\n",
      "Epoch [85/300], Step [800/1875], d_loss: -0.0147, g_loss: 0.0192\n",
      "Epoch [85/300], Step [1000/1875], d_loss: -0.0149, g_loss: 0.0956\n",
      "Epoch [85/300], Step [1200/1875], d_loss: 0.0546, g_loss: -0.1145\n",
      "Epoch [85/300], Step [1400/1875], d_loss: -0.0623, g_loss: -0.0837\n",
      "Epoch [85/300], Step [1600/1875], d_loss: -0.1326, g_loss: -0.0760\n",
      "Epoch [85/300], Step [1800/1875], d_loss: 0.0740, g_loss: 0.0567\n",
      "Epoch [86/300], Step [200/1875], d_loss: 0.0186, g_loss: -0.0359\n",
      "Epoch [86/300], Step [400/1875], d_loss: -0.0939, g_loss: 0.2870\n",
      "Epoch [86/300], Step [600/1875], d_loss: 0.0608, g_loss: -0.1638\n",
      "Epoch [86/300], Step [800/1875], d_loss: -0.0011, g_loss: 0.0106\n",
      "Epoch [86/300], Step [1000/1875], d_loss: -0.1900, g_loss: 0.3072\n",
      "Epoch [86/300], Step [1200/1875], d_loss: 0.1903, g_loss: -0.2706\n",
      "Epoch [86/300], Step [1400/1875], d_loss: 0.0386, g_loss: -0.0021\n",
      "Epoch [86/300], Step [1600/1875], d_loss: -0.0968, g_loss: -0.0069\n",
      "Epoch [86/300], Step [1800/1875], d_loss: -0.0930, g_loss: 0.1601\n",
      "Epoch [87/300], Step [200/1875], d_loss: 0.0520, g_loss: 0.0184\n",
      "Epoch [87/300], Step [400/1875], d_loss: -0.0098, g_loss: -0.0097\n",
      "Epoch [87/300], Step [600/1875], d_loss: -0.0188, g_loss: -0.0727\n",
      "Epoch [87/300], Step [800/1875], d_loss: -0.0580, g_loss: -0.0094\n",
      "Epoch [87/300], Step [1000/1875], d_loss: -0.0826, g_loss: -0.0407\n",
      "Epoch [87/300], Step [1200/1875], d_loss: -0.0104, g_loss: 0.1710\n",
      "Epoch [87/300], Step [1400/1875], d_loss: -0.0992, g_loss: -0.1066\n",
      "Epoch [87/300], Step [1600/1875], d_loss: 0.0995, g_loss: 0.0558\n",
      "Epoch [87/300], Step [1800/1875], d_loss: -0.0060, g_loss: -0.0159\n",
      "Epoch [88/300], Step [200/1875], d_loss: 0.0016, g_loss: 0.2116\n",
      "Epoch [88/300], Step [400/1875], d_loss: 0.0169, g_loss: -0.1547\n",
      "Epoch [88/300], Step [600/1875], d_loss: -0.0451, g_loss: -0.0926\n",
      "Epoch [88/300], Step [800/1875], d_loss: -0.0179, g_loss: 0.0189\n",
      "Epoch [88/300], Step [1000/1875], d_loss: -0.0387, g_loss: -0.0906\n",
      "Epoch [88/300], Step [1200/1875], d_loss: -0.0422, g_loss: -0.0020\n",
      "Epoch [88/300], Step [1400/1875], d_loss: -0.0468, g_loss: 0.0146\n",
      "Epoch [88/300], Step [1600/1875], d_loss: -0.0425, g_loss: -0.1107\n",
      "Epoch [88/300], Step [1800/1875], d_loss: 0.0124, g_loss: 0.0258\n",
      "Epoch [89/300], Step [200/1875], d_loss: -0.0684, g_loss: 0.0184\n",
      "Epoch [89/300], Step [400/1875], d_loss: 0.0064, g_loss: -0.0820\n",
      "Epoch [89/300], Step [600/1875], d_loss: -0.0671, g_loss: -0.0288\n",
      "Epoch [89/300], Step [800/1875], d_loss: -0.0157, g_loss: -0.0750\n",
      "Epoch [89/300], Step [1000/1875], d_loss: -0.0093, g_loss: -0.0275\n",
      "Epoch [89/300], Step [1200/1875], d_loss: -0.0422, g_loss: 0.0780\n",
      "Epoch [89/300], Step [1400/1875], d_loss: -0.0596, g_loss: -0.0727\n",
      "Epoch [89/300], Step [1600/1875], d_loss: -0.0292, g_loss: 0.0410\n",
      "Epoch [89/300], Step [1800/1875], d_loss: -0.0117, g_loss: 0.0541\n",
      "Epoch [90/300], Step [200/1875], d_loss: -0.0331, g_loss: 0.0234\n",
      "Epoch [90/300], Step [400/1875], d_loss: -0.0845, g_loss: 0.0349\n",
      "Epoch [90/300], Step [600/1875], d_loss: 0.0120, g_loss: -0.0592\n",
      "Epoch [90/300], Step [800/1875], d_loss: -0.0689, g_loss: 0.0733\n",
      "Epoch [90/300], Step [1000/1875], d_loss: -0.0200, g_loss: -0.1986\n",
      "Epoch [90/300], Step [1200/1875], d_loss: -0.0449, g_loss: -0.0527\n",
      "Epoch [90/300], Step [1400/1875], d_loss: -0.0690, g_loss: 0.1945\n",
      "Epoch [90/300], Step [1600/1875], d_loss: -0.0253, g_loss: -0.0301\n",
      "Epoch [90/300], Step [1800/1875], d_loss: -0.1300, g_loss: 0.0252\n",
      "Epoch [91/300], Step [200/1875], d_loss: -0.0291, g_loss: 0.0906\n",
      "Epoch [91/300], Step [400/1875], d_loss: -0.0569, g_loss: -0.0648\n",
      "Epoch [91/300], Step [600/1875], d_loss: -0.0159, g_loss: 0.0924\n",
      "Epoch [91/300], Step [800/1875], d_loss: -0.0051, g_loss: -0.0528\n",
      "Epoch [91/300], Step [1000/1875], d_loss: -0.0433, g_loss: -0.0391\n",
      "Epoch [91/300], Step [1200/1875], d_loss: -0.0880, g_loss: 0.0848\n",
      "Epoch [91/300], Step [1400/1875], d_loss: -0.0480, g_loss: -0.1563\n",
      "Epoch [91/300], Step [1600/1875], d_loss: -0.0141, g_loss: 0.0125\n",
      "Epoch [91/300], Step [1800/1875], d_loss: -0.0870, g_loss: -0.0492\n",
      "Epoch [92/300], Step [200/1875], d_loss: -0.0413, g_loss: 0.0542\n",
      "Epoch [92/300], Step [400/1875], d_loss: -0.0308, g_loss: -0.0509\n",
      "Epoch [92/300], Step [600/1875], d_loss: 0.0167, g_loss: 0.0243\n",
      "Epoch [92/300], Step [800/1875], d_loss: -0.0273, g_loss: -0.0326\n",
      "Epoch [92/300], Step [1000/1875], d_loss: -0.0801, g_loss: 0.0217\n",
      "Epoch [92/300], Step [1200/1875], d_loss: -0.0316, g_loss: -0.0170\n",
      "Epoch [92/300], Step [1400/1875], d_loss: -0.0694, g_loss: 0.0132\n",
      "Epoch [92/300], Step [1600/1875], d_loss: -0.0371, g_loss: -0.0415\n",
      "Epoch [92/300], Step [1800/1875], d_loss: 0.0205, g_loss: 0.0212\n",
      "Epoch [93/300], Step [200/1875], d_loss: -0.0140, g_loss: 0.0536\n",
      "Epoch [93/300], Step [400/1875], d_loss: -0.0174, g_loss: -0.1118\n",
      "Epoch [93/300], Step [600/1875], d_loss: -0.0728, g_loss: 0.1347\n",
      "Epoch [93/300], Step [800/1875], d_loss: -0.0189, g_loss: -0.1588\n",
      "Epoch [93/300], Step [1000/1875], d_loss: -0.0116, g_loss: 0.0311\n",
      "Epoch [93/300], Step [1200/1875], d_loss: -0.0822, g_loss: 0.1089\n",
      "Epoch [93/300], Step [1400/1875], d_loss: -0.0846, g_loss: -0.0839\n",
      "Epoch [93/300], Step [1600/1875], d_loss: -0.0280, g_loss: 0.1237\n",
      "Epoch [93/300], Step [1800/1875], d_loss: -0.0101, g_loss: -0.0864\n",
      "Epoch [94/300], Step [200/1875], d_loss: -0.0329, g_loss: -0.0108\n",
      "Epoch [94/300], Step [400/1875], d_loss: -0.1003, g_loss: 0.2725\n",
      "Epoch [94/300], Step [600/1875], d_loss: -0.0027, g_loss: -0.0275\n",
      "Epoch [94/300], Step [800/1875], d_loss: -0.0645, g_loss: -0.4232\n",
      "Epoch [94/300], Step [1000/1875], d_loss: -0.1030, g_loss: -0.1664\n",
      "Epoch [94/300], Step [1200/1875], d_loss: 0.0313, g_loss: 0.0348\n",
      "Epoch [94/300], Step [1400/1875], d_loss: 0.0347, g_loss: 0.7324\n",
      "Epoch [94/300], Step [1600/1875], d_loss: -0.1789, g_loss: 0.7305\n",
      "Epoch [94/300], Step [1800/1875], d_loss: 0.1518, g_loss: -0.9916\n",
      "Epoch [95/300], Step [200/1875], d_loss: -0.0407, g_loss: -0.9217\n",
      "Epoch [95/300], Step [400/1875], d_loss: 0.0182, g_loss: 0.0944\n",
      "Epoch [95/300], Step [600/1875], d_loss: -0.1572, g_loss: 0.4370\n",
      "Epoch [95/300], Step [800/1875], d_loss: -0.2189, g_loss: -0.6258\n",
      "Epoch [95/300], Step [1000/1875], d_loss: 0.0177, g_loss: 0.8663\n",
      "Epoch [95/300], Step [1200/1875], d_loss: 0.1765, g_loss: -0.3484\n",
      "Epoch [95/300], Step [1400/1875], d_loss: -0.0430, g_loss: -0.0369\n",
      "Epoch [95/300], Step [1600/1875], d_loss: -0.2692, g_loss: 0.8729\n",
      "Epoch [95/300], Step [1800/1875], d_loss: -0.2212, g_loss: -0.6703\n",
      "Epoch [96/300], Step [200/1875], d_loss: -0.0377, g_loss: -0.0462\n",
      "Epoch [96/300], Step [400/1875], d_loss: -0.1683, g_loss: 0.3795\n",
      "Epoch [96/300], Step [600/1875], d_loss: -0.0654, g_loss: -0.0943\n",
      "Epoch [96/300], Step [800/1875], d_loss: -0.0651, g_loss: 0.1435\n",
      "Epoch [96/300], Step [1000/1875], d_loss: -0.0216, g_loss: -0.0906\n",
      "Epoch [96/300], Step [1200/1875], d_loss: -0.0139, g_loss: 0.0408\n",
      "Epoch [96/300], Step [1400/1875], d_loss: -0.0024, g_loss: -0.0093\n",
      "Epoch [96/300], Step [1600/1875], d_loss: -0.0474, g_loss: -0.1043\n",
      "Epoch [96/300], Step [1800/1875], d_loss: -0.0071, g_loss: 0.0756\n",
      "Epoch [97/300], Step [200/1875], d_loss: -0.0547, g_loss: 0.0298\n",
      "Epoch [97/300], Step [400/1875], d_loss: -0.0836, g_loss: -0.0624\n",
      "Epoch [97/300], Step [600/1875], d_loss: -0.0470, g_loss: -0.0271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/300], Step [800/1875], d_loss: -0.0575, g_loss: 0.0268\n",
      "Epoch [97/300], Step [1000/1875], d_loss: -0.0901, g_loss: 0.0194\n",
      "Epoch [97/300], Step [1200/1875], d_loss: -0.0646, g_loss: -0.0311\n",
      "Epoch [97/300], Step [1400/1875], d_loss: -0.0853, g_loss: -0.0783\n",
      "Epoch [97/300], Step [1600/1875], d_loss: -0.0747, g_loss: 0.1442\n",
      "Epoch [97/300], Step [1800/1875], d_loss: -0.0158, g_loss: -0.2054\n",
      "Epoch [98/300], Step [200/1875], d_loss: -0.0200, g_loss: -0.0507\n",
      "Epoch [98/300], Step [400/1875], d_loss: -0.0330, g_loss: 0.0578\n",
      "Epoch [98/300], Step [600/1875], d_loss: -0.0483, g_loss: -0.0477\n",
      "Epoch [98/300], Step [800/1875], d_loss: -0.0477, g_loss: -0.1173\n",
      "Epoch [98/300], Step [1000/1875], d_loss: -0.0200, g_loss: 0.0010\n",
      "Epoch [98/300], Step [1200/1875], d_loss: -0.0734, g_loss: -0.1000\n",
      "Epoch [98/300], Step [1400/1875], d_loss: 0.0039, g_loss: 0.0098\n",
      "Epoch [98/300], Step [1600/1875], d_loss: -0.0602, g_loss: 0.2958\n",
      "Epoch [98/300], Step [1800/1875], d_loss: -0.1335, g_loss: 0.3949\n",
      "Epoch [99/300], Step [200/1875], d_loss: -0.1378, g_loss: 0.7357\n",
      "Epoch [99/300], Step [400/1875], d_loss: -0.0290, g_loss: 0.2298\n",
      "Epoch [99/300], Step [600/1875], d_loss: -0.1341, g_loss: -0.6939\n",
      "Epoch [99/300], Step [800/1875], d_loss: 0.0806, g_loss: 0.0573\n",
      "Epoch [99/300], Step [1000/1875], d_loss: -0.1279, g_loss: 0.6979\n",
      "Epoch [99/300], Step [1200/1875], d_loss: -0.1584, g_loss: -0.6934\n",
      "Epoch [99/300], Step [1400/1875], d_loss: 0.1710, g_loss: 0.3835\n",
      "Epoch [99/300], Step [1600/1875], d_loss: -0.0594, g_loss: 0.2239\n",
      "Epoch [99/300], Step [1800/1875], d_loss: -0.3947, g_loss: -0.5802\n",
      "Epoch [100/300], Step [200/1875], d_loss: -0.0169, g_loss: -0.0226\n",
      "Epoch [100/300], Step [400/1875], d_loss: -0.0501, g_loss: 0.3192\n",
      "Epoch [100/300], Step [600/1875], d_loss: -0.2327, g_loss: -0.2376\n",
      "Epoch [100/300], Step [800/1875], d_loss: -0.2186, g_loss: 0.4466\n",
      "Epoch [100/300], Step [1000/1875], d_loss: -0.0899, g_loss: -0.1546\n",
      "Epoch [100/300], Step [1200/1875], d_loss: -0.0165, g_loss: -0.0127\n",
      "Epoch [100/300], Step [1400/1875], d_loss: 0.0052, g_loss: -0.0243\n",
      "Epoch [100/300], Step [1600/1875], d_loss: -0.0153, g_loss: -0.0228\n",
      "Epoch [100/300], Step [1800/1875], d_loss: -0.0157, g_loss: -0.0338\n",
      "Epoch [101/300], Step [200/1875], d_loss: -0.0537, g_loss: -0.0261\n",
      "Epoch [101/300], Step [400/1875], d_loss: 0.0037, g_loss: -0.0080\n",
      "Epoch [101/300], Step [600/1875], d_loss: -0.0260, g_loss: 0.0323\n",
      "Epoch [101/300], Step [800/1875], d_loss: -0.0625, g_loss: 0.0055\n",
      "Epoch [101/300], Step [1000/1875], d_loss: 0.0082, g_loss: 0.0015\n",
      "Epoch [101/300], Step [1200/1875], d_loss: -0.0455, g_loss: 0.0050\n",
      "Epoch [101/300], Step [1400/1875], d_loss: -0.0055, g_loss: 0.0973\n",
      "Epoch [101/300], Step [1600/1875], d_loss: -0.0263, g_loss: -0.0516\n",
      "Epoch [101/300], Step [1800/1875], d_loss: -0.0954, g_loss: -0.0298\n",
      "Epoch [102/300], Step [200/1875], d_loss: 0.0020, g_loss: -0.0007\n",
      "Epoch [102/300], Step [400/1875], d_loss: 0.0258, g_loss: -0.0787\n",
      "Epoch [102/300], Step [600/1875], d_loss: -0.0284, g_loss: -0.0628\n",
      "Epoch [102/300], Step [800/1875], d_loss: -0.0437, g_loss: 0.1034\n",
      "Epoch [102/300], Step [1000/1875], d_loss: 0.0657, g_loss: -0.0433\n",
      "Epoch [102/300], Step [1200/1875], d_loss: -0.0035, g_loss: 0.0058\n",
      "Epoch [102/300], Step [1400/1875], d_loss: -0.0662, g_loss: -0.0600\n",
      "Epoch [102/300], Step [1600/1875], d_loss: -0.0235, g_loss: 0.0742\n",
      "Epoch [102/300], Step [1800/1875], d_loss: -0.0895, g_loss: -0.0498\n",
      "Epoch [103/300], Step [200/1875], d_loss: -0.0480, g_loss: -0.0023\n",
      "Epoch [103/300], Step [400/1875], d_loss: -0.0162, g_loss: -0.0609\n",
      "Epoch [103/300], Step [600/1875], d_loss: -0.0769, g_loss: 0.0747\n",
      "Epoch [103/300], Step [800/1875], d_loss: -0.0348, g_loss: -0.0883\n",
      "Epoch [103/300], Step [1000/1875], d_loss: -0.0461, g_loss: 0.0822\n",
      "Epoch [103/300], Step [1200/1875], d_loss: -0.0205, g_loss: -0.1518\n",
      "Epoch [103/300], Step [1400/1875], d_loss: -0.0192, g_loss: 0.0441\n",
      "Epoch [103/300], Step [1600/1875], d_loss: 0.0056, g_loss: -0.0056\n",
      "Epoch [103/300], Step [1800/1875], d_loss: -0.0718, g_loss: -0.0125\n",
      "Epoch [104/300], Step [200/1875], d_loss: -0.0478, g_loss: 0.0472\n",
      "Epoch [104/300], Step [400/1875], d_loss: -0.0291, g_loss: -0.0491\n",
      "Epoch [104/300], Step [600/1875], d_loss: -0.0544, g_loss: 0.0607\n",
      "Epoch [104/300], Step [800/1875], d_loss: 0.0021, g_loss: -0.0027\n",
      "Epoch [104/300], Step [1000/1875], d_loss: -0.0669, g_loss: 0.0376\n",
      "Epoch [104/300], Step [1200/1875], d_loss: -0.0546, g_loss: -0.0323\n",
      "Epoch [104/300], Step [1400/1875], d_loss: -0.0512, g_loss: -0.0418\n",
      "Epoch [104/300], Step [1600/1875], d_loss: -0.0302, g_loss: -0.0171\n",
      "Epoch [104/300], Step [1800/1875], d_loss: -0.0616, g_loss: 0.0332\n",
      "Epoch [105/300], Step [200/1875], d_loss: -0.0048, g_loss: -0.0279\n",
      "Epoch [105/300], Step [400/1875], d_loss: -0.0278, g_loss: 0.1145\n",
      "Epoch [105/300], Step [600/1875], d_loss: -0.0367, g_loss: -0.1611\n",
      "Epoch [105/300], Step [800/1875], d_loss: -0.0327, g_loss: 0.0409\n",
      "Epoch [105/300], Step [1000/1875], d_loss: 0.0435, g_loss: -0.1254\n",
      "Epoch [105/300], Step [1200/1875], d_loss: -0.0766, g_loss: 0.0132\n",
      "Epoch [105/300], Step [1400/1875], d_loss: -0.0837, g_loss: 0.0259\n",
      "Epoch [105/300], Step [1600/1875], d_loss: -0.0130, g_loss: 0.0296\n",
      "Epoch [105/300], Step [1800/1875], d_loss: -0.0310, g_loss: -0.1227\n",
      "Epoch [106/300], Step [200/1875], d_loss: -0.0474, g_loss: -0.0287\n",
      "Epoch [106/300], Step [400/1875], d_loss: -0.0519, g_loss: 0.1108\n",
      "Epoch [106/300], Step [600/1875], d_loss: -0.0275, g_loss: -0.0610\n",
      "Epoch [106/300], Step [800/1875], d_loss: -0.0580, g_loss: -0.0337\n",
      "Epoch [106/300], Step [1000/1875], d_loss: -0.0054, g_loss: 0.0504\n",
      "Epoch [106/300], Step [1200/1875], d_loss: -0.0586, g_loss: -0.0601\n",
      "Epoch [106/300], Step [1400/1875], d_loss: -0.0895, g_loss: -0.0065\n",
      "Epoch [106/300], Step [1600/1875], d_loss: -0.0112, g_loss: -0.0234\n",
      "Epoch [106/300], Step [1800/1875], d_loss: -0.0586, g_loss: 0.0724\n",
      "Epoch [107/300], Step [200/1875], d_loss: 0.0575, g_loss: -0.1304\n",
      "Epoch [107/300], Step [400/1875], d_loss: -0.0217, g_loss: 0.0563\n",
      "Epoch [107/300], Step [600/1875], d_loss: -0.0463, g_loss: 0.0636\n",
      "Epoch [107/300], Step [800/1875], d_loss: -0.0447, g_loss: 0.0861\n",
      "Epoch [107/300], Step [1000/1875], d_loss: 0.0499, g_loss: -0.2669\n",
      "Epoch [107/300], Step [1200/1875], d_loss: -0.1019, g_loss: 0.0242\n",
      "Epoch [107/300], Step [1400/1875], d_loss: 0.0706, g_loss: -0.1116\n",
      "Epoch [107/300], Step [1600/1875], d_loss: -0.2600, g_loss: 0.4225\n",
      "Epoch [107/300], Step [1800/1875], d_loss: 0.1103, g_loss: -0.1875\n",
      "Epoch [108/300], Step [200/1875], d_loss: 0.2280, g_loss: -0.4079\n",
      "Epoch [108/300], Step [400/1875], d_loss: -0.0647, g_loss: -0.0492\n",
      "Epoch [108/300], Step [600/1875], d_loss: -0.0369, g_loss: 0.6754\n",
      "Epoch [108/300], Step [800/1875], d_loss: 0.0377, g_loss: -0.5884\n",
      "Epoch [108/300], Step [1000/1875], d_loss: -0.0200, g_loss: 0.4373\n",
      "Epoch [108/300], Step [1200/1875], d_loss: 0.0107, g_loss: -0.0242\n",
      "Epoch [108/300], Step [1400/1875], d_loss: -0.1804, g_loss: -0.2753\n",
      "Epoch [108/300], Step [1600/1875], d_loss: -0.0690, g_loss: 0.6990\n",
      "Epoch [108/300], Step [1800/1875], d_loss: 0.0708, g_loss: -0.5836\n",
      "Epoch [109/300], Step [200/1875], d_loss: -0.1885, g_loss: -0.5153\n",
      "Epoch [109/300], Step [400/1875], d_loss: 0.0748, g_loss: 0.6099\n",
      "Epoch [109/300], Step [600/1875], d_loss: 0.1663, g_loss: -0.4163\n",
      "Epoch [109/300], Step [800/1875], d_loss: 0.0532, g_loss: 0.0864\n",
      "Epoch [109/300], Step [1000/1875], d_loss: -0.0012, g_loss: 0.0125\n",
      "Epoch [109/300], Step [1200/1875], d_loss: -0.0455, g_loss: -0.0302\n",
      "Epoch [109/300], Step [1400/1875], d_loss: -0.0719, g_loss: 0.2584\n",
      "Epoch [109/300], Step [1600/1875], d_loss: -0.1572, g_loss: -0.3495\n",
      "Epoch [109/300], Step [1800/1875], d_loss: -0.0370, g_loss: 0.8765\n",
      "Epoch [110/300], Step [200/1875], d_loss: -0.0218, g_loss: 0.1747\n",
      "Epoch [110/300], Step [400/1875], d_loss: -0.2220, g_loss: -0.5269\n",
      "Epoch [110/300], Step [600/1875], d_loss: -0.0895, g_loss: 0.1982\n",
      "Epoch [110/300], Step [800/1875], d_loss: -0.0249, g_loss: -0.2763\n",
      "Epoch [110/300], Step [1000/1875], d_loss: -0.0386, g_loss: 0.1076\n",
      "Epoch [110/300], Step [1200/1875], d_loss: -0.0406, g_loss: 0.0313\n",
      "Epoch [110/300], Step [1400/1875], d_loss: 0.0041, g_loss: -0.2146\n",
      "Epoch [110/300], Step [1600/1875], d_loss: -0.0169, g_loss: 0.2613\n",
      "Epoch [110/300], Step [1800/1875], d_loss: 0.0142, g_loss: -0.1900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [111/300], Step [200/1875], d_loss: -0.0682, g_loss: 0.0614\n",
      "Epoch [111/300], Step [400/1875], d_loss: 0.0030, g_loss: 0.0444\n",
      "Epoch [111/300], Step [600/1875], d_loss: -0.0355, g_loss: -0.1205\n",
      "Epoch [111/300], Step [800/1875], d_loss: -0.0860, g_loss: -0.0301\n",
      "Epoch [111/300], Step [1000/1875], d_loss: -0.0584, g_loss: 0.0515\n",
      "Epoch [111/300], Step [1200/1875], d_loss: -0.0377, g_loss: -0.1768\n",
      "Epoch [111/300], Step [1400/1875], d_loss: 0.0290, g_loss: 0.0292\n",
      "Epoch [111/300], Step [1600/1875], d_loss: -0.0107, g_loss: -0.0085\n",
      "Epoch [111/300], Step [1800/1875], d_loss: -0.0290, g_loss: 0.1144\n",
      "Epoch [112/300], Step [200/1875], d_loss: -0.0668, g_loss: -0.0045\n",
      "Epoch [112/300], Step [400/1875], d_loss: -0.0220, g_loss: 0.0150\n",
      "Epoch [112/300], Step [600/1875], d_loss: -0.0150, g_loss: -0.1410\n",
      "Epoch [112/300], Step [800/1875], d_loss: -0.0541, g_loss: 0.1140\n",
      "Epoch [112/300], Step [1000/1875], d_loss: -0.0248, g_loss: -0.1065\n",
      "Epoch [112/300], Step [1200/1875], d_loss: -0.0462, g_loss: 0.1244\n",
      "Epoch [112/300], Step [1400/1875], d_loss: -0.0481, g_loss: -0.0501\n",
      "Epoch [112/300], Step [1600/1875], d_loss: -0.0125, g_loss: -0.0227\n",
      "Epoch [112/300], Step [1800/1875], d_loss: -0.0720, g_loss: -0.0031\n",
      "Epoch [113/300], Step [200/1875], d_loss: 0.0290, g_loss: -0.0208\n",
      "Epoch [113/300], Step [400/1875], d_loss: -0.0398, g_loss: 0.0757\n",
      "Epoch [113/300], Step [600/1875], d_loss: -0.0327, g_loss: -0.0747\n",
      "Epoch [113/300], Step [800/1875], d_loss: 0.0241, g_loss: -0.0302\n",
      "Epoch [113/300], Step [1000/1875], d_loss: -0.0524, g_loss: 0.0100\n",
      "Epoch [113/300], Step [1200/1875], d_loss: 0.0666, g_loss: 0.0542\n",
      "Epoch [113/300], Step [1400/1875], d_loss: -0.0121, g_loss: -0.0547\n",
      "Epoch [113/300], Step [1600/1875], d_loss: -0.0333, g_loss: -0.0013\n",
      "Epoch [113/300], Step [1800/1875], d_loss: -0.0340, g_loss: 0.1085\n",
      "Epoch [114/300], Step [200/1875], d_loss: -0.0587, g_loss: 0.3111\n",
      "Epoch [114/300], Step [400/1875], d_loss: 0.1572, g_loss: -0.3496\n",
      "Epoch [114/300], Step [600/1875], d_loss: -0.1320, g_loss: -0.0164\n",
      "Epoch [114/300], Step [800/1875], d_loss: 0.1504, g_loss: -0.0204\n",
      "Epoch [114/300], Step [1000/1875], d_loss: -0.0557, g_loss: 0.1771\n",
      "Epoch [114/300], Step [1200/1875], d_loss: -0.0366, g_loss: 0.0203\n",
      "Epoch [114/300], Step [1400/1875], d_loss: 0.0461, g_loss: 0.0019\n",
      "Epoch [114/300], Step [1600/1875], d_loss: -0.0341, g_loss: 0.0140\n",
      "Epoch [114/300], Step [1800/1875], d_loss: -0.1536, g_loss: 0.2923\n",
      "Epoch [115/300], Step [200/1875], d_loss: 0.0294, g_loss: -0.0932\n",
      "Epoch [115/300], Step [400/1875], d_loss: -0.0665, g_loss: -0.0817\n",
      "Epoch [115/300], Step [600/1875], d_loss: -0.0389, g_loss: 0.0000\n",
      "Epoch [115/300], Step [800/1875], d_loss: -0.0040, g_loss: 0.0414\n",
      "Epoch [115/300], Step [1000/1875], d_loss: 0.0054, g_loss: -0.0434\n",
      "Epoch [115/300], Step [1200/1875], d_loss: -0.0306, g_loss: -0.0709\n",
      "Epoch [115/300], Step [1400/1875], d_loss: -0.0231, g_loss: 0.0210\n",
      "Epoch [115/300], Step [1600/1875], d_loss: -0.0258, g_loss: -0.0944\n",
      "Epoch [115/300], Step [1800/1875], d_loss: -0.0102, g_loss: 0.0216\n",
      "Epoch [116/300], Step [200/1875], d_loss: -0.0315, g_loss: -0.0044\n",
      "Epoch [116/300], Step [400/1875], d_loss: -0.0596, g_loss: 0.0575\n",
      "Epoch [116/300], Step [600/1875], d_loss: -0.0082, g_loss: -0.0848\n",
      "Epoch [116/300], Step [800/1875], d_loss: -0.0577, g_loss: 0.0818\n",
      "Epoch [116/300], Step [1000/1875], d_loss: -0.0275, g_loss: -0.0214\n",
      "Epoch [116/300], Step [1200/1875], d_loss: -0.0475, g_loss: -0.0085\n",
      "Epoch [116/300], Step [1400/1875], d_loss: -0.0215, g_loss: -0.0432\n",
      "Epoch [116/300], Step [1600/1875], d_loss: -0.0065, g_loss: 0.0581\n",
      "Epoch [116/300], Step [1800/1875], d_loss: -0.0343, g_loss: -0.0462\n",
      "Epoch [117/300], Step [200/1875], d_loss: 0.0148, g_loss: 0.1354\n",
      "Epoch [117/300], Step [400/1875], d_loss: -0.0427, g_loss: -0.1488\n",
      "Epoch [117/300], Step [600/1875], d_loss: 0.0054, g_loss: 0.1851\n",
      "Epoch [117/300], Step [800/1875], d_loss: -0.0569, g_loss: -0.1856\n",
      "Epoch [117/300], Step [1000/1875], d_loss: 0.0123, g_loss: 0.1020\n",
      "Epoch [117/300], Step [1200/1875], d_loss: -0.0006, g_loss: -0.0832\n",
      "Epoch [117/300], Step [1400/1875], d_loss: -0.0512, g_loss: 0.0547\n",
      "Epoch [117/300], Step [1600/1875], d_loss: -0.0508, g_loss: -0.0216\n",
      "Epoch [117/300], Step [1800/1875], d_loss: -0.0161, g_loss: 0.0556\n",
      "Epoch [118/300], Step [200/1875], d_loss: -0.0120, g_loss: -0.1234\n",
      "Epoch [118/300], Step [400/1875], d_loss: -0.0203, g_loss: 0.1378\n",
      "Epoch [118/300], Step [600/1875], d_loss: -0.0444, g_loss: -0.1070\n",
      "Epoch [118/300], Step [800/1875], d_loss: -0.0338, g_loss: 0.0396\n",
      "Epoch [118/300], Step [1000/1875], d_loss: 0.0047, g_loss: -0.0928\n",
      "Epoch [118/300], Step [1200/1875], d_loss: -0.0741, g_loss: -0.0086\n",
      "Epoch [118/300], Step [1400/1875], d_loss: 0.0125, g_loss: -0.1395\n",
      "Epoch [118/300], Step [1600/1875], d_loss: -0.1351, g_loss: 0.0653\n",
      "Epoch [118/300], Step [1800/1875], d_loss: -0.0214, g_loss: 0.0015\n",
      "Epoch [119/300], Step [200/1875], d_loss: -0.0478, g_loss: 0.0532\n",
      "Epoch [119/300], Step [400/1875], d_loss: -0.0822, g_loss: 0.0548\n",
      "Epoch [119/300], Step [600/1875], d_loss: -0.0736, g_loss: -0.1378\n",
      "Epoch [119/300], Step [800/1875], d_loss: 0.0177, g_loss: 0.0469\n",
      "Epoch [119/300], Step [1000/1875], d_loss: -0.0683, g_loss: -0.0325\n",
      "Epoch [119/300], Step [1200/1875], d_loss: 0.0189, g_loss: -0.0963\n",
      "Epoch [119/300], Step [1400/1875], d_loss: -0.0519, g_loss: 0.0048\n",
      "Epoch [119/300], Step [1600/1875], d_loss: 0.0676, g_loss: -0.0402\n",
      "Epoch [119/300], Step [1800/1875], d_loss: -0.1206, g_loss: 0.1290\n",
      "Epoch [120/300], Step [200/1875], d_loss: -0.0716, g_loss: -0.0307\n",
      "Epoch [120/300], Step [400/1875], d_loss: -0.0512, g_loss: -0.0564\n",
      "Epoch [120/300], Step [600/1875], d_loss: -0.0267, g_loss: 0.2013\n",
      "Epoch [120/300], Step [800/1875], d_loss: 0.0124, g_loss: 0.0055\n",
      "Epoch [120/300], Step [1000/1875], d_loss: -0.0912, g_loss: -0.0648\n",
      "Epoch [120/300], Step [1200/1875], d_loss: -0.0947, g_loss: 0.4737\n",
      "Epoch [120/300], Step [1400/1875], d_loss: 0.1223, g_loss: -0.5742\n",
      "Epoch [120/300], Step [1600/1875], d_loss: 0.0370, g_loss: 0.1277\n",
      "Epoch [120/300], Step [1800/1875], d_loss: -0.1197, g_loss: 0.1922\n",
      "Epoch [121/300], Step [200/1875], d_loss: 0.0850, g_loss: -0.1216\n",
      "Epoch [121/300], Step [400/1875], d_loss: -0.1620, g_loss: -0.2005\n",
      "Epoch [121/300], Step [600/1875], d_loss: -0.1195, g_loss: 0.4022\n",
      "Epoch [121/300], Step [800/1875], d_loss: 0.0196, g_loss: -0.5477\n",
      "Epoch [121/300], Step [1000/1875], d_loss: 0.1221, g_loss: 0.2290\n",
      "Epoch [121/300], Step [1200/1875], d_loss: -0.0273, g_loss: 0.0450\n",
      "Epoch [121/300], Step [1400/1875], d_loss: -0.2307, g_loss: -0.3566\n",
      "Epoch [121/300], Step [1600/1875], d_loss: -0.0779, g_loss: 0.2751\n",
      "Epoch [121/300], Step [1800/1875], d_loss: -0.1520, g_loss: -0.4270\n",
      "Epoch [122/300], Step [200/1875], d_loss: 0.0169, g_loss: 0.0729\n",
      "Epoch [122/300], Step [400/1875], d_loss: 0.0050, g_loss: -0.0021\n",
      "Epoch [122/300], Step [600/1875], d_loss: -0.0488, g_loss: -0.0072\n",
      "Epoch [122/300], Step [800/1875], d_loss: -0.0555, g_loss: -0.1995\n",
      "Epoch [122/300], Step [1000/1875], d_loss: -0.0718, g_loss: 0.3487\n",
      "Epoch [122/300], Step [1200/1875], d_loss: 0.0048, g_loss: -0.1743\n",
      "Epoch [122/300], Step [1400/1875], d_loss: -0.0116, g_loss: -0.1707\n",
      "Epoch [122/300], Step [1600/1875], d_loss: -0.0577, g_loss: 0.0063\n",
      "Epoch [122/300], Step [1800/1875], d_loss: -0.0519, g_loss: -0.0463\n",
      "Epoch [123/300], Step [200/1875], d_loss: -0.0501, g_loss: 0.0162\n",
      "Epoch [123/300], Step [400/1875], d_loss: -0.0591, g_loss: -0.0412\n",
      "Epoch [123/300], Step [600/1875], d_loss: -0.0090, g_loss: -0.0342\n",
      "Epoch [123/300], Step [800/1875], d_loss: -0.1167, g_loss: 0.0562\n",
      "Epoch [123/300], Step [1000/1875], d_loss: -0.0761, g_loss: -0.0632\n",
      "Epoch [123/300], Step [1200/1875], d_loss: -0.0307, g_loss: -0.0153\n",
      "Epoch [123/300], Step [1400/1875], d_loss: -0.0588, g_loss: 0.1268\n",
      "Epoch [123/300], Step [1600/1875], d_loss: 0.0097, g_loss: -0.1364\n",
      "Epoch [123/300], Step [1800/1875], d_loss: -0.0532, g_loss: 0.0384\n",
      "Epoch [124/300], Step [200/1875], d_loss: -0.0169, g_loss: -0.0485\n",
      "Epoch [124/300], Step [400/1875], d_loss: -0.0236, g_loss: -0.0093\n",
      "Epoch [124/300], Step [600/1875], d_loss: 0.0127, g_loss: -0.0375\n",
      "Epoch [124/300], Step [800/1875], d_loss: -0.0331, g_loss: 0.0486\n",
      "Epoch [124/300], Step [1000/1875], d_loss: -0.0742, g_loss: 0.0589\n",
      "Epoch [124/300], Step [1200/1875], d_loss: -0.0218, g_loss: -0.0672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [124/300], Step [1400/1875], d_loss: -0.0077, g_loss: 0.0317\n",
      "Epoch [124/300], Step [1600/1875], d_loss: -0.1124, g_loss: 0.0435\n",
      "Epoch [124/300], Step [1800/1875], d_loss: 0.0168, g_loss: -0.0082\n",
      "Epoch [125/300], Step [200/1875], d_loss: -0.0220, g_loss: 0.0080\n",
      "Epoch [125/300], Step [400/1875], d_loss: -0.0195, g_loss: 0.0348\n",
      "Epoch [125/300], Step [600/1875], d_loss: -0.0417, g_loss: -0.1070\n",
      "Epoch [125/300], Step [800/1875], d_loss: -0.0669, g_loss: 0.0964\n",
      "Epoch [125/300], Step [1000/1875], d_loss: 0.0701, g_loss: -0.0815\n",
      "Epoch [125/300], Step [1200/1875], d_loss: -0.0358, g_loss: 0.0836\n",
      "Epoch [125/300], Step [1400/1875], d_loss: -0.1300, g_loss: 0.0466\n",
      "Epoch [125/300], Step [1600/1875], d_loss: 0.0854, g_loss: -0.1378\n",
      "Epoch [125/300], Step [1800/1875], d_loss: -0.0801, g_loss: 0.0641\n",
      "Epoch [126/300], Step [200/1875], d_loss: -0.0456, g_loss: -0.1038\n",
      "Epoch [126/300], Step [400/1875], d_loss: -0.0932, g_loss: 0.2440\n",
      "Epoch [126/300], Step [600/1875], d_loss: -0.0262, g_loss: -0.0691\n",
      "Epoch [126/300], Step [800/1875], d_loss: -0.0407, g_loss: -0.0783\n",
      "Epoch [126/300], Step [1000/1875], d_loss: -0.0383, g_loss: 0.0736\n",
      "Epoch [126/300], Step [1200/1875], d_loss: -0.0070, g_loss: -0.1024\n",
      "Epoch [126/300], Step [1400/1875], d_loss: -0.0052, g_loss: 0.0675\n",
      "Epoch [126/300], Step [1600/1875], d_loss: -0.0179, g_loss: -0.0420\n",
      "Epoch [126/300], Step [1800/1875], d_loss: -0.0190, g_loss: -0.0327\n",
      "Epoch [127/300], Step [200/1875], d_loss: -0.0143, g_loss: -0.0104\n",
      "Epoch [127/300], Step [400/1875], d_loss: -0.0475, g_loss: -0.0265\n",
      "Epoch [127/300], Step [600/1875], d_loss: -0.0255, g_loss: 0.0307\n",
      "Epoch [127/300], Step [800/1875], d_loss: -0.0447, g_loss: -0.0979\n",
      "Epoch [127/300], Step [1000/1875], d_loss: -0.0633, g_loss: 0.0568\n",
      "Epoch [127/300], Step [1200/1875], d_loss: -0.0076, g_loss: 0.0378\n",
      "Epoch [127/300], Step [1400/1875], d_loss: -0.1086, g_loss: -0.0817\n",
      "Epoch [127/300], Step [1600/1875], d_loss: 0.0389, g_loss: -0.0189\n",
      "Epoch [127/300], Step [1800/1875], d_loss: -0.0264, g_loss: -0.0124\n",
      "Epoch [128/300], Step [200/1875], d_loss: -0.0261, g_loss: 0.0583\n",
      "Epoch [128/300], Step [400/1875], d_loss: -0.0679, g_loss: 0.0019\n",
      "Epoch [128/300], Step [600/1875], d_loss: -0.0812, g_loss: 0.2542\n",
      "Epoch [128/300], Step [800/1875], d_loss: -0.0119, g_loss: -0.1443\n",
      "Epoch [128/300], Step [1000/1875], d_loss: -0.0302, g_loss: 0.0593\n",
      "Epoch [128/300], Step [1200/1875], d_loss: 0.0277, g_loss: -0.0885\n",
      "Epoch [128/300], Step [1400/1875], d_loss: -0.0515, g_loss: 0.1352\n",
      "Epoch [128/300], Step [1600/1875], d_loss: 0.0471, g_loss: -0.1753\n",
      "Epoch [128/300], Step [1800/1875], d_loss: -0.1890, g_loss: -0.0917\n",
      "Epoch [129/300], Step [200/1875], d_loss: -0.0994, g_loss: -0.5106\n",
      "Epoch [129/300], Step [400/1875], d_loss: -0.1524, g_loss: -0.1748\n",
      "Epoch [129/300], Step [600/1875], d_loss: 0.1270, g_loss: 0.3428\n",
      "Epoch [129/300], Step [800/1875], d_loss: -0.3370, g_loss: 0.8606\n",
      "Epoch [129/300], Step [1000/1875], d_loss: 0.1760, g_loss: -0.9387\n",
      "Epoch [129/300], Step [1200/1875], d_loss: -0.1871, g_loss: -0.2097\n",
      "Epoch [129/300], Step [1400/1875], d_loss: 0.0857, g_loss: 0.8215\n",
      "Epoch [129/300], Step [1600/1875], d_loss: 0.2182, g_loss: -0.9258\n",
      "Epoch [129/300], Step [1800/1875], d_loss: 0.1036, g_loss: 0.1657\n",
      "Epoch [130/300], Step [200/1875], d_loss: 0.0285, g_loss: 0.9996\n",
      "Epoch [130/300], Step [400/1875], d_loss: 0.2230, g_loss: -1.1128\n",
      "Epoch [130/300], Step [600/1875], d_loss: 0.3127, g_loss: 0.3596\n",
      "Epoch [130/300], Step [800/1875], d_loss: 0.0004, g_loss: 0.0115\n",
      "Epoch [130/300], Step [1000/1875], d_loss: -0.0548, g_loss: -0.1435\n",
      "Epoch [130/300], Step [1200/1875], d_loss: -0.0368, g_loss: 0.1236\n",
      "Epoch [130/300], Step [1400/1875], d_loss: 0.0405, g_loss: 0.2068\n",
      "Epoch [130/300], Step [1600/1875], d_loss: 0.1293, g_loss: -0.6273\n",
      "Epoch [130/300], Step [1800/1875], d_loss: -0.0427, g_loss: 0.2103\n",
      "Epoch [131/300], Step [200/1875], d_loss: -0.0454, g_loss: -0.1118\n",
      "Epoch [131/300], Step [400/1875], d_loss: -0.0166, g_loss: -0.0984\n",
      "Epoch [131/300], Step [600/1875], d_loss: -0.0070, g_loss: 0.0292\n",
      "Epoch [131/300], Step [800/1875], d_loss: -0.0291, g_loss: 0.0081\n",
      "Epoch [131/300], Step [1000/1875], d_loss: -0.0261, g_loss: -0.0451\n",
      "Epoch [131/300], Step [1200/1875], d_loss: -0.0379, g_loss: 0.1285\n",
      "Epoch [131/300], Step [1400/1875], d_loss: -0.0629, g_loss: 0.0344\n",
      "Epoch [131/300], Step [1600/1875], d_loss: -0.1012, g_loss: -0.3537\n",
      "Epoch [131/300], Step [1800/1875], d_loss: 0.0026, g_loss: 0.2133\n",
      "Epoch [132/300], Step [200/1875], d_loss: -0.0443, g_loss: 0.2273\n",
      "Epoch [132/300], Step [400/1875], d_loss: 0.0527, g_loss: -0.2895\n",
      "Epoch [132/300], Step [600/1875], d_loss: 0.0081, g_loss: 0.0799\n",
      "Epoch [132/300], Step [800/1875], d_loss: 0.0016, g_loss: -0.0963\n",
      "Epoch [132/300], Step [1000/1875], d_loss: -0.0041, g_loss: -0.0363\n",
      "Epoch [132/300], Step [1200/1875], d_loss: -0.0454, g_loss: 0.0019\n",
      "Epoch [132/300], Step [1400/1875], d_loss: -0.0192, g_loss: -0.2074\n",
      "Epoch [132/300], Step [1600/1875], d_loss: 0.0245, g_loss: 0.0791\n",
      "Epoch [132/300], Step [1800/1875], d_loss: -0.0279, g_loss: 0.0488\n",
      "Epoch [133/300], Step [200/1875], d_loss: -0.0541, g_loss: -0.1688\n",
      "Epoch [133/300], Step [400/1875], d_loss: -0.0484, g_loss: 0.1132\n",
      "Epoch [133/300], Step [600/1875], d_loss: -0.0150, g_loss: -0.0229\n",
      "Epoch [133/300], Step [800/1875], d_loss: -0.0527, g_loss: -0.0208\n",
      "Epoch [133/300], Step [1000/1875], d_loss: 0.0099, g_loss: 0.0489\n",
      "Epoch [133/300], Step [1200/1875], d_loss: -0.0478, g_loss: -0.0026\n",
      "Epoch [133/300], Step [1400/1875], d_loss: -0.0164, g_loss: -0.0617\n",
      "Epoch [133/300], Step [1600/1875], d_loss: -0.0315, g_loss: 0.1070\n",
      "Epoch [133/300], Step [1800/1875], d_loss: -0.0094, g_loss: -0.0850\n",
      "Epoch [134/300], Step [200/1875], d_loss: -0.0276, g_loss: 0.0725\n",
      "Epoch [134/300], Step [400/1875], d_loss: -0.0284, g_loss: 0.0608\n",
      "Epoch [134/300], Step [600/1875], d_loss: -0.0205, g_loss: -0.0434\n",
      "Epoch [134/300], Step [800/1875], d_loss: -0.0292, g_loss: 0.0073\n",
      "Epoch [134/300], Step [1000/1875], d_loss: 0.0012, g_loss: 0.0307\n",
      "Epoch [134/300], Step [1200/1875], d_loss: -0.0281, g_loss: 0.0214\n",
      "Epoch [134/300], Step [1400/1875], d_loss: -0.0144, g_loss: 0.0245\n",
      "Epoch [134/300], Step [1600/1875], d_loss: -0.0156, g_loss: -0.0863\n",
      "Epoch [134/300], Step [1800/1875], d_loss: -0.0521, g_loss: 0.1131\n",
      "Epoch [135/300], Step [200/1875], d_loss: -0.0303, g_loss: -0.0608\n",
      "Epoch [135/300], Step [400/1875], d_loss: -0.0128, g_loss: 0.1820\n",
      "Epoch [135/300], Step [600/1875], d_loss: -0.0385, g_loss: -0.1515\n",
      "Epoch [135/300], Step [800/1875], d_loss: -0.0242, g_loss: 0.1629\n",
      "Epoch [135/300], Step [1000/1875], d_loss: -0.0268, g_loss: -0.0981\n",
      "Epoch [135/300], Step [1200/1875], d_loss: -0.1120, g_loss: -0.0135\n",
      "Epoch [135/300], Step [1400/1875], d_loss: -0.0039, g_loss: -0.0684\n",
      "Epoch [135/300], Step [1600/1875], d_loss: -0.0751, g_loss: -0.0118\n",
      "Epoch [135/300], Step [1800/1875], d_loss: -0.0491, g_loss: 0.0297\n",
      "Epoch [136/300], Step [200/1875], d_loss: -0.0111, g_loss: -0.1243\n",
      "Epoch [136/300], Step [400/1875], d_loss: -0.0636, g_loss: 0.0880\n",
      "Epoch [136/300], Step [600/1875], d_loss: -0.0205, g_loss: -0.0830\n",
      "Epoch [136/300], Step [800/1875], d_loss: -0.0158, g_loss: 0.0120\n",
      "Epoch [136/300], Step [1000/1875], d_loss: -0.0339, g_loss: -0.1333\n",
      "Epoch [136/300], Step [1200/1875], d_loss: -0.0006, g_loss: 0.0790\n",
      "Epoch [136/300], Step [1400/1875], d_loss: -0.0684, g_loss: 0.0693\n",
      "Epoch [136/300], Step [1600/1875], d_loss: 0.0019, g_loss: -0.0561\n",
      "Epoch [136/300], Step [1800/1875], d_loss: -0.0683, g_loss: -0.0322\n",
      "Epoch [137/300], Step [200/1875], d_loss: -0.0345, g_loss: 0.1022\n",
      "Epoch [137/300], Step [400/1875], d_loss: -0.0112, g_loss: -0.0271\n",
      "Epoch [137/300], Step [600/1875], d_loss: -0.0632, g_loss: 0.0116\n",
      "Epoch [137/300], Step [800/1875], d_loss: -0.0289, g_loss: 0.0652\n",
      "Epoch [137/300], Step [1000/1875], d_loss: -0.0167, g_loss: -0.0151\n",
      "Epoch [137/300], Step [1200/1875], d_loss: -0.0523, g_loss: 0.0403\n",
      "Epoch [137/300], Step [1400/1875], d_loss: -0.0201, g_loss: -0.0527\n",
      "Epoch [137/300], Step [1600/1875], d_loss: -0.1230, g_loss: 0.1099\n",
      "Epoch [137/300], Step [1800/1875], d_loss: 0.0170, g_loss: -0.0967\n",
      "Epoch [138/300], Step [200/1875], d_loss: -0.0417, g_loss: -0.0119\n",
      "Epoch [138/300], Step [400/1875], d_loss: 0.0385, g_loss: -0.0726\n",
      "Epoch [138/300], Step [600/1875], d_loss: -0.0530, g_loss: -0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [138/300], Step [800/1875], d_loss: 0.0265, g_loss: -0.0195\n",
      "Epoch [138/300], Step [1000/1875], d_loss: -0.0311, g_loss: 0.0092\n",
      "Epoch [138/300], Step [1200/1875], d_loss: -0.0265, g_loss: -0.1592\n",
      "Epoch [138/300], Step [1400/1875], d_loss: -0.0704, g_loss: 0.0691\n",
      "Epoch [138/300], Step [1600/1875], d_loss: 0.0061, g_loss: -0.1017\n",
      "Epoch [138/300], Step [1800/1875], d_loss: -0.1545, g_loss: 0.1878\n",
      "Epoch [139/300], Step [200/1875], d_loss: -0.1427, g_loss: 0.0856\n",
      "Epoch [139/300], Step [400/1875], d_loss: 0.0881, g_loss: 0.0582\n",
      "Epoch [139/300], Step [600/1875], d_loss: -0.1430, g_loss: 0.3451\n",
      "Epoch [139/300], Step [800/1875], d_loss: 0.0786, g_loss: -0.2921\n",
      "Epoch [139/300], Step [1000/1875], d_loss: -0.0212, g_loss: -0.0212\n",
      "Epoch [139/300], Step [1200/1875], d_loss: -0.0987, g_loss: 0.5308\n",
      "Epoch [139/300], Step [1400/1875], d_loss: 0.1434, g_loss: -0.4874\n",
      "Epoch [139/300], Step [1600/1875], d_loss: 0.0327, g_loss: 0.0739\n",
      "Epoch [139/300], Step [1800/1875], d_loss: 0.0125, g_loss: -0.1220\n",
      "Epoch [140/300], Step [200/1875], d_loss: -0.0100, g_loss: 0.0260\n",
      "Epoch [140/300], Step [400/1875], d_loss: -0.0019, g_loss: -0.0513\n",
      "Epoch [140/300], Step [600/1875], d_loss: -0.0580, g_loss: -0.0597\n",
      "Epoch [140/300], Step [800/1875], d_loss: -0.0298, g_loss: -0.0610\n",
      "Epoch [140/300], Step [1000/1875], d_loss: -0.0520, g_loss: -0.0193\n",
      "Epoch [140/300], Step [1200/1875], d_loss: -0.0666, g_loss: 0.0560\n",
      "Epoch [140/300], Step [1400/1875], d_loss: -0.0717, g_loss: -0.0081\n",
      "Epoch [140/300], Step [1600/1875], d_loss: 0.0036, g_loss: -0.0487\n",
      "Epoch [140/300], Step [1800/1875], d_loss: -0.0079, g_loss: 0.0278\n",
      "Epoch [141/300], Step [200/1875], d_loss: -0.0871, g_loss: 0.1833\n",
      "Epoch [141/300], Step [400/1875], d_loss: -0.0653, g_loss: 0.1668\n",
      "Epoch [141/300], Step [600/1875], d_loss: 0.0423, g_loss: -0.1730\n",
      "Epoch [141/300], Step [800/1875], d_loss: 0.0658, g_loss: -0.0803\n",
      "Epoch [141/300], Step [1000/1875], d_loss: -0.0134, g_loss: -0.0076\n",
      "Epoch [141/300], Step [1200/1875], d_loss: -0.2395, g_loss: 0.2707\n",
      "Epoch [141/300], Step [1400/1875], d_loss: 0.1378, g_loss: -0.2830\n",
      "Epoch [141/300], Step [1600/1875], d_loss: -0.0086, g_loss: -0.0385\n",
      "Epoch [141/300], Step [1800/1875], d_loss: 0.0725, g_loss: 0.2268\n",
      "Epoch [142/300], Step [200/1875], d_loss: 0.2368, g_loss: 0.0528\n",
      "Epoch [142/300], Step [400/1875], d_loss: -0.0676, g_loss: 0.1131\n",
      "Epoch [142/300], Step [600/1875], d_loss: -0.1594, g_loss: -0.2233\n",
      "Epoch [142/300], Step [800/1875], d_loss: 0.0439, g_loss: 0.0840\n",
      "Epoch [142/300], Step [1000/1875], d_loss: -0.1346, g_loss: 0.3225\n",
      "Epoch [142/300], Step [1200/1875], d_loss: 0.0481, g_loss: -0.2423\n",
      "Epoch [142/300], Step [1400/1875], d_loss: 0.0027, g_loss: -0.0126\n",
      "Epoch [142/300], Step [1600/1875], d_loss: -0.0491, g_loss: 0.2168\n",
      "Epoch [142/300], Step [1800/1875], d_loss: -0.1700, g_loss: -0.2581\n",
      "Epoch [143/300], Step [200/1875], d_loss: 0.0516, g_loss: 0.1494\n",
      "Epoch [143/300], Step [400/1875], d_loss: 0.0225, g_loss: 0.0332\n",
      "Epoch [143/300], Step [600/1875], d_loss: -0.0066, g_loss: -0.0806\n",
      "Epoch [143/300], Step [800/1875], d_loss: -0.0040, g_loss: -0.0634\n",
      "Epoch [143/300], Step [1000/1875], d_loss: -0.0085, g_loss: 0.0002\n",
      "Epoch [143/300], Step [1200/1875], d_loss: -0.0194, g_loss: 0.1027\n",
      "Epoch [143/300], Step [1400/1875], d_loss: -0.0114, g_loss: 0.0244\n",
      "Epoch [143/300], Step [1600/1875], d_loss: -0.0019, g_loss: -0.1085\n",
      "Epoch [143/300], Step [1800/1875], d_loss: -0.0780, g_loss: 0.1047\n",
      "Epoch [144/300], Step [200/1875], d_loss: -0.0172, g_loss: -0.0050\n",
      "Epoch [144/300], Step [400/1875], d_loss: -0.0571, g_loss: -0.0668\n",
      "Epoch [144/300], Step [600/1875], d_loss: -0.0350, g_loss: -0.0380\n",
      "Epoch [144/300], Step [800/1875], d_loss: -0.0196, g_loss: 0.0414\n",
      "Epoch [144/300], Step [1000/1875], d_loss: 0.0036, g_loss: -0.0070\n",
      "Epoch [144/300], Step [1200/1875], d_loss: -0.0151, g_loss: 0.0528\n",
      "Epoch [144/300], Step [1400/1875], d_loss: -0.0608, g_loss: -0.1053\n",
      "Epoch [144/300], Step [1600/1875], d_loss: 0.0185, g_loss: 0.1056\n",
      "Epoch [144/300], Step [1800/1875], d_loss: 0.0072, g_loss: -0.0680\n",
      "Epoch [145/300], Step [200/1875], d_loss: -0.0262, g_loss: 0.1193\n",
      "Epoch [145/300], Step [400/1875], d_loss: 0.0362, g_loss: -0.1773\n",
      "Epoch [145/300], Step [600/1875], d_loss: -0.0417, g_loss: 0.0613\n",
      "Epoch [145/300], Step [800/1875], d_loss: -0.0240, g_loss: -0.0229\n",
      "Epoch [145/300], Step [1000/1875], d_loss: -0.0318, g_loss: -0.0118\n",
      "Epoch [145/300], Step [1200/1875], d_loss: -0.0072, g_loss: -0.0867\n",
      "Epoch [145/300], Step [1400/1875], d_loss: -0.0302, g_loss: 0.0841\n",
      "Epoch [145/300], Step [1600/1875], d_loss: -0.0055, g_loss: -0.0870\n",
      "Epoch [145/300], Step [1800/1875], d_loss: -0.0596, g_loss: 0.1277\n",
      "Epoch [146/300], Step [200/1875], d_loss: 0.0129, g_loss: -0.0544\n",
      "Epoch [146/300], Step [400/1875], d_loss: -0.0348, g_loss: 0.1546\n",
      "Epoch [146/300], Step [600/1875], d_loss: 0.0012, g_loss: -0.1072\n",
      "Epoch [146/300], Step [800/1875], d_loss: -0.0209, g_loss: -0.0128\n",
      "Epoch [146/300], Step [1000/1875], d_loss: -0.0212, g_loss: 0.0074\n",
      "Epoch [146/300], Step [1200/1875], d_loss: 0.0134, g_loss: -0.0454\n",
      "Epoch [146/300], Step [1400/1875], d_loss: -0.0996, g_loss: -0.0458\n",
      "Epoch [146/300], Step [1600/1875], d_loss: 0.0355, g_loss: 0.0091\n",
      "Epoch [146/300], Step [1800/1875], d_loss: -0.0371, g_loss: 0.3537\n",
      "Epoch [147/300], Step [200/1875], d_loss: 0.0928, g_loss: 0.3574\n",
      "Epoch [147/300], Step [400/1875], d_loss: -0.0374, g_loss: 0.1728\n",
      "Epoch [147/300], Step [600/1875], d_loss: 0.0112, g_loss: -0.6546\n",
      "Epoch [147/300], Step [800/1875], d_loss: 0.0017, g_loss: 0.0166\n",
      "Epoch [147/300], Step [1000/1875], d_loss: 0.0908, g_loss: 0.6759\n",
      "Epoch [147/300], Step [1200/1875], d_loss: 0.0753, g_loss: -0.2658\n",
      "Epoch [147/300], Step [1400/1875], d_loss: -0.1722, g_loss: -0.3333\n",
      "Epoch [147/300], Step [1600/1875], d_loss: -0.1806, g_loss: 0.4428\n",
      "Epoch [147/300], Step [1800/1875], d_loss: -0.1613, g_loss: -0.2717\n",
      "Epoch [148/300], Step [200/1875], d_loss: -0.0126, g_loss: 0.1921\n",
      "Epoch [148/300], Step [400/1875], d_loss: -0.0507, g_loss: -0.2652\n",
      "Epoch [148/300], Step [600/1875], d_loss: -0.0989, g_loss: 0.1206\n",
      "Epoch [148/300], Step [800/1875], d_loss: 0.0007, g_loss: -0.0016\n",
      "Epoch [148/300], Step [1000/1875], d_loss: -0.0052, g_loss: 0.1017\n",
      "Epoch [148/300], Step [1200/1875], d_loss: -0.0374, g_loss: -0.0357\n",
      "Epoch [148/300], Step [1400/1875], d_loss: -0.0836, g_loss: 0.0800\n",
      "Epoch [148/300], Step [1600/1875], d_loss: 0.0615, g_loss: -0.1646\n",
      "Epoch [148/300], Step [1800/1875], d_loss: 0.0181, g_loss: 0.2107\n",
      "Epoch [149/300], Step [200/1875], d_loss: 0.0050, g_loss: -0.1126\n",
      "Epoch [149/300], Step [400/1875], d_loss: -0.0257, g_loss: 0.0974\n",
      "Epoch [149/300], Step [600/1875], d_loss: -0.0743, g_loss: -0.0381\n",
      "Epoch [149/300], Step [800/1875], d_loss: -0.0467, g_loss: 0.0492\n",
      "Epoch [149/300], Step [1000/1875], d_loss: -0.0653, g_loss: -0.1367\n",
      "Epoch [149/300], Step [1200/1875], d_loss: -0.0247, g_loss: 0.2313\n",
      "Epoch [149/300], Step [1400/1875], d_loss: -0.0360, g_loss: -0.2002\n",
      "Epoch [149/300], Step [1600/1875], d_loss: -0.0189, g_loss: 0.1123\n",
      "Epoch [149/300], Step [1800/1875], d_loss: 0.0359, g_loss: -0.0826\n",
      "Epoch [150/300], Step [200/1875], d_loss: -0.0269, g_loss: -0.0272\n",
      "Epoch [150/300], Step [400/1875], d_loss: 0.0092, g_loss: 0.0292\n",
      "Epoch [150/300], Step [600/1875], d_loss: -0.0299, g_loss: -0.0011\n",
      "Epoch [150/300], Step [800/1875], d_loss: -0.0154, g_loss: -0.0060\n",
      "Epoch [150/300], Step [1000/1875], d_loss: -0.0303, g_loss: -0.0309\n",
      "Epoch [150/300], Step [1200/1875], d_loss: -0.0730, g_loss: 0.1397\n",
      "Epoch [150/300], Step [1400/1875], d_loss: 0.0423, g_loss: -0.1207\n",
      "Epoch [150/300], Step [1600/1875], d_loss: -0.0870, g_loss: 0.0138\n",
      "Epoch [150/300], Step [1800/1875], d_loss: -0.0279, g_loss: -0.1044\n",
      "Epoch [151/300], Step [200/1875], d_loss: -0.0662, g_loss: -0.0245\n",
      "Epoch [151/300], Step [400/1875], d_loss: -0.0473, g_loss: 0.0748\n",
      "Epoch [151/300], Step [600/1875], d_loss: -0.1526, g_loss: 0.4158\n",
      "Epoch [151/300], Step [800/1875], d_loss: 0.1003, g_loss: -0.3649\n",
      "Epoch [151/300], Step [1000/1875], d_loss: -0.0659, g_loss: -0.3620\n",
      "Epoch [151/300], Step [1200/1875], d_loss: 0.1122, g_loss: 0.1671\n",
      "Epoch [151/300], Step [1400/1875], d_loss: -0.2572, g_loss: 0.8772\n",
      "Epoch [151/300], Step [1600/1875], d_loss: 0.0650, g_loss: -0.1268\n",
      "Epoch [151/300], Step [1800/1875], d_loss: -0.0986, g_loss: -0.4782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/300], Step [200/1875], d_loss: -0.1529, g_loss: -0.1212\n",
      "Epoch [152/300], Step [400/1875], d_loss: -0.3064, g_loss: 0.8692\n",
      "Epoch [152/300], Step [600/1875], d_loss: -0.0460, g_loss: -0.9649\n",
      "Epoch [152/300], Step [800/1875], d_loss: 0.0544, g_loss: 0.2822\n",
      "Epoch [152/300], Step [1000/1875], d_loss: 0.0295, g_loss: -0.0580\n",
      "Epoch [152/300], Step [1200/1875], d_loss: -0.0412, g_loss: -0.2082\n",
      "Epoch [152/300], Step [1400/1875], d_loss: -0.1087, g_loss: 0.3769\n",
      "Epoch [152/300], Step [1600/1875], d_loss: -0.1486, g_loss: -0.5603\n",
      "Epoch [152/300], Step [1800/1875], d_loss: -0.1839, g_loss: 0.2704\n",
      "Epoch [153/300], Step [200/1875], d_loss: -0.1357, g_loss: -1.0188\n",
      "Epoch [153/300], Step [400/1875], d_loss: -0.1073, g_loss: 0.8443\n",
      "Epoch [153/300], Step [600/1875], d_loss: 0.0955, g_loss: -0.7573\n",
      "Epoch [153/300], Step [800/1875], d_loss: -0.1614, g_loss: 0.9728\n",
      "Epoch [153/300], Step [1000/1875], d_loss: -0.1075, g_loss: -0.8607\n",
      "Epoch [153/300], Step [1200/1875], d_loss: 0.1045, g_loss: 0.3811\n",
      "Epoch [153/300], Step [1400/1875], d_loss: 0.0530, g_loss: -0.1209\n",
      "Epoch [153/300], Step [1600/1875], d_loss: -0.0300, g_loss: -0.0508\n",
      "Epoch [153/300], Step [1800/1875], d_loss: -0.0775, g_loss: 0.3474\n",
      "Epoch [154/300], Step [200/1875], d_loss: -0.1874, g_loss: -0.8399\n",
      "Epoch [154/300], Step [400/1875], d_loss: 0.0131, g_loss: 0.5692\n",
      "Epoch [154/300], Step [600/1875], d_loss: 0.0949, g_loss: -0.4436\n",
      "Epoch [154/300], Step [800/1875], d_loss: -0.0229, g_loss: -0.0028\n",
      "Epoch [154/300], Step [1000/1875], d_loss: -0.0462, g_loss: -0.0137\n",
      "Epoch [154/300], Step [1200/1875], d_loss: -0.0068, g_loss: 0.2705\n",
      "Epoch [154/300], Step [1400/1875], d_loss: -0.0341, g_loss: -0.3259\n",
      "Epoch [154/300], Step [1600/1875], d_loss: -0.0694, g_loss: -0.0889\n",
      "Epoch [154/300], Step [1800/1875], d_loss: -0.0160, g_loss: 0.1320\n",
      "Epoch [155/300], Step [200/1875], d_loss: -0.0109, g_loss: -0.0506\n",
      "Epoch [155/300], Step [400/1875], d_loss: 0.0093, g_loss: -0.0984\n",
      "Epoch [155/300], Step [600/1875], d_loss: -0.0673, g_loss: -0.1006\n",
      "Epoch [155/300], Step [800/1875], d_loss: -0.0214, g_loss: 0.0666\n",
      "Epoch [155/300], Step [1000/1875], d_loss: -0.0619, g_loss: 0.2140\n",
      "Epoch [155/300], Step [1200/1875], d_loss: -0.0171, g_loss: -0.1791\n",
      "Epoch [155/300], Step [1400/1875], d_loss: -0.0414, g_loss: 0.0866\n",
      "Epoch [155/300], Step [1600/1875], d_loss: -0.0534, g_loss: -0.0880\n",
      "Epoch [155/300], Step [1800/1875], d_loss: -0.0061, g_loss: 0.0295\n",
      "Epoch [156/300], Step [200/1875], d_loss: -0.0915, g_loss: 0.0192\n",
      "Epoch [156/300], Step [400/1875], d_loss: -0.1038, g_loss: 0.0283\n",
      "Epoch [156/300], Step [600/1875], d_loss: -0.0450, g_loss: -0.0237\n",
      "Epoch [156/300], Step [800/1875], d_loss: -0.0323, g_loss: 0.0434\n",
      "Epoch [156/300], Step [1000/1875], d_loss: -0.0458, g_loss: -0.1115\n",
      "Epoch [156/300], Step [1200/1875], d_loss: -0.0145, g_loss: 0.1062\n",
      "Epoch [156/300], Step [1400/1875], d_loss: -0.0464, g_loss: -0.0397\n",
      "Epoch [156/300], Step [1600/1875], d_loss: -0.0102, g_loss: 0.0159\n",
      "Epoch [156/300], Step [1800/1875], d_loss: -0.0405, g_loss: 0.0459\n",
      "Epoch [157/300], Step [200/1875], d_loss: -0.0100, g_loss: -0.0292\n",
      "Epoch [157/300], Step [400/1875], d_loss: -0.0210, g_loss: 0.0671\n",
      "Epoch [157/300], Step [600/1875], d_loss: 0.0381, g_loss: -0.0903\n",
      "Epoch [157/300], Step [800/1875], d_loss: -0.0300, g_loss: 0.0972\n",
      "Epoch [157/300], Step [1000/1875], d_loss: 0.0526, g_loss: -0.2083\n",
      "Epoch [157/300], Step [1200/1875], d_loss: -0.1153, g_loss: 0.0206\n",
      "Epoch [157/300], Step [1400/1875], d_loss: 0.0290, g_loss: 0.0982\n",
      "Epoch [157/300], Step [1600/1875], d_loss: -0.0047, g_loss: -0.0720\n",
      "Epoch [157/300], Step [1800/1875], d_loss: -0.0199, g_loss: 0.0967\n",
      "Epoch [158/300], Step [200/1875], d_loss: 0.0123, g_loss: -0.0731\n",
      "Epoch [158/300], Step [400/1875], d_loss: 0.0479, g_loss: 0.1157\n",
      "Epoch [158/300], Step [600/1875], d_loss: -0.0182, g_loss: -0.1178\n",
      "Epoch [158/300], Step [800/1875], d_loss: -0.0368, g_loss: 0.0557\n",
      "Epoch [158/300], Step [1000/1875], d_loss: -0.0086, g_loss: 0.0382\n",
      "Epoch [158/300], Step [1200/1875], d_loss: -0.0151, g_loss: -0.0839\n",
      "Epoch [158/300], Step [1400/1875], d_loss: 0.0061, g_loss: 0.1060\n",
      "Epoch [158/300], Step [1600/1875], d_loss: -0.0232, g_loss: -0.1085\n",
      "Epoch [158/300], Step [1800/1875], d_loss: -0.0656, g_loss: 0.0374\n",
      "Epoch [159/300], Step [200/1875], d_loss: -0.0485, g_loss: -0.0613\n",
      "Epoch [159/300], Step [400/1875], d_loss: -0.0151, g_loss: -0.0494\n",
      "Epoch [159/300], Step [600/1875], d_loss: -0.0196, g_loss: 0.0545\n",
      "Epoch [159/300], Step [800/1875], d_loss: -0.0344, g_loss: -0.0296\n",
      "Epoch [159/300], Step [1000/1875], d_loss: -0.0092, g_loss: -0.0422\n",
      "Epoch [159/300], Step [1200/1875], d_loss: -0.0458, g_loss: 0.0553\n",
      "Epoch [159/300], Step [1400/1875], d_loss: -0.0386, g_loss: -0.0237\n",
      "Epoch [159/300], Step [1600/1875], d_loss: -0.0246, g_loss: -0.0273\n",
      "Epoch [159/300], Step [1800/1875], d_loss: 0.0105, g_loss: -0.1264\n",
      "Epoch [160/300], Step [200/1875], d_loss: 0.0631, g_loss: -0.1441\n",
      "Epoch [160/300], Step [400/1875], d_loss: -0.0174, g_loss: 0.0322\n",
      "Epoch [160/300], Step [600/1875], d_loss: 0.0443, g_loss: -0.0360\n",
      "Epoch [160/300], Step [800/1875], d_loss: -0.0924, g_loss: 0.0727\n",
      "Epoch [160/300], Step [1000/1875], d_loss: 0.0772, g_loss: -0.0697\n",
      "Epoch [160/300], Step [1200/1875], d_loss: -0.1476, g_loss: 0.2386\n",
      "Epoch [160/300], Step [1400/1875], d_loss: 0.0218, g_loss: -0.0516\n",
      "Epoch [160/300], Step [1600/1875], d_loss: -0.1604, g_loss: 0.0910\n",
      "Epoch [160/300], Step [1800/1875], d_loss: 0.0540, g_loss: -0.0374\n",
      "Epoch [161/300], Step [200/1875], d_loss: -0.0585, g_loss: -0.3144\n",
      "Epoch [161/300], Step [400/1875], d_loss: -0.0108, g_loss: 0.1098\n",
      "Epoch [161/300], Step [600/1875], d_loss: 0.0244, g_loss: -0.3323\n",
      "Epoch [161/300], Step [800/1875], d_loss: 0.0334, g_loss: 0.2606\n",
      "Epoch [161/300], Step [1000/1875], d_loss: 0.0626, g_loss: -0.3305\n",
      "Epoch [161/300], Step [1200/1875], d_loss: -0.0258, g_loss: 0.0837\n",
      "Epoch [161/300], Step [1400/1875], d_loss: 0.0098, g_loss: 0.1023\n",
      "Epoch [161/300], Step [1600/1875], d_loss: 0.0008, g_loss: -0.1423\n",
      "Epoch [161/300], Step [1800/1875], d_loss: -0.0554, g_loss: 0.0492\n",
      "Epoch [162/300], Step [200/1875], d_loss: 0.0350, g_loss: -0.0611\n",
      "Epoch [162/300], Step [400/1875], d_loss: -0.0238, g_loss: -0.0532\n",
      "Epoch [162/300], Step [600/1875], d_loss: -0.0070, g_loss: 0.1593\n",
      "Epoch [162/300], Step [800/1875], d_loss: -0.0499, g_loss: -0.1261\n",
      "Epoch [162/300], Step [1000/1875], d_loss: -0.0537, g_loss: -0.0318\n",
      "Epoch [162/300], Step [1200/1875], d_loss: -0.0114, g_loss: -0.0538\n",
      "Epoch [162/300], Step [1400/1875], d_loss: -0.0355, g_loss: -0.0260\n",
      "Epoch [162/300], Step [1600/1875], d_loss: -0.0435, g_loss: 0.0508\n",
      "Epoch [162/300], Step [1800/1875], d_loss: -0.0468, g_loss: -0.0356\n",
      "Epoch [163/300], Step [200/1875], d_loss: 0.0003, g_loss: 0.0501\n",
      "Epoch [163/300], Step [400/1875], d_loss: -0.0190, g_loss: -0.0418\n",
      "Epoch [163/300], Step [600/1875], d_loss: -0.0257, g_loss: 0.1189\n",
      "Epoch [163/300], Step [800/1875], d_loss: -0.0143, g_loss: -0.0446\n",
      "Epoch [163/300], Step [1000/1875], d_loss: -0.0192, g_loss: -0.1157\n",
      "Epoch [163/300], Step [1200/1875], d_loss: -0.0571, g_loss: 0.0981\n",
      "Epoch [163/300], Step [1400/1875], d_loss: 0.0308, g_loss: -0.1754\n",
      "Epoch [163/300], Step [1600/1875], d_loss: 0.0355, g_loss: -0.0149\n",
      "Epoch [163/300], Step [1800/1875], d_loss: -0.0581, g_loss: -0.0405\n",
      "Epoch [164/300], Step [200/1875], d_loss: -0.0057, g_loss: 0.0213\n",
      "Epoch [164/300], Step [400/1875], d_loss: -0.0236, g_loss: -0.0245\n",
      "Epoch [164/300], Step [600/1875], d_loss: -0.1271, g_loss: -0.1059\n",
      "Epoch [164/300], Step [800/1875], d_loss: -0.0486, g_loss: 0.1272\n",
      "Epoch [164/300], Step [1000/1875], d_loss: -0.0808, g_loss: -0.0790\n",
      "Epoch [164/300], Step [1200/1875], d_loss: 0.0412, g_loss: -0.0016\n",
      "Epoch [164/300], Step [1400/1875], d_loss: -0.0218, g_loss: 0.0007\n",
      "Epoch [164/300], Step [1600/1875], d_loss: 0.0041, g_loss: -0.1482\n",
      "Epoch [164/300], Step [1800/1875], d_loss: -0.0148, g_loss: 0.0976\n",
      "Epoch [165/300], Step [200/1875], d_loss: 0.0008, g_loss: -0.0247\n",
      "Epoch [165/300], Step [400/1875], d_loss: 0.0003, g_loss: -0.0760\n",
      "Epoch [165/300], Step [600/1875], d_loss: -0.0145, g_loss: 0.0336\n",
      "Epoch [165/300], Step [800/1875], d_loss: -0.0060, g_loss: 0.0140\n",
      "Epoch [165/300], Step [1000/1875], d_loss: -0.0342, g_loss: -0.0448\n",
      "Epoch [165/300], Step [1200/1875], d_loss: -0.0892, g_loss: 0.1029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [165/300], Step [1400/1875], d_loss: 0.0342, g_loss: -0.0510\n",
      "Epoch [165/300], Step [1600/1875], d_loss: -0.0381, g_loss: -0.0117\n",
      "Epoch [165/300], Step [1800/1875], d_loss: 0.0155, g_loss: -0.0619\n",
      "Epoch [166/300], Step [200/1875], d_loss: -0.1456, g_loss: 0.0202\n",
      "Epoch [166/300], Step [400/1875], d_loss: 0.0174, g_loss: -0.0487\n",
      "Epoch [166/300], Step [600/1875], d_loss: -0.1303, g_loss: 0.2908\n",
      "Epoch [166/300], Step [800/1875], d_loss: -0.0860, g_loss: -0.2714\n",
      "Epoch [166/300], Step [1000/1875], d_loss: 0.0180, g_loss: 0.0858\n",
      "Epoch [166/300], Step [1200/1875], d_loss: -0.0290, g_loss: -0.0125\n",
      "Epoch [166/300], Step [1400/1875], d_loss: -0.0140, g_loss: 0.0426\n",
      "Epoch [166/300], Step [1600/1875], d_loss: -0.0134, g_loss: -0.0666\n",
      "Epoch [166/300], Step [1800/1875], d_loss: 0.0052, g_loss: -0.0047\n",
      "Epoch [167/300], Step [200/1875], d_loss: -0.0152, g_loss: -0.0056\n",
      "Epoch [167/300], Step [400/1875], d_loss: 0.0149, g_loss: -0.0152\n",
      "Epoch [167/300], Step [600/1875], d_loss: -0.0430, g_loss: -0.0656\n",
      "Epoch [167/300], Step [800/1875], d_loss: 0.0039, g_loss: -0.0230\n",
      "Epoch [167/300], Step [1000/1875], d_loss: -0.0615, g_loss: 0.1573\n",
      "Epoch [167/300], Step [1200/1875], d_loss: 0.0337, g_loss: -0.2289\n",
      "Epoch [167/300], Step [1400/1875], d_loss: -0.0658, g_loss: 0.0133\n",
      "Epoch [167/300], Step [1600/1875], d_loss: -0.1163, g_loss: 0.0395\n",
      "Epoch [167/300], Step [1800/1875], d_loss: 0.0085, g_loss: -0.0477\n",
      "Epoch [168/300], Step [200/1875], d_loss: -0.0230, g_loss: -0.0254\n",
      "Epoch [168/300], Step [400/1875], d_loss: -0.0134, g_loss: 0.0290\n",
      "Epoch [168/300], Step [600/1875], d_loss: -0.0351, g_loss: -0.0074\n",
      "Epoch [168/300], Step [800/1875], d_loss: 0.0073, g_loss: -0.0298\n",
      "Epoch [168/300], Step [1000/1875], d_loss: -0.0045, g_loss: 0.0415\n",
      "Epoch [168/300], Step [1200/1875], d_loss: -0.0319, g_loss: -0.0589\n",
      "Epoch [168/300], Step [1400/1875], d_loss: 0.0849, g_loss: 0.1812\n",
      "Epoch [168/300], Step [1600/1875], d_loss: -0.0551, g_loss: 0.0749\n",
      "Epoch [168/300], Step [1800/1875], d_loss: 0.0059, g_loss: -0.1544\n",
      "Epoch [169/300], Step [200/1875], d_loss: -0.0546, g_loss: 0.0311\n",
      "Epoch [169/300], Step [400/1875], d_loss: -0.0242, g_loss: -0.0651\n",
      "Epoch [169/300], Step [600/1875], d_loss: -0.0398, g_loss: 0.0677\n",
      "Epoch [169/300], Step [800/1875], d_loss: -0.0287, g_loss: -0.0843\n",
      "Epoch [169/300], Step [1000/1875], d_loss: -0.0243, g_loss: 0.1506\n",
      "Epoch [169/300], Step [1200/1875], d_loss: 0.0190, g_loss: -0.1515\n",
      "Epoch [169/300], Step [1400/1875], d_loss: -0.0619, g_loss: 0.1633\n",
      "Epoch [169/300], Step [1600/1875], d_loss: -0.0557, g_loss: -0.0867\n",
      "Epoch [169/300], Step [1800/1875], d_loss: -0.0215, g_loss: 0.0105\n",
      "Epoch [170/300], Step [200/1875], d_loss: -0.0529, g_loss: -0.0251\n",
      "Epoch [170/300], Step [400/1875], d_loss: 0.0419, g_loss: 0.0667\n",
      "Epoch [170/300], Step [600/1875], d_loss: -0.0507, g_loss: 0.1977\n",
      "Epoch [170/300], Step [800/1875], d_loss: -0.0556, g_loss: -0.0938\n",
      "Epoch [170/300], Step [1000/1875], d_loss: 0.0181, g_loss: 0.1141\n",
      "Epoch [170/300], Step [1200/1875], d_loss: 0.0672, g_loss: -0.1528\n",
      "Epoch [170/300], Step [1400/1875], d_loss: -0.0128, g_loss: 0.0106\n",
      "Epoch [170/300], Step [1600/1875], d_loss: -0.0064, g_loss: 0.0144\n",
      "Epoch [170/300], Step [1800/1875], d_loss: -0.0746, g_loss: -0.0050\n",
      "Epoch [171/300], Step [200/1875], d_loss: -0.0377, g_loss: -0.0087\n",
      "Epoch [171/300], Step [400/1875], d_loss: -0.0496, g_loss: 0.1796\n",
      "Epoch [171/300], Step [600/1875], d_loss: 0.0373, g_loss: -0.2049\n",
      "Epoch [171/300], Step [800/1875], d_loss: -0.0442, g_loss: 0.1092\n",
      "Epoch [171/300], Step [1000/1875], d_loss: -0.0048, g_loss: -0.1072\n",
      "Epoch [171/300], Step [1200/1875], d_loss: -0.0526, g_loss: 0.1487\n",
      "Epoch [171/300], Step [1400/1875], d_loss: -0.0193, g_loss: -0.1584\n",
      "Epoch [171/300], Step [1600/1875], d_loss: 0.0046, g_loss: 0.0639\n",
      "Epoch [171/300], Step [1800/1875], d_loss: -0.0635, g_loss: -0.1071\n",
      "Epoch [172/300], Step [200/1875], d_loss: -0.0366, g_loss: 0.0913\n",
      "Epoch [172/300], Step [400/1875], d_loss: -0.0681, g_loss: -0.0962\n",
      "Epoch [172/300], Step [600/1875], d_loss: 0.0314, g_loss: -0.0073\n",
      "Epoch [172/300], Step [800/1875], d_loss: -0.0995, g_loss: 0.1275\n",
      "Epoch [172/300], Step [1000/1875], d_loss: 0.0194, g_loss: -0.0959\n",
      "Epoch [172/300], Step [1200/1875], d_loss: -0.0393, g_loss: 0.1410\n",
      "Epoch [172/300], Step [1400/1875], d_loss: -0.0043, g_loss: -0.3004\n",
      "Epoch [172/300], Step [1600/1875], d_loss: -0.0265, g_loss: -0.0043\n",
      "Epoch [172/300], Step [1800/1875], d_loss: -0.0615, g_loss: 0.2329\n",
      "Epoch [173/300], Step [200/1875], d_loss: -0.0245, g_loss: 0.2206\n",
      "Epoch [173/300], Step [400/1875], d_loss: 0.0126, g_loss: -0.3274\n",
      "Epoch [173/300], Step [600/1875], d_loss: 0.0152, g_loss: -0.0379\n",
      "Epoch [173/300], Step [800/1875], d_loss: -0.0763, g_loss: 0.5517\n",
      "Epoch [173/300], Step [1000/1875], d_loss: 0.0346, g_loss: -0.0349\n",
      "Epoch [173/300], Step [1200/1875], d_loss: -0.1041, g_loss: -0.2275\n",
      "Epoch [173/300], Step [1400/1875], d_loss: 0.0284, g_loss: 0.2566\n",
      "Epoch [173/300], Step [1600/1875], d_loss: -0.0072, g_loss: -0.0097\n",
      "Epoch [173/300], Step [1800/1875], d_loss: -0.1525, g_loss: -0.3070\n",
      "Epoch [174/300], Step [200/1875], d_loss: -0.1387, g_loss: -0.1887\n",
      "Epoch [174/300], Step [400/1875], d_loss: -0.1362, g_loss: 0.4268\n",
      "Epoch [174/300], Step [600/1875], d_loss: 0.1115, g_loss: -0.5387\n",
      "Epoch [174/300], Step [800/1875], d_loss: 0.0149, g_loss: 0.0477\n",
      "Epoch [174/300], Step [1000/1875], d_loss: -0.0434, g_loss: 0.2087\n",
      "Epoch [174/300], Step [1200/1875], d_loss: -0.1403, g_loss: -0.3256\n",
      "Epoch [174/300], Step [1400/1875], d_loss: -0.0296, g_loss: 0.3425\n",
      "Epoch [174/300], Step [1600/1875], d_loss: 0.0489, g_loss: -0.1391\n",
      "Epoch [174/300], Step [1800/1875], d_loss: -0.0124, g_loss: -0.0275\n",
      "Epoch [175/300], Step [200/1875], d_loss: 0.0460, g_loss: 0.1598\n",
      "Epoch [175/300], Step [400/1875], d_loss: 0.0339, g_loss: -0.0427\n",
      "Epoch [175/300], Step [600/1875], d_loss: 0.0088, g_loss: 0.0224\n",
      "Epoch [175/300], Step [800/1875], d_loss: -0.0172, g_loss: -0.0317\n",
      "Epoch [175/300], Step [1000/1875], d_loss: -0.0443, g_loss: -0.0034\n",
      "Epoch [175/300], Step [1200/1875], d_loss: -0.0418, g_loss: 0.0787\n",
      "Epoch [175/300], Step [1400/1875], d_loss: -0.0112, g_loss: 0.0297\n",
      "Epoch [175/300], Step [1600/1875], d_loss: 0.0071, g_loss: -0.1550\n",
      "Epoch [175/300], Step [1800/1875], d_loss: -0.0050, g_loss: 0.0750\n",
      "Epoch [176/300], Step [200/1875], d_loss: 0.0337, g_loss: -0.1406\n",
      "Epoch [176/300], Step [400/1875], d_loss: -0.0077, g_loss: -0.0035\n",
      "Epoch [176/300], Step [600/1875], d_loss: 0.0102, g_loss: -0.0103\n",
      "Epoch [176/300], Step [800/1875], d_loss: -0.0340, g_loss: -0.0656\n",
      "Epoch [176/300], Step [1000/1875], d_loss: -0.0180, g_loss: 0.0490\n",
      "Epoch [176/300], Step [1200/1875], d_loss: -0.0463, g_loss: -0.0247\n",
      "Epoch [176/300], Step [1400/1875], d_loss: 0.0063, g_loss: 0.0387\n",
      "Epoch [176/300], Step [1600/1875], d_loss: -0.0093, g_loss: -0.0267\n",
      "Epoch [176/300], Step [1800/1875], d_loss: -0.0583, g_loss: -0.0186\n",
      "Epoch [177/300], Step [200/1875], d_loss: -0.0155, g_loss: 0.0461\n",
      "Epoch [177/300], Step [400/1875], d_loss: -0.0062, g_loss: 0.0185\n",
      "Epoch [177/300], Step [600/1875], d_loss: -0.0139, g_loss: -0.0897\n",
      "Epoch [177/300], Step [800/1875], d_loss: -0.0204, g_loss: 0.0084\n",
      "Epoch [177/300], Step [1000/1875], d_loss: -0.0381, g_loss: 0.0848\n",
      "Epoch [177/300], Step [1200/1875], d_loss: 0.0086, g_loss: -0.0981\n",
      "Epoch [177/300], Step [1400/1875], d_loss: 0.0271, g_loss: 0.1430\n",
      "Epoch [177/300], Step [1600/1875], d_loss: -0.0143, g_loss: 0.0409\n",
      "Epoch [177/300], Step [1800/1875], d_loss: -0.0339, g_loss: 0.0248\n",
      "Epoch [178/300], Step [200/1875], d_loss: -0.0273, g_loss: -0.0123\n",
      "Epoch [178/300], Step [400/1875], d_loss: -0.0246, g_loss: 0.0224\n",
      "Epoch [178/300], Step [600/1875], d_loss: -0.1104, g_loss: 0.0393\n",
      "Epoch [178/300], Step [800/1875], d_loss: 0.0603, g_loss: -0.0825\n",
      "Epoch [178/300], Step [1000/1875], d_loss: -0.0449, g_loss: 0.0145\n",
      "Epoch [178/300], Step [1200/1875], d_loss: -0.0455, g_loss: 0.0960\n",
      "Epoch [178/300], Step [1400/1875], d_loss: -0.0222, g_loss: -0.0771\n",
      "Epoch [178/300], Step [1600/1875], d_loss: 0.0105, g_loss: -0.0629\n",
      "Epoch [178/300], Step [1800/1875], d_loss: -0.2173, g_loss: 0.4023\n",
      "Epoch [179/300], Step [200/1875], d_loss: -0.1682, g_loss: 0.3253\n",
      "Epoch [179/300], Step [400/1875], d_loss: 0.0207, g_loss: -0.1708\n",
      "Epoch [179/300], Step [600/1875], d_loss: 0.2243, g_loss: 0.1397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [179/300], Step [800/1875], d_loss: 0.1834, g_loss: -0.1412\n",
      "Epoch [179/300], Step [1000/1875], d_loss: 0.0417, g_loss: 0.0319\n",
      "Epoch [179/300], Step [1200/1875], d_loss: 0.0216, g_loss: -0.0433\n",
      "Epoch [179/300], Step [1400/1875], d_loss: -0.0608, g_loss: -0.0353\n",
      "Epoch [179/300], Step [1600/1875], d_loss: -0.0530, g_loss: 0.2619\n",
      "Epoch [179/300], Step [1800/1875], d_loss: -0.0816, g_loss: -0.2880\n",
      "Epoch [180/300], Step [200/1875], d_loss: -0.0365, g_loss: -0.0716\n",
      "Epoch [180/300], Step [400/1875], d_loss: -0.1252, g_loss: 0.7782\n",
      "Epoch [180/300], Step [600/1875], d_loss: 0.0944, g_loss: -0.7431\n",
      "Epoch [180/300], Step [800/1875], d_loss: 0.0178, g_loss: 0.3627\n",
      "Epoch [180/300], Step [1000/1875], d_loss: -0.0588, g_loss: -0.2429\n",
      "Epoch [180/300], Step [1200/1875], d_loss: -0.0300, g_loss: 0.0283\n",
      "Epoch [180/300], Step [1400/1875], d_loss: -0.0181, g_loss: -0.0543\n",
      "Epoch [180/300], Step [1600/1875], d_loss: -0.0649, g_loss: -0.0937\n",
      "Epoch [180/300], Step [1800/1875], d_loss: -0.1014, g_loss: -0.0688\n",
      "Epoch [181/300], Step [200/1875], d_loss: -0.1074, g_loss: 0.0743\n",
      "Epoch [181/300], Step [400/1875], d_loss: -0.0212, g_loss: 0.0340\n",
      "Epoch [181/300], Step [600/1875], d_loss: -0.0135, g_loss: 0.0116\n",
      "Epoch [181/300], Step [800/1875], d_loss: -0.0245, g_loss: 0.0857\n",
      "Epoch [181/300], Step [1000/1875], d_loss: -0.0178, g_loss: -0.0575\n",
      "Epoch [181/300], Step [1200/1875], d_loss: -0.0323, g_loss: 0.0445\n",
      "Epoch [181/300], Step [1400/1875], d_loss: -0.0063, g_loss: -0.0433\n",
      "Epoch [181/300], Step [1600/1875], d_loss: -0.0199, g_loss: 0.0169\n",
      "Epoch [181/300], Step [1800/1875], d_loss: -0.0525, g_loss: 0.0020\n",
      "Epoch [182/300], Step [200/1875], d_loss: -0.0277, g_loss: -0.0294\n",
      "Epoch [182/300], Step [400/1875], d_loss: -0.0835, g_loss: 0.0818\n",
      "Epoch [182/300], Step [600/1875], d_loss: 0.0645, g_loss: -0.1348\n",
      "Epoch [182/300], Step [800/1875], d_loss: -0.0514, g_loss: 0.0024\n",
      "Epoch [182/300], Step [1000/1875], d_loss: 0.0261, g_loss: -0.0310\n",
      "Epoch [182/300], Step [1200/1875], d_loss: -0.0771, g_loss: 0.2388\n",
      "Epoch [182/300], Step [1400/1875], d_loss: 0.0832, g_loss: -0.3338\n",
      "Epoch [182/300], Step [1600/1875], d_loss: -0.0278, g_loss: -0.1865\n",
      "Epoch [182/300], Step [1800/1875], d_loss: -0.1747, g_loss: -0.0418\n",
      "Epoch [183/300], Step [200/1875], d_loss: -0.1959, g_loss: 0.0107\n",
      "Epoch [183/300], Step [400/1875], d_loss: 0.1681, g_loss: 0.2624\n",
      "Epoch [183/300], Step [600/1875], d_loss: 0.0022, g_loss: 0.0108\n",
      "Epoch [183/300], Step [800/1875], d_loss: -0.1186, g_loss: -0.2009\n",
      "Epoch [183/300], Step [1000/1875], d_loss: -0.1263, g_loss: 0.5500\n",
      "Epoch [183/300], Step [1200/1875], d_loss: -0.1629, g_loss: -0.2128\n",
      "Epoch [183/300], Step [1400/1875], d_loss: -0.0554, g_loss: 0.3915\n",
      "Epoch [183/300], Step [1600/1875], d_loss: -0.0127, g_loss: -0.2938\n",
      "Epoch [183/300], Step [1800/1875], d_loss: -0.0156, g_loss: 0.0402\n",
      "Epoch [184/300], Step [200/1875], d_loss: -0.0133, g_loss: -0.0414\n",
      "Epoch [184/300], Step [400/1875], d_loss: -0.0330, g_loss: -0.0514\n",
      "Epoch [184/300], Step [600/1875], d_loss: -0.0320, g_loss: -0.0925\n",
      "Epoch [184/300], Step [800/1875], d_loss: -0.0266, g_loss: -0.0247\n",
      "Epoch [184/300], Step [1000/1875], d_loss: -0.0162, g_loss: -0.0080\n",
      "Epoch [184/300], Step [1200/1875], d_loss: -0.0326, g_loss: 0.0330\n",
      "Epoch [184/300], Step [1400/1875], d_loss: -0.0664, g_loss: -0.0201\n",
      "Epoch [184/300], Step [1600/1875], d_loss: -0.0039, g_loss: -0.1479\n",
      "Epoch [184/300], Step [1800/1875], d_loss: -0.0265, g_loss: 0.1502\n",
      "Epoch [185/300], Step [200/1875], d_loss: 0.0106, g_loss: 0.1102\n",
      "Epoch [185/300], Step [400/1875], d_loss: 0.0382, g_loss: -0.0597\n",
      "Epoch [185/300], Step [600/1875], d_loss: -0.0381, g_loss: -0.0754\n",
      "Epoch [185/300], Step [800/1875], d_loss: -0.0031, g_loss: 0.1821\n",
      "Epoch [185/300], Step [1000/1875], d_loss: 0.0478, g_loss: -0.1917\n",
      "Epoch [185/300], Step [1200/1875], d_loss: -0.0003, g_loss: 0.0180\n",
      "Epoch [185/300], Step [1400/1875], d_loss: -0.0196, g_loss: -0.0146\n",
      "Epoch [185/300], Step [1600/1875], d_loss: 0.0248, g_loss: -0.0027\n",
      "Epoch [185/300], Step [1800/1875], d_loss: -0.0191, g_loss: -0.0431\n",
      "Epoch [186/300], Step [200/1875], d_loss: -0.0225, g_loss: 0.1599\n",
      "Epoch [186/300], Step [400/1875], d_loss: -0.0758, g_loss: -0.1420\n",
      "Epoch [186/300], Step [600/1875], d_loss: -0.0136, g_loss: 0.0774\n",
      "Epoch [186/300], Step [800/1875], d_loss: -0.0613, g_loss: -0.0821\n",
      "Epoch [186/300], Step [1000/1875], d_loss: -0.0487, g_loss: 0.1487\n",
      "Epoch [186/300], Step [1200/1875], d_loss: 0.0364, g_loss: -0.0513\n",
      "Epoch [186/300], Step [1400/1875], d_loss: -0.0321, g_loss: 0.0109\n",
      "Epoch [186/300], Step [1600/1875], d_loss: -0.0196, g_loss: 0.0146\n",
      "Epoch [186/300], Step [1800/1875], d_loss: -0.0404, g_loss: -0.0105\n",
      "Epoch [187/300], Step [200/1875], d_loss: -0.1113, g_loss: 0.1238\n",
      "Epoch [187/300], Step [400/1875], d_loss: 0.1035, g_loss: 0.0084\n",
      "Epoch [187/300], Step [600/1875], d_loss: -0.0262, g_loss: -0.0178\n",
      "Epoch [187/300], Step [800/1875], d_loss: 0.0047, g_loss: 0.0019\n",
      "Epoch [187/300], Step [1000/1875], d_loss: 0.0264, g_loss: 0.0120\n",
      "Epoch [187/300], Step [1200/1875], d_loss: -0.0172, g_loss: -0.0935\n",
      "Epoch [187/300], Step [1400/1875], d_loss: -0.0313, g_loss: 0.1175\n",
      "Epoch [187/300], Step [1600/1875], d_loss: 0.0542, g_loss: -0.0718\n",
      "Epoch [187/300], Step [1800/1875], d_loss: -0.0384, g_loss: 0.0524\n",
      "Epoch [188/300], Step [200/1875], d_loss: 0.0322, g_loss: 0.0785\n",
      "Epoch [188/300], Step [400/1875], d_loss: -0.0368, g_loss: -0.2123\n",
      "Epoch [188/300], Step [600/1875], d_loss: -0.0435, g_loss: 0.2096\n",
      "Epoch [188/300], Step [800/1875], d_loss: -0.0143, g_loss: -0.1553\n",
      "Epoch [188/300], Step [1000/1875], d_loss: -0.0126, g_loss: 0.1871\n",
      "Epoch [188/300], Step [1200/1875], d_loss: -0.0269, g_loss: -0.2425\n",
      "Epoch [188/300], Step [1400/1875], d_loss: -0.0410, g_loss: 0.0744\n",
      "Epoch [188/300], Step [1600/1875], d_loss: -0.0091, g_loss: -0.0486\n",
      "Epoch [188/300], Step [1800/1875], d_loss: -0.0618, g_loss: 0.0671\n",
      "Epoch [189/300], Step [200/1875], d_loss: 0.1622, g_loss: 0.0161\n",
      "Epoch [189/300], Step [400/1875], d_loss: -0.0685, g_loss: 0.0354\n",
      "Epoch [189/300], Step [600/1875], d_loss: 0.0338, g_loss: -0.1185\n",
      "Epoch [189/300], Step [800/1875], d_loss: -0.0352, g_loss: 0.1135\n",
      "Epoch [189/300], Step [1000/1875], d_loss: -0.0613, g_loss: -0.2778\n",
      "Epoch [189/300], Step [1200/1875], d_loss: 0.0284, g_loss: 0.0180\n",
      "Epoch [189/300], Step [1400/1875], d_loss: -0.0755, g_loss: 0.3044\n",
      "Epoch [189/300], Step [1600/1875], d_loss: 0.0548, g_loss: -0.3903\n",
      "Epoch [189/300], Step [1800/1875], d_loss: -0.0645, g_loss: -0.2897\n",
      "Epoch [190/300], Step [200/1875], d_loss: -0.0425, g_loss: -0.5497\n",
      "Epoch [190/300], Step [400/1875], d_loss: 0.0476, g_loss: 0.0383\n",
      "Epoch [190/300], Step [600/1875], d_loss: 0.1015, g_loss: 0.8979\n",
      "Epoch [190/300], Step [800/1875], d_loss: -0.0791, g_loss: -0.7396\n",
      "Epoch [190/300], Step [1000/1875], d_loss: -0.0253, g_loss: -0.0256\n",
      "Epoch [190/300], Step [1200/1875], d_loss: -0.1808, g_loss: 0.7391\n",
      "Epoch [190/300], Step [1400/1875], d_loss: 0.0007, g_loss: -0.7098\n",
      "Epoch [190/300], Step [1600/1875], d_loss: 0.0819, g_loss: 0.2780\n",
      "Epoch [190/300], Step [1800/1875], d_loss: 0.0710, g_loss: -0.3200\n",
      "Epoch [191/300], Step [200/1875], d_loss: -0.1178, g_loss: -0.3235\n",
      "Epoch [191/300], Step [400/1875], d_loss: 0.0332, g_loss: 0.2973\n",
      "Epoch [191/300], Step [600/1875], d_loss: -0.1025, g_loss: -0.2272\n",
      "Epoch [191/300], Step [800/1875], d_loss: -0.0461, g_loss: 0.2344\n",
      "Epoch [191/300], Step [1000/1875], d_loss: 0.0585, g_loss: -0.2232\n",
      "Epoch [191/300], Step [1200/1875], d_loss: 0.0425, g_loss: 0.2306\n",
      "Epoch [191/300], Step [1400/1875], d_loss: 0.0235, g_loss: -0.1114\n",
      "Epoch [191/300], Step [1600/1875], d_loss: -0.0111, g_loss: -0.0114\n",
      "Epoch [191/300], Step [1800/1875], d_loss: -0.0511, g_loss: 0.0204\n",
      "Epoch [192/300], Step [200/1875], d_loss: -0.0500, g_loss: -0.0371\n",
      "Epoch [192/300], Step [400/1875], d_loss: -0.0185, g_loss: -0.0492\n",
      "Epoch [192/300], Step [600/1875], d_loss: -0.0948, g_loss: 0.0283\n",
      "Epoch [192/300], Step [800/1875], d_loss: 0.1126, g_loss: -0.0125\n",
      "Epoch [192/300], Step [1000/1875], d_loss: -0.0103, g_loss: 0.0248\n",
      "Epoch [192/300], Step [1200/1875], d_loss: -0.1376, g_loss: 0.0616\n",
      "Epoch [192/300], Step [1400/1875], d_loss: -0.0334, g_loss: -0.1026\n",
      "Epoch [192/300], Step [1600/1875], d_loss: 0.0669, g_loss: 0.0368\n",
      "Epoch [192/300], Step [1800/1875], d_loss: -0.0497, g_loss: -0.0283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [193/300], Step [200/1875], d_loss: 0.0104, g_loss: 0.1765\n",
      "Epoch [193/300], Step [400/1875], d_loss: -0.0144, g_loss: -0.0816\n",
      "Epoch [193/300], Step [600/1875], d_loss: -0.0350, g_loss: 0.0075\n",
      "Epoch [193/300], Step [800/1875], d_loss: -0.1435, g_loss: 0.0422\n",
      "Epoch [193/300], Step [1000/1875], d_loss: -0.0199, g_loss: -0.0353\n",
      "Epoch [193/300], Step [1200/1875], d_loss: -0.0084, g_loss: 0.0952\n",
      "Epoch [193/300], Step [1400/1875], d_loss: -0.0079, g_loss: -0.0474\n",
      "Epoch [193/300], Step [1600/1875], d_loss: -0.0423, g_loss: -0.0392\n",
      "Epoch [193/300], Step [1800/1875], d_loss: -0.0132, g_loss: 0.0318\n",
      "Epoch [194/300], Step [200/1875], d_loss: -0.0620, g_loss: 0.0281\n",
      "Epoch [194/300], Step [400/1875], d_loss: 0.0279, g_loss: 0.0340\n",
      "Epoch [194/300], Step [600/1875], d_loss: 0.0185, g_loss: -0.1087\n",
      "Epoch [194/300], Step [800/1875], d_loss: -0.1365, g_loss: 0.3815\n",
      "Epoch [194/300], Step [1000/1875], d_loss: 0.1641, g_loss: -0.3392\n",
      "Epoch [194/300], Step [1200/1875], d_loss: 0.0034, g_loss: -0.0405\n",
      "Epoch [194/300], Step [1400/1875], d_loss: -0.1325, g_loss: 0.4322\n",
      "Epoch [194/300], Step [1600/1875], d_loss: 0.1023, g_loss: -0.4524\n",
      "Epoch [194/300], Step [1800/1875], d_loss: -0.0070, g_loss: 0.2394\n",
      "Epoch [195/300], Step [200/1875], d_loss: -0.1898, g_loss: 0.0084\n",
      "Epoch [195/300], Step [400/1875], d_loss: -0.0214, g_loss: -0.0901\n",
      "Epoch [195/300], Step [600/1875], d_loss: -0.0295, g_loss: -0.0248\n",
      "Epoch [195/300], Step [800/1875], d_loss: -0.0599, g_loss: 0.0164\n",
      "Epoch [195/300], Step [1000/1875], d_loss: -0.0659, g_loss: -0.0496\n",
      "Epoch [195/300], Step [1200/1875], d_loss: 0.0114, g_loss: 0.0819\n",
      "Epoch [195/300], Step [1400/1875], d_loss: -0.0317, g_loss: -0.0231\n",
      "Epoch [195/300], Step [1600/1875], d_loss: 0.0024, g_loss: 0.0420\n",
      "Epoch [195/300], Step [1800/1875], d_loss: -0.0221, g_loss: -0.0189\n",
      "Epoch [196/300], Step [200/1875], d_loss: -0.0158, g_loss: 0.0840\n",
      "Epoch [196/300], Step [400/1875], d_loss: -0.0025, g_loss: 0.0380\n",
      "Epoch [196/300], Step [600/1875], d_loss: 0.0070, g_loss: -0.0261\n",
      "Epoch [196/300], Step [800/1875], d_loss: 0.0481, g_loss: 0.0623\n",
      "Epoch [196/300], Step [1000/1875], d_loss: -0.0408, g_loss: -0.1789\n",
      "Epoch [196/300], Step [1200/1875], d_loss: -0.0521, g_loss: 0.1741\n",
      "Epoch [196/300], Step [1400/1875], d_loss: -0.0386, g_loss: -0.1220\n",
      "Epoch [196/300], Step [1600/1875], d_loss: -0.0218, g_loss: -0.0092\n",
      "Epoch [196/300], Step [1800/1875], d_loss: -0.0338, g_loss: 0.1521\n",
      "Epoch [197/300], Step [200/1875], d_loss: -0.0621, g_loss: -0.1267\n",
      "Epoch [197/300], Step [400/1875], d_loss: -0.0075, g_loss: -0.0198\n",
      "Epoch [197/300], Step [600/1875], d_loss: -0.0131, g_loss: -0.0085\n",
      "Epoch [197/300], Step [800/1875], d_loss: -0.0602, g_loss: -0.0283\n",
      "Epoch [197/300], Step [1000/1875], d_loss: -0.0163, g_loss: 0.0982\n",
      "Epoch [197/300], Step [1200/1875], d_loss: -0.0022, g_loss: -0.0586\n",
      "Epoch [197/300], Step [1400/1875], d_loss: -0.0227, g_loss: -0.0809\n",
      "Epoch [197/300], Step [1600/1875], d_loss: -0.1445, g_loss: 0.2081\n",
      "Epoch [197/300], Step [1800/1875], d_loss: -0.0187, g_loss: 0.0551\n",
      "Epoch [198/300], Step [200/1875], d_loss: -0.0621, g_loss: 0.1512\n",
      "Epoch [198/300], Step [400/1875], d_loss: -0.0750, g_loss: -0.4422\n",
      "Epoch [198/300], Step [600/1875], d_loss: -0.0620, g_loss: -0.0697\n",
      "Epoch [198/300], Step [800/1875], d_loss: -0.0723, g_loss: 0.2908\n",
      "Epoch [198/300], Step [1000/1875], d_loss: 0.0580, g_loss: -0.1210\n",
      "Epoch [198/300], Step [1200/1875], d_loss: -0.2059, g_loss: -0.1356\n",
      "Epoch [198/300], Step [1400/1875], d_loss: -0.1192, g_loss: 0.2280\n",
      "Epoch [198/300], Step [1600/1875], d_loss: 0.2143, g_loss: -0.2969\n",
      "Epoch [198/300], Step [1800/1875], d_loss: -0.0211, g_loss: -0.0729\n",
      "Epoch [199/300], Step [200/1875], d_loss: 0.0538, g_loss: 0.5835\n",
      "Epoch [199/300], Step [400/1875], d_loss: 0.0263, g_loss: -0.2770\n",
      "Epoch [199/300], Step [600/1875], d_loss: -0.0956, g_loss: -0.1848\n",
      "Epoch [199/300], Step [800/1875], d_loss: -0.0628, g_loss: 0.9209\n",
      "Epoch [199/300], Step [1000/1875], d_loss: -0.0196, g_loss: -0.5375\n",
      "Epoch [199/300], Step [1200/1875], d_loss: 0.2926, g_loss: 0.4068\n",
      "Epoch [199/300], Step [1400/1875], d_loss: 0.0040, g_loss: -0.0651\n",
      "Epoch [199/300], Step [1600/1875], d_loss: -0.0037, g_loss: -0.1467\n",
      "Epoch [199/300], Step [1800/1875], d_loss: -0.0903, g_loss: 0.2233\n",
      "Epoch [200/300], Step [200/1875], d_loss: 0.0278, g_loss: -0.3277\n",
      "Epoch [200/300], Step [400/1875], d_loss: -0.0446, g_loss: -0.1328\n",
      "Epoch [200/300], Step [600/1875], d_loss: -0.2363, g_loss: 0.8675\n",
      "Epoch [200/300], Step [800/1875], d_loss: -0.0968, g_loss: -0.7267\n",
      "Epoch [200/300], Step [1000/1875], d_loss: 0.2062, g_loss: 0.3830\n",
      "Epoch [200/300], Step [1200/1875], d_loss: 0.0370, g_loss: -0.1367\n",
      "Epoch [200/300], Step [1400/1875], d_loss: -0.0221, g_loss: -0.0500\n",
      "Epoch [200/300], Step [1600/1875], d_loss: -0.0436, g_loss: 0.3446\n",
      "Epoch [200/300], Step [1800/1875], d_loss: -0.0581, g_loss: -0.6938\n",
      "Epoch [201/300], Step [200/1875], d_loss: 0.0002, g_loss: 0.1284\n",
      "Epoch [201/300], Step [400/1875], d_loss: 0.0685, g_loss: -0.3332\n",
      "Epoch [201/300], Step [600/1875], d_loss: -0.0018, g_loss: 0.1376\n",
      "Epoch [201/300], Step [800/1875], d_loss: -0.0144, g_loss: -0.3209\n",
      "Epoch [201/300], Step [1000/1875], d_loss: 0.0351, g_loss: 0.2017\n",
      "Epoch [201/300], Step [1200/1875], d_loss: 0.0088, g_loss: -0.2322\n",
      "Epoch [201/300], Step [1400/1875], d_loss: -0.0859, g_loss: 0.0656\n",
      "Epoch [201/300], Step [1600/1875], d_loss: -0.0244, g_loss: -0.0803\n",
      "Epoch [201/300], Step [1800/1875], d_loss: -0.0304, g_loss: -0.0236\n",
      "Epoch [202/300], Step [200/1875], d_loss: -0.0132, g_loss: 0.0540\n",
      "Epoch [202/300], Step [400/1875], d_loss: -0.0198, g_loss: -0.0840\n",
      "Epoch [202/300], Step [600/1875], d_loss: -0.0186, g_loss: -0.0218\n",
      "Epoch [202/300], Step [800/1875], d_loss: -0.0255, g_loss: 0.0666\n",
      "Epoch [202/300], Step [1000/1875], d_loss: -0.0309, g_loss: -0.1409\n",
      "Epoch [202/300], Step [1200/1875], d_loss: -0.0137, g_loss: 0.0001\n",
      "Epoch [202/300], Step [1400/1875], d_loss: -0.0306, g_loss: 0.0501\n",
      "Epoch [202/300], Step [1600/1875], d_loss: -0.0241, g_loss: -0.0366\n",
      "Epoch [202/300], Step [1800/1875], d_loss: -0.0247, g_loss: -0.0330\n",
      "Epoch [203/300], Step [200/1875], d_loss: -0.0316, g_loss: 0.0383\n",
      "Epoch [203/300], Step [400/1875], d_loss: -0.0317, g_loss: 0.0202\n",
      "Epoch [203/300], Step [600/1875], d_loss: -0.0131, g_loss: 0.0433\n",
      "Epoch [203/300], Step [800/1875], d_loss: -0.0357, g_loss: -0.0436\n",
      "Epoch [203/300], Step [1000/1875], d_loss: -0.0384, g_loss: 0.0143\n",
      "Epoch [203/300], Step [1200/1875], d_loss: -0.0630, g_loss: 0.0788\n",
      "Epoch [203/300], Step [1400/1875], d_loss: -0.0527, g_loss: -0.0868\n",
      "Epoch [203/300], Step [1600/1875], d_loss: -0.0456, g_loss: 0.1016\n",
      "Epoch [203/300], Step [1800/1875], d_loss: -0.0104, g_loss: -0.0454\n",
      "Epoch [204/300], Step [200/1875], d_loss: -0.0398, g_loss: -0.0319\n",
      "Epoch [204/300], Step [400/1875], d_loss: -0.0598, g_loss: 0.0710\n",
      "Epoch [204/300], Step [600/1875], d_loss: -0.0534, g_loss: -0.0754\n",
      "Epoch [204/300], Step [800/1875], d_loss: -0.0392, g_loss: 0.0516\n",
      "Epoch [204/300], Step [1000/1875], d_loss: -0.0261, g_loss: -0.0851\n",
      "Epoch [204/300], Step [1200/1875], d_loss: 0.0279, g_loss: 0.1812\n",
      "Epoch [204/300], Step [1400/1875], d_loss: -0.0698, g_loss: -0.0922\n",
      "Epoch [204/300], Step [1600/1875], d_loss: 0.0114, g_loss: 0.1357\n",
      "Epoch [204/300], Step [1800/1875], d_loss: -0.0003, g_loss: -0.0739\n",
      "Epoch [205/300], Step [200/1875], d_loss: -0.0292, g_loss: -0.0361\n",
      "Epoch [205/300], Step [400/1875], d_loss: -0.0269, g_loss: -0.0258\n",
      "Epoch [205/300], Step [600/1875], d_loss: -0.0310, g_loss: 0.0130\n",
      "Epoch [205/300], Step [800/1875], d_loss: -0.0378, g_loss: -0.0531\n",
      "Epoch [205/300], Step [1000/1875], d_loss: -0.0389, g_loss: 0.0538\n",
      "Epoch [205/300], Step [1200/1875], d_loss: -0.0264, g_loss: -0.1011\n",
      "Epoch [205/300], Step [1400/1875], d_loss: -0.0232, g_loss: 0.0202\n",
      "Epoch [205/300], Step [1600/1875], d_loss: -0.0452, g_loss: 0.0455\n",
      "Epoch [205/300], Step [1800/1875], d_loss: -0.0275, g_loss: -0.1010\n",
      "Epoch [206/300], Step [200/1875], d_loss: -0.0514, g_loss: 0.0905\n",
      "Epoch [206/300], Step [400/1875], d_loss: -0.1269, g_loss: -0.0346\n",
      "Epoch [206/300], Step [600/1875], d_loss: 0.0349, g_loss: -0.0137\n",
      "Epoch [206/300], Step [800/1875], d_loss: -0.0897, g_loss: -0.0850\n",
      "Epoch [206/300], Step [1000/1875], d_loss: 0.0579, g_loss: 0.1089\n",
      "Epoch [206/300], Step [1200/1875], d_loss: -0.1152, g_loss: 0.3656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [206/300], Step [1400/1875], d_loss: 0.1149, g_loss: -0.3019\n",
      "Epoch [206/300], Step [1600/1875], d_loss: -0.0827, g_loss: -0.3431\n",
      "Epoch [206/300], Step [1800/1875], d_loss: -0.0007, g_loss: -0.0145\n",
      "Epoch [207/300], Step [200/1875], d_loss: -0.0343, g_loss: 0.0601\n",
      "Epoch [207/300], Step [400/1875], d_loss: -0.0846, g_loss: 0.5123\n",
      "Epoch [207/300], Step [600/1875], d_loss: 0.0422, g_loss: -0.4599\n",
      "Epoch [207/300], Step [800/1875], d_loss: -0.0792, g_loss: -0.0374\n",
      "Epoch [207/300], Step [1000/1875], d_loss: -0.0911, g_loss: 0.5350\n",
      "Epoch [207/300], Step [1200/1875], d_loss: 0.0768, g_loss: -0.0700\n",
      "Epoch [207/300], Step [1400/1875], d_loss: -0.0776, g_loss: -0.1494\n",
      "Epoch [207/300], Step [1600/1875], d_loss: -0.1157, g_loss: 0.7120\n",
      "Epoch [207/300], Step [1800/1875], d_loss: 0.0332, g_loss: -0.3799\n",
      "Epoch [208/300], Step [200/1875], d_loss: 0.0015, g_loss: 0.0162\n",
      "Epoch [208/300], Step [400/1875], d_loss: 0.0048, g_loss: -0.0354\n",
      "Epoch [208/300], Step [600/1875], d_loss: -0.0017, g_loss: -0.0100\n",
      "Epoch [208/300], Step [800/1875], d_loss: 0.0106, g_loss: -0.0804\n",
      "Epoch [208/300], Step [1000/1875], d_loss: -0.0056, g_loss: 0.0544\n",
      "Epoch [208/300], Step [1200/1875], d_loss: 0.0275, g_loss: -0.0929\n",
      "Epoch [208/300], Step [1400/1875], d_loss: 0.0101, g_loss: 0.0822\n",
      "Epoch [208/300], Step [1600/1875], d_loss: -0.0014, g_loss: -0.0689\n",
      "Epoch [208/300], Step [1800/1875], d_loss: -0.0279, g_loss: -0.0354\n",
      "Epoch [209/300], Step [200/1875], d_loss: -0.0098, g_loss: 0.0146\n",
      "Epoch [209/300], Step [400/1875], d_loss: -0.0414, g_loss: -0.0553\n",
      "Epoch [209/300], Step [600/1875], d_loss: -0.0123, g_loss: -0.0309\n",
      "Epoch [209/300], Step [800/1875], d_loss: -0.0477, g_loss: -0.0214\n",
      "Epoch [209/300], Step [1000/1875], d_loss: -0.0434, g_loss: 0.0421\n",
      "Epoch [209/300], Step [1200/1875], d_loss: -0.0148, g_loss: -0.0778\n",
      "Epoch [209/300], Step [1400/1875], d_loss: 0.0085, g_loss: -0.0477\n",
      "Epoch [209/300], Step [1600/1875], d_loss: -0.0664, g_loss: 0.0349\n",
      "Epoch [209/300], Step [1800/1875], d_loss: -0.0299, g_loss: 0.0011\n",
      "Epoch [210/300], Step [200/1875], d_loss: -0.0260, g_loss: -0.0228\n",
      "Epoch [210/300], Step [400/1875], d_loss: -0.0144, g_loss: -0.0442\n",
      "Epoch [210/300], Step [600/1875], d_loss: -0.0114, g_loss: -0.0077\n",
      "Epoch [210/300], Step [800/1875], d_loss: 0.0065, g_loss: 0.1938\n",
      "Epoch [210/300], Step [1000/1875], d_loss: -0.0259, g_loss: -0.2024\n",
      "Epoch [210/300], Step [1200/1875], d_loss: -0.0530, g_loss: 0.1307\n",
      "Epoch [210/300], Step [1400/1875], d_loss: -0.0295, g_loss: -0.0004\n",
      "Epoch [210/300], Step [1600/1875], d_loss: -0.0602, g_loss: 0.1199\n",
      "Epoch [210/300], Step [1800/1875], d_loss: -0.0048, g_loss: -0.2284\n",
      "Epoch [211/300], Step [200/1875], d_loss: -0.0587, g_loss: 0.0348\n",
      "Epoch [211/300], Step [400/1875], d_loss: -0.0134, g_loss: 0.0128\n",
      "Epoch [211/300], Step [600/1875], d_loss: -0.0096, g_loss: 0.0919\n",
      "Epoch [211/300], Step [800/1875], d_loss: -0.0483, g_loss: -0.1177\n",
      "Epoch [211/300], Step [1000/1875], d_loss: -0.0017, g_loss: 0.2011\n",
      "Epoch [211/300], Step [1200/1875], d_loss: -0.0483, g_loss: -0.1007\n",
      "Epoch [211/300], Step [1400/1875], d_loss: -0.0705, g_loss: -0.0920\n",
      "Epoch [211/300], Step [1600/1875], d_loss: 0.0287, g_loss: 0.1724\n",
      "Epoch [211/300], Step [1800/1875], d_loss: 0.0539, g_loss: -0.2365\n",
      "Epoch [212/300], Step [200/1875], d_loss: -0.1243, g_loss: -0.5617\n",
      "Epoch [212/300], Step [400/1875], d_loss: 0.0161, g_loss: 0.1485\n",
      "Epoch [212/300], Step [600/1875], d_loss: -0.1088, g_loss: 0.3214\n",
      "Epoch [212/300], Step [800/1875], d_loss: -0.1680, g_loss: -0.4122\n",
      "Epoch [212/300], Step [1000/1875], d_loss: 0.1010, g_loss: 0.2488\n",
      "Epoch [212/300], Step [1200/1875], d_loss: 0.0068, g_loss: -0.0628\n",
      "Epoch [212/300], Step [1400/1875], d_loss: -0.0318, g_loss: -0.1314\n",
      "Epoch [212/300], Step [1600/1875], d_loss: -0.0028, g_loss: 0.4709\n",
      "Epoch [212/300], Step [1800/1875], d_loss: 0.0696, g_loss: -0.3993\n",
      "Epoch [213/300], Step [200/1875], d_loss: -0.1218, g_loss: -0.2753\n",
      "Epoch [213/300], Step [400/1875], d_loss: 0.0780, g_loss: 0.1981\n",
      "Epoch [213/300], Step [600/1875], d_loss: -0.0238, g_loss: -0.1813\n",
      "Epoch [213/300], Step [800/1875], d_loss: -0.0121, g_loss: 0.1405\n",
      "Epoch [213/300], Step [1000/1875], d_loss: -0.0336, g_loss: 0.0604\n",
      "Epoch [213/300], Step [1200/1875], d_loss: -0.0405, g_loss: -0.1178\n",
      "Epoch [213/300], Step [1400/1875], d_loss: 0.0149, g_loss: 0.1202\n",
      "Epoch [213/300], Step [1600/1875], d_loss: 0.0114, g_loss: -0.2179\n",
      "Epoch [213/300], Step [1800/1875], d_loss: -0.0260, g_loss: 0.0478\n",
      "Epoch [214/300], Step [200/1875], d_loss: -0.0022, g_loss: 0.0356\n",
      "Epoch [214/300], Step [400/1875], d_loss: -0.0325, g_loss: -0.0412\n",
      "Epoch [214/300], Step [600/1875], d_loss: -0.0423, g_loss: 0.0163\n",
      "Epoch [214/300], Step [800/1875], d_loss: -0.0745, g_loss: 0.1018\n",
      "Epoch [214/300], Step [1000/1875], d_loss: 0.1521, g_loss: -0.1239\n",
      "Epoch [214/300], Step [1200/1875], d_loss: -0.0291, g_loss: -0.1276\n",
      "Epoch [214/300], Step [1400/1875], d_loss: -0.0439, g_loss: 0.2829\n",
      "Epoch [214/300], Step [1600/1875], d_loss: -0.0320, g_loss: -0.0723\n",
      "Epoch [214/300], Step [1800/1875], d_loss: -0.0842, g_loss: -0.1636\n",
      "Epoch [215/300], Step [200/1875], d_loss: -0.0292, g_loss: 0.1230\n",
      "Epoch [215/300], Step [400/1875], d_loss: -0.0287, g_loss: -0.0398\n",
      "Epoch [215/300], Step [600/1875], d_loss: 0.0036, g_loss: 0.0908\n",
      "Epoch [215/300], Step [800/1875], d_loss: -0.0023, g_loss: -0.1494\n",
      "Epoch [215/300], Step [1000/1875], d_loss: -0.0276, g_loss: 0.0578\n",
      "Epoch [215/300], Step [1200/1875], d_loss: -0.0504, g_loss: -0.0695\n",
      "Epoch [215/300], Step [1400/1875], d_loss: -0.0318, g_loss: 0.1688\n",
      "Epoch [215/300], Step [1600/1875], d_loss: -0.0295, g_loss: -0.1452\n",
      "Epoch [215/300], Step [1800/1875], d_loss: -0.0176, g_loss: 0.0468\n",
      "Epoch [216/300], Step [200/1875], d_loss: -0.0365, g_loss: -0.0783\n",
      "Epoch [216/300], Step [400/1875], d_loss: -0.0339, g_loss: 0.0352\n",
      "Epoch [216/300], Step [600/1875], d_loss: -0.0174, g_loss: 0.0004\n",
      "Epoch [216/300], Step [800/1875], d_loss: -0.0391, g_loss: 0.0730\n",
      "Epoch [216/300], Step [1000/1875], d_loss: -0.0503, g_loss: 0.0039\n",
      "Epoch [216/300], Step [1200/1875], d_loss: -0.0383, g_loss: 0.0713\n",
      "Epoch [216/300], Step [1400/1875], d_loss: -0.0361, g_loss: -0.0954\n",
      "Epoch [216/300], Step [1600/1875], d_loss: -0.0103, g_loss: 0.0190\n",
      "Epoch [216/300], Step [1800/1875], d_loss: -0.0159, g_loss: -0.0171\n",
      "Epoch [217/300], Step [200/1875], d_loss: -0.0194, g_loss: 0.0406\n",
      "Epoch [217/300], Step [400/1875], d_loss: 0.0238, g_loss: -0.1325\n",
      "Epoch [217/300], Step [600/1875], d_loss: -0.0080, g_loss: 0.1755\n",
      "Epoch [217/300], Step [800/1875], d_loss: -0.0387, g_loss: -0.0319\n",
      "Epoch [217/300], Step [1000/1875], d_loss: -0.0200, g_loss: 0.0164\n",
      "Epoch [217/300], Step [1200/1875], d_loss: -0.0944, g_loss: -0.1070\n",
      "Epoch [217/300], Step [1400/1875], d_loss: -0.0018, g_loss: 0.0870\n",
      "Epoch [217/300], Step [1600/1875], d_loss: -0.1035, g_loss: 0.3150\n",
      "Epoch [217/300], Step [1800/1875], d_loss: 0.0411, g_loss: -0.0622\n",
      "Epoch [218/300], Step [200/1875], d_loss: -0.0843, g_loss: 0.4016\n",
      "Epoch [218/300], Step [400/1875], d_loss: 0.1953, g_loss: -0.5060\n",
      "Epoch [218/300], Step [600/1875], d_loss: -0.3114, g_loss: -0.4434\n",
      "Epoch [218/300], Step [800/1875], d_loss: 0.1219, g_loss: 0.5617\n",
      "Epoch [218/300], Step [1000/1875], d_loss: -0.0293, g_loss: 0.0560\n",
      "Epoch [218/300], Step [1200/1875], d_loss: -0.3377, g_loss: -0.3119\n",
      "Epoch [218/300], Step [1400/1875], d_loss: -0.1705, g_loss: 0.6447\n",
      "Epoch [218/300], Step [1600/1875], d_loss: -0.0025, g_loss: 0.0310\n",
      "Epoch [218/300], Step [1800/1875], d_loss: -0.2044, g_loss: -0.5424\n",
      "Epoch [219/300], Step [200/1875], d_loss: 0.0323, g_loss: 0.0386\n",
      "Epoch [219/300], Step [400/1875], d_loss: -0.1095, g_loss: 0.4405\n",
      "Epoch [219/300], Step [600/1875], d_loss: -0.1245, g_loss: -0.7556\n",
      "Epoch [219/300], Step [800/1875], d_loss: -0.2445, g_loss: 0.9788\n",
      "Epoch [219/300], Step [1000/1875], d_loss: 0.1053, g_loss: -0.9989\n",
      "Epoch [219/300], Step [1200/1875], d_loss: 0.0929, g_loss: 0.3177\n",
      "Epoch [219/300], Step [1400/1875], d_loss: 0.0151, g_loss: -0.1224\n",
      "Epoch [219/300], Step [1600/1875], d_loss: -0.0226, g_loss: -0.0962\n",
      "Epoch [219/300], Step [1800/1875], d_loss: -0.0311, g_loss: 0.4309\n",
      "Epoch [220/300], Step [200/1875], d_loss: 0.0337, g_loss: -1.1030\n",
      "Epoch [220/300], Step [400/1875], d_loss: 0.2475, g_loss: 0.4371\n",
      "Epoch [220/300], Step [600/1875], d_loss: 0.0152, g_loss: -0.0431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [220/300], Step [800/1875], d_loss: 0.0009, g_loss: -0.0058\n",
      "Epoch [220/300], Step [1000/1875], d_loss: -0.0511, g_loss: 0.1092\n",
      "Epoch [220/300], Step [1200/1875], d_loss: -0.0167, g_loss: -0.2964\n",
      "Epoch [220/300], Step [1400/1875], d_loss: -0.0838, g_loss: 0.8837\n",
      "Epoch [220/300], Step [1600/1875], d_loss: -0.1810, g_loss: -0.5913\n",
      "Epoch [220/300], Step [1800/1875], d_loss: -0.0263, g_loss: 0.0365\n",
      "Epoch [221/300], Step [200/1875], d_loss: 0.0699, g_loss: 0.2472\n",
      "Epoch [221/300], Step [400/1875], d_loss: -0.0221, g_loss: 0.0531\n",
      "Epoch [221/300], Step [600/1875], d_loss: -0.0274, g_loss: -0.2163\n",
      "Epoch [221/300], Step [800/1875], d_loss: -0.0325, g_loss: 0.1004\n",
      "Epoch [221/300], Step [1000/1875], d_loss: -0.0266, g_loss: -0.0054\n",
      "Epoch [221/300], Step [1200/1875], d_loss: -0.0339, g_loss: -0.0805\n",
      "Epoch [221/300], Step [1400/1875], d_loss: -0.0264, g_loss: -0.0619\n",
      "Epoch [221/300], Step [1600/1875], d_loss: -0.0516, g_loss: -0.0434\n",
      "Epoch [221/300], Step [1800/1875], d_loss: -0.0045, g_loss: -0.0912\n",
      "Epoch [222/300], Step [200/1875], d_loss: -0.0445, g_loss: 0.0230\n",
      "Epoch [222/300], Step [400/1875], d_loss: -0.0927, g_loss: -0.0308\n",
      "Epoch [222/300], Step [600/1875], d_loss: 0.0214, g_loss: -0.1149\n",
      "Epoch [222/300], Step [800/1875], d_loss: -0.0143, g_loss: 0.0568\n",
      "Epoch [222/300], Step [1000/1875], d_loss: -0.0721, g_loss: 0.0545\n",
      "Epoch [222/300], Step [1200/1875], d_loss: -0.0027, g_loss: 0.0096\n",
      "Epoch [222/300], Step [1400/1875], d_loss: -0.0725, g_loss: 0.1586\n",
      "Epoch [222/300], Step [1600/1875], d_loss: 0.0873, g_loss: -0.1987\n",
      "Epoch [222/300], Step [1800/1875], d_loss: -0.0153, g_loss: 0.1337\n",
      "Epoch [223/300], Step [200/1875], d_loss: -0.0264, g_loss: 0.2264\n",
      "Epoch [223/300], Step [400/1875], d_loss: 0.0202, g_loss: -0.0723\n",
      "Epoch [223/300], Step [600/1875], d_loss: -0.0168, g_loss: -0.1193\n",
      "Epoch [223/300], Step [800/1875], d_loss: 0.0912, g_loss: 0.1687\n",
      "Epoch [223/300], Step [1000/1875], d_loss: -0.0143, g_loss: 0.0516\n",
      "Epoch [223/300], Step [1200/1875], d_loss: -0.0583, g_loss: -0.0912\n",
      "Epoch [223/300], Step [1400/1875], d_loss: 0.0284, g_loss: 0.1322\n",
      "Epoch [223/300], Step [1600/1875], d_loss: -0.1022, g_loss: 0.4811\n",
      "Epoch [223/300], Step [1800/1875], d_loss: 0.2423, g_loss: -0.3964\n",
      "Epoch [224/300], Step [200/1875], d_loss: 0.3308, g_loss: -0.7630\n",
      "Epoch [224/300], Step [400/1875], d_loss: -0.0156, g_loss: -0.0372\n",
      "Epoch [224/300], Step [600/1875], d_loss: -0.1438, g_loss: 0.5003\n",
      "Epoch [224/300], Step [800/1875], d_loss: -0.1798, g_loss: -0.4512\n",
      "Epoch [224/300], Step [1000/1875], d_loss: -0.0728, g_loss: 0.3157\n",
      "Epoch [224/300], Step [1200/1875], d_loss: 0.0734, g_loss: -0.2914\n",
      "Epoch [224/300], Step [1400/1875], d_loss: -0.0134, g_loss: 0.0946\n",
      "Epoch [224/300], Step [1600/1875], d_loss: 0.0200, g_loss: -0.0482\n",
      "Epoch [224/300], Step [1800/1875], d_loss: -0.0048, g_loss: -0.0838\n",
      "Epoch [225/300], Step [200/1875], d_loss: -0.1378, g_loss: 0.3800\n",
      "Epoch [225/300], Step [400/1875], d_loss: -0.0469, g_loss: -0.3081\n",
      "Epoch [225/300], Step [600/1875], d_loss: 0.0767, g_loss: 0.1829\n",
      "Epoch [225/300], Step [800/1875], d_loss: 0.0574, g_loss: -0.1850\n",
      "Epoch [225/300], Step [1000/1875], d_loss: 0.0225, g_loss: 0.0318\n",
      "Epoch [225/300], Step [1200/1875], d_loss: 0.0016, g_loss: 0.1246\n",
      "Epoch [225/300], Step [1400/1875], d_loss: -0.0336, g_loss: -0.2304\n",
      "Epoch [225/300], Step [1600/1875], d_loss: -0.0231, g_loss: 0.2735\n",
      "Epoch [225/300], Step [1800/1875], d_loss: -0.0066, g_loss: -0.1569\n",
      "Epoch [226/300], Step [200/1875], d_loss: 0.0389, g_loss: 0.2256\n",
      "Epoch [226/300], Step [400/1875], d_loss: 0.0172, g_loss: -0.0925\n",
      "Epoch [226/300], Step [600/1875], d_loss: -0.0337, g_loss: -0.0610\n",
      "Epoch [226/300], Step [800/1875], d_loss: -0.1755, g_loss: 0.2939\n",
      "Epoch [226/300], Step [1000/1875], d_loss: -0.0557, g_loss: -0.2821\n",
      "Epoch [226/300], Step [1200/1875], d_loss: 0.1025, g_loss: 0.1411\n",
      "Epoch [226/300], Step [1400/1875], d_loss: 0.0825, g_loss: -0.1975\n",
      "Epoch [226/300], Step [1600/1875], d_loss: -0.0082, g_loss: 0.0934\n",
      "Epoch [226/300], Step [1800/1875], d_loss: -0.0044, g_loss: 0.0556\n",
      "Epoch [227/300], Step [200/1875], d_loss: -0.0502, g_loss: -0.1711\n",
      "Epoch [227/300], Step [400/1875], d_loss: 0.1126, g_loss: 0.1387\n",
      "Epoch [227/300], Step [600/1875], d_loss: 0.0412, g_loss: -0.2475\n",
      "Epoch [227/300], Step [800/1875], d_loss: -0.0268, g_loss: 0.2082\n",
      "Epoch [227/300], Step [1000/1875], d_loss: -0.0034, g_loss: -0.2131\n",
      "Epoch [227/300], Step [1200/1875], d_loss: -0.0614, g_loss: 0.0327\n",
      "Epoch [227/300], Step [1400/1875], d_loss: 0.0096, g_loss: 0.0420\n",
      "Epoch [227/300], Step [1600/1875], d_loss: -0.0093, g_loss: -0.0635\n",
      "Epoch [227/300], Step [1800/1875], d_loss: -0.0374, g_loss: 0.0028\n",
      "Epoch [228/300], Step [200/1875], d_loss: -0.0154, g_loss: 0.0088\n",
      "Epoch [228/300], Step [400/1875], d_loss: -0.0279, g_loss: -0.1031\n",
      "Epoch [228/300], Step [600/1875], d_loss: -0.0362, g_loss: 0.0258\n",
      "Epoch [228/300], Step [800/1875], d_loss: -0.0192, g_loss: 0.0534\n",
      "Epoch [228/300], Step [1000/1875], d_loss: -0.0408, g_loss: 0.0167\n",
      "Epoch [228/300], Step [1200/1875], d_loss: -0.0239, g_loss: -0.0410\n",
      "Epoch [228/300], Step [1400/1875], d_loss: -0.0253, g_loss: -0.0169\n",
      "Epoch [228/300], Step [1600/1875], d_loss: -0.0386, g_loss: -0.0368\n",
      "Epoch [228/300], Step [1800/1875], d_loss: -0.0072, g_loss: -0.0247\n",
      "Epoch [229/300], Step [200/1875], d_loss: -0.0498, g_loss: 0.0936\n",
      "Epoch [229/300], Step [400/1875], d_loss: -0.0358, g_loss: -0.0623\n",
      "Epoch [229/300], Step [600/1875], d_loss: 0.0092, g_loss: -0.0012\n",
      "Epoch [229/300], Step [800/1875], d_loss: 0.0571, g_loss: 0.0483\n",
      "Epoch [229/300], Step [1000/1875], d_loss: -0.0103, g_loss: 0.0527\n",
      "Epoch [229/300], Step [1200/1875], d_loss: -0.0224, g_loss: 0.0512\n",
      "Epoch [229/300], Step [1400/1875], d_loss: -0.0100, g_loss: -0.0335\n",
      "Epoch [229/300], Step [1600/1875], d_loss: -0.0118, g_loss: -0.0031\n",
      "Epoch [229/300], Step [1800/1875], d_loss: -0.0327, g_loss: 0.0462\n",
      "Epoch [230/300], Step [200/1875], d_loss: -0.0432, g_loss: -0.1146\n",
      "Epoch [230/300], Step [400/1875], d_loss: -0.0366, g_loss: 0.0370\n",
      "Epoch [230/300], Step [600/1875], d_loss: 0.0003, g_loss: 0.0308\n",
      "Epoch [230/300], Step [800/1875], d_loss: -0.0370, g_loss: 0.0986\n",
      "Epoch [230/300], Step [1000/1875], d_loss: 0.0096, g_loss: -0.0928\n",
      "Epoch [230/300], Step [1200/1875], d_loss: -0.0292, g_loss: 0.0140\n",
      "Epoch [230/300], Step [1400/1875], d_loss: -0.0059, g_loss: 0.0311\n",
      "Epoch [230/300], Step [1600/1875], d_loss: -0.0738, g_loss: -0.1481\n",
      "Epoch [230/300], Step [1800/1875], d_loss: -0.1061, g_loss: 0.1310\n",
      "Epoch [231/300], Step [200/1875], d_loss: 0.0444, g_loss: 0.0040\n",
      "Epoch [231/300], Step [400/1875], d_loss: 0.0056, g_loss: -0.0106\n",
      "Epoch [231/300], Step [600/1875], d_loss: 0.0190, g_loss: -0.1308\n",
      "Epoch [231/300], Step [800/1875], d_loss: -0.0284, g_loss: 0.2452\n",
      "Epoch [231/300], Step [1000/1875], d_loss: -0.0080, g_loss: -0.1518\n",
      "Epoch [231/300], Step [1200/1875], d_loss: 0.0015, g_loss: 0.1173\n",
      "Epoch [231/300], Step [1400/1875], d_loss: -0.0041, g_loss: -0.0868\n",
      "Epoch [231/300], Step [1600/1875], d_loss: -0.0460, g_loss: -0.0512\n",
      "Epoch [231/300], Step [1800/1875], d_loss: -0.0705, g_loss: 0.0628\n",
      "Epoch [232/300], Step [200/1875], d_loss: -0.0008, g_loss: -0.0115\n",
      "Epoch [232/300], Step [400/1875], d_loss: -0.0202, g_loss: -0.0367\n",
      "Epoch [232/300], Step [600/1875], d_loss: -0.0242, g_loss: 0.0593\n",
      "Epoch [232/300], Step [800/1875], d_loss: 0.0181, g_loss: -0.1179\n",
      "Epoch [232/300], Step [1000/1875], d_loss: 0.0018, g_loss: 0.3484\n",
      "Epoch [232/300], Step [1200/1875], d_loss: -0.0072, g_loss: -0.2472\n",
      "Epoch [232/300], Step [1400/1875], d_loss: -0.0039, g_loss: 0.1282\n",
      "Epoch [232/300], Step [1600/1875], d_loss: -0.0759, g_loss: -0.0184\n",
      "Epoch [232/300], Step [1800/1875], d_loss: 0.0841, g_loss: -0.0402\n",
      "Epoch [233/300], Step [200/1875], d_loss: -0.0109, g_loss: -0.0431\n",
      "Epoch [233/300], Step [400/1875], d_loss: -0.0116, g_loss: 0.0249\n",
      "Epoch [233/300], Step [600/1875], d_loss: -0.0688, g_loss: 0.1049\n",
      "Epoch [233/300], Step [800/1875], d_loss: -0.0347, g_loss: -0.0426\n",
      "Epoch [233/300], Step [1000/1875], d_loss: 0.0229, g_loss: 0.0259\n",
      "Epoch [233/300], Step [1200/1875], d_loss: 0.0394, g_loss: -0.1376\n",
      "Epoch [233/300], Step [1400/1875], d_loss: -0.0128, g_loss: 0.0522\n",
      "Epoch [233/300], Step [1600/1875], d_loss: -0.0490, g_loss: 0.0159\n",
      "Epoch [233/300], Step [1800/1875], d_loss: -0.1240, g_loss: 0.0345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [234/300], Step [200/1875], d_loss: 0.0055, g_loss: 0.1649\n",
      "Epoch [234/300], Step [400/1875], d_loss: -0.0536, g_loss: -0.0400\n",
      "Epoch [234/300], Step [600/1875], d_loss: -0.0127, g_loss: 0.0935\n",
      "Epoch [234/300], Step [800/1875], d_loss: -0.0548, g_loss: -0.1806\n",
      "Epoch [234/300], Step [1000/1875], d_loss: 0.0194, g_loss: -0.0526\n",
      "Epoch [234/300], Step [1200/1875], d_loss: -0.0533, g_loss: 0.1668\n",
      "Epoch [234/300], Step [1400/1875], d_loss: 0.0381, g_loss: -0.2256\n",
      "Epoch [234/300], Step [1600/1875], d_loss: 0.0055, g_loss: 0.2024\n",
      "Epoch [234/300], Step [1800/1875], d_loss: 0.0138, g_loss: -0.1977\n",
      "Epoch [235/300], Step [200/1875], d_loss: -0.0180, g_loss: 0.0441\n",
      "Epoch [235/300], Step [400/1875], d_loss: -0.0355, g_loss: -0.0414\n",
      "Epoch [235/300], Step [600/1875], d_loss: -0.0247, g_loss: 0.0138\n",
      "Epoch [235/300], Step [800/1875], d_loss: -0.0011, g_loss: -0.0505\n",
      "Epoch [235/300], Step [1000/1875], d_loss: -0.0616, g_loss: 0.0480\n",
      "Epoch [235/300], Step [1200/1875], d_loss: -0.0497, g_loss: 0.0220\n",
      "Epoch [235/300], Step [1400/1875], d_loss: -0.0170, g_loss: -0.1594\n",
      "Epoch [235/300], Step [1600/1875], d_loss: -0.0312, g_loss: 0.0513\n",
      "Epoch [235/300], Step [1800/1875], d_loss: -0.0211, g_loss: -0.1148\n",
      "Epoch [236/300], Step [200/1875], d_loss: 0.0057, g_loss: 0.0344\n",
      "Epoch [236/300], Step [400/1875], d_loss: -0.0087, g_loss: -0.0858\n",
      "Epoch [236/300], Step [600/1875], d_loss: -0.0027, g_loss: 0.0972\n",
      "Epoch [236/300], Step [800/1875], d_loss: -0.0457, g_loss: 0.0647\n",
      "Epoch [236/300], Step [1000/1875], d_loss: -0.0716, g_loss: -0.1853\n",
      "Epoch [236/300], Step [1200/1875], d_loss: 0.0427, g_loss: 0.1164\n",
      "Epoch [236/300], Step [1400/1875], d_loss: -0.0343, g_loss: -0.0359\n",
      "Epoch [236/300], Step [1600/1875], d_loss: -0.0719, g_loss: 0.1252\n",
      "Epoch [236/300], Step [1800/1875], d_loss: -0.0730, g_loss: -0.0188\n",
      "Epoch [237/300], Step [200/1875], d_loss: -0.0503, g_loss: -0.0006\n",
      "Epoch [237/300], Step [400/1875], d_loss: -0.0403, g_loss: 0.0447\n",
      "Epoch [237/300], Step [600/1875], d_loss: -0.0186, g_loss: -0.0002\n",
      "Epoch [237/300], Step [800/1875], d_loss: -0.1151, g_loss: 0.0114\n",
      "Epoch [237/300], Step [1000/1875], d_loss: -0.0150, g_loss: 0.0326\n",
      "Epoch [237/300], Step [1200/1875], d_loss: -0.0376, g_loss: 0.0403\n",
      "Epoch [237/300], Step [1400/1875], d_loss: -0.0474, g_loss: -0.0567\n",
      "Epoch [237/300], Step [1600/1875], d_loss: 0.0114, g_loss: -0.0245\n",
      "Epoch [237/300], Step [1800/1875], d_loss: 0.0380, g_loss: -0.0336\n",
      "Epoch [238/300], Step [200/1875], d_loss: -0.0175, g_loss: -0.0945\n",
      "Epoch [238/300], Step [400/1875], d_loss: 0.0069, g_loss: 0.0375\n",
      "Epoch [238/300], Step [600/1875], d_loss: -0.0592, g_loss: -0.0953\n",
      "Epoch [238/300], Step [800/1875], d_loss: -0.0509, g_loss: 0.1113\n",
      "Epoch [238/300], Step [1000/1875], d_loss: 0.0488, g_loss: -0.1608\n",
      "Epoch [238/300], Step [1200/1875], d_loss: 0.0075, g_loss: -0.0353\n",
      "Epoch [238/300], Step [1400/1875], d_loss: -0.0890, g_loss: 0.1483\n",
      "Epoch [238/300], Step [1600/1875], d_loss: -0.0788, g_loss: -0.1635\n",
      "Epoch [238/300], Step [1800/1875], d_loss: -0.0393, g_loss: -0.0104\n",
      "Epoch [239/300], Step [200/1875], d_loss: -0.0231, g_loss: 0.2392\n",
      "Epoch [239/300], Step [400/1875], d_loss: -0.0267, g_loss: -0.1258\n",
      "Epoch [239/300], Step [600/1875], d_loss: 0.0008, g_loss: 0.0325\n",
      "Epoch [239/300], Step [800/1875], d_loss: -0.0775, g_loss: -0.0460\n",
      "Epoch [239/300], Step [1000/1875], d_loss: -0.0054, g_loss: -0.0041\n",
      "Epoch [239/300], Step [1200/1875], d_loss: -0.0186, g_loss: 0.0148\n",
      "Epoch [239/300], Step [1400/1875], d_loss: -0.0469, g_loss: 0.0501\n",
      "Epoch [239/300], Step [1600/1875], d_loss: -0.0229, g_loss: 0.0300\n",
      "Epoch [239/300], Step [1800/1875], d_loss: -0.0286, g_loss: 0.0312\n",
      "Epoch [240/300], Step [200/1875], d_loss: -0.0414, g_loss: -0.0246\n",
      "Epoch [240/300], Step [400/1875], d_loss: -0.0236, g_loss: -0.0329\n",
      "Epoch [240/300], Step [600/1875], d_loss: 0.0662, g_loss: 0.0213\n",
      "Epoch [240/300], Step [800/1875], d_loss: -0.0441, g_loss: 0.0593\n",
      "Epoch [240/300], Step [1000/1875], d_loss: 0.0497, g_loss: -0.0751\n",
      "Epoch [240/300], Step [1200/1875], d_loss: 0.0128, g_loss: 0.0261\n",
      "Epoch [240/300], Step [1400/1875], d_loss: -0.0586, g_loss: 0.0501\n",
      "Epoch [240/300], Step [1600/1875], d_loss: 0.0440, g_loss: 0.0018\n",
      "Epoch [240/300], Step [1800/1875], d_loss: -0.0099, g_loss: 0.0251\n",
      "Epoch [241/300], Step [200/1875], d_loss: -0.0161, g_loss: -0.0320\n",
      "Epoch [241/300], Step [400/1875], d_loss: -0.0151, g_loss: -0.0556\n",
      "Epoch [241/300], Step [600/1875], d_loss: -0.0356, g_loss: 0.0403\n",
      "Epoch [241/300], Step [800/1875], d_loss: -0.0257, g_loss: -0.0978\n",
      "Epoch [241/300], Step [1000/1875], d_loss: 0.0020, g_loss: 0.0503\n",
      "Epoch [241/300], Step [1200/1875], d_loss: -0.0367, g_loss: -0.0967\n",
      "Epoch [241/300], Step [1400/1875], d_loss: 0.0183, g_loss: 0.1174\n",
      "Epoch [241/300], Step [1600/1875], d_loss: -0.0402, g_loss: -0.0445\n",
      "Epoch [241/300], Step [1800/1875], d_loss: -0.0779, g_loss: -0.0439\n",
      "Epoch [242/300], Step [200/1875], d_loss: 0.1419, g_loss: -0.3257\n",
      "Epoch [242/300], Step [400/1875], d_loss: -0.0608, g_loss: -0.0652\n",
      "Epoch [242/300], Step [600/1875], d_loss: 0.0601, g_loss: 0.1076\n",
      "Epoch [242/300], Step [800/1875], d_loss: -0.1922, g_loss: 0.3998\n",
      "Epoch [242/300], Step [1000/1875], d_loss: 0.1017, g_loss: -0.4299\n",
      "Epoch [242/300], Step [1200/1875], d_loss: -0.1570, g_loss: -0.1761\n",
      "Epoch [242/300], Step [1400/1875], d_loss: 0.1056, g_loss: 0.2310\n",
      "Epoch [242/300], Step [1600/1875], d_loss: -0.1788, g_loss: 0.5133\n",
      "Epoch [242/300], Step [1800/1875], d_loss: 0.2099, g_loss: -0.6958\n",
      "Epoch [243/300], Step [200/1875], d_loss: -0.1110, g_loss: -0.2197\n",
      "Epoch [243/300], Step [400/1875], d_loss: 0.0423, g_loss: 0.7560\n",
      "Epoch [243/300], Step [600/1875], d_loss: -0.0720, g_loss: -0.8495\n",
      "Epoch [243/300], Step [800/1875], d_loss: 0.0387, g_loss: 0.0591\n",
      "Epoch [243/300], Step [1000/1875], d_loss: -0.1550, g_loss: 0.2668\n",
      "Epoch [243/300], Step [1200/1875], d_loss: -0.1699, g_loss: -0.3686\n",
      "Epoch [243/300], Step [1400/1875], d_loss: -0.0112, g_loss: 0.6841\n",
      "Epoch [243/300], Step [1600/1875], d_loss: -0.1761, g_loss: -0.6538\n",
      "Epoch [243/300], Step [1800/1875], d_loss: 0.0884, g_loss: 0.3971\n",
      "Epoch [244/300], Step [200/1875], d_loss: -0.0592, g_loss: 0.1572\n",
      "Epoch [244/300], Step [400/1875], d_loss: -0.0543, g_loss: -0.1276\n",
      "Epoch [244/300], Step [600/1875], d_loss: -0.0826, g_loss: 0.6032\n",
      "Epoch [244/300], Step [800/1875], d_loss: -0.0566, g_loss: -0.5277\n",
      "Epoch [244/300], Step [1000/1875], d_loss: 0.2141, g_loss: 0.5041\n",
      "Epoch [244/300], Step [1200/1875], d_loss: 0.0311, g_loss: -0.3361\n",
      "Epoch [244/300], Step [1400/1875], d_loss: -0.0420, g_loss: -0.1408\n",
      "Epoch [244/300], Step [1600/1875], d_loss: 0.0095, g_loss: 0.6073\n",
      "Epoch [244/300], Step [1800/1875], d_loss: -0.1425, g_loss: -0.6148\n",
      "Epoch [245/300], Step [200/1875], d_loss: 0.0246, g_loss: 0.0590\n",
      "Epoch [245/300], Step [400/1875], d_loss: -0.0688, g_loss: 0.2020\n",
      "Epoch [245/300], Step [600/1875], d_loss: -0.1406, g_loss: -0.2588\n",
      "Epoch [245/300], Step [800/1875], d_loss: -0.1354, g_loss: 0.5965\n",
      "Epoch [245/300], Step [1000/1875], d_loss: -0.1100, g_loss: -0.6020\n",
      "Epoch [245/300], Step [1200/1875], d_loss: 0.0600, g_loss: 0.4629\n",
      "Epoch [245/300], Step [1400/1875], d_loss: 0.0528, g_loss: -0.4651\n",
      "Epoch [245/300], Step [1600/1875], d_loss: 0.0290, g_loss: 0.2706\n",
      "Epoch [245/300], Step [1800/1875], d_loss: -0.0598, g_loss: -0.3691\n",
      "Epoch [246/300], Step [200/1875], d_loss: -0.0152, g_loss: 0.0507\n",
      "Epoch [246/300], Step [400/1875], d_loss: -0.0295, g_loss: 0.1741\n",
      "Epoch [246/300], Step [600/1875], d_loss: -0.0179, g_loss: -0.1183\n",
      "Epoch [246/300], Step [800/1875], d_loss: 0.0034, g_loss: -0.0855\n",
      "Epoch [246/300], Step [1000/1875], d_loss: -0.0409, g_loss: -0.1603\n",
      "Epoch [246/300], Step [1200/1875], d_loss: -0.0034, g_loss: 0.0888\n",
      "Epoch [246/300], Step [1400/1875], d_loss: -0.0131, g_loss: -0.0213\n",
      "Epoch [246/300], Step [1600/1875], d_loss: -0.0239, g_loss: 0.0180\n",
      "Epoch [246/300], Step [1800/1875], d_loss: -0.0286, g_loss: 0.0627\n",
      "Epoch [247/300], Step [200/1875], d_loss: 0.0072, g_loss: -0.0916\n",
      "Epoch [247/300], Step [400/1875], d_loss: -0.0369, g_loss: 0.0604\n",
      "Epoch [247/300], Step [600/1875], d_loss: 0.0200, g_loss: -0.0862\n",
      "Epoch [247/300], Step [800/1875], d_loss: -0.0317, g_loss: 0.0056\n",
      "Epoch [247/300], Step [1000/1875], d_loss: -0.0810, g_loss: 0.1515\n",
      "Epoch [247/300], Step [1200/1875], d_loss: 0.0146, g_loss: -0.0502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [247/300], Step [1400/1875], d_loss: 0.0287, g_loss: -0.0207\n",
      "Epoch [247/300], Step [1600/1875], d_loss: -0.0647, g_loss: 0.1581\n",
      "Epoch [247/300], Step [1800/1875], d_loss: -0.0360, g_loss: -0.0576\n",
      "Epoch [248/300], Step [200/1875], d_loss: 0.0089, g_loss: -0.1174\n",
      "Epoch [248/300], Step [400/1875], d_loss: -0.0325, g_loss: -0.0513\n",
      "Epoch [248/300], Step [600/1875], d_loss: 0.0208, g_loss: 0.2222\n",
      "Epoch [248/300], Step [800/1875], d_loss: -0.0010, g_loss: -0.1624\n",
      "Epoch [248/300], Step [1000/1875], d_loss: -0.0049, g_loss: 0.0799\n",
      "Epoch [248/300], Step [1200/1875], d_loss: -0.0353, g_loss: -0.0575\n",
      "Epoch [248/300], Step [1400/1875], d_loss: -0.0318, g_loss: 0.0694\n",
      "Epoch [248/300], Step [1600/1875], d_loss: -0.0006, g_loss: -0.0494\n",
      "Epoch [248/300], Step [1800/1875], d_loss: -0.0536, g_loss: 0.1263\n",
      "Epoch [249/300], Step [200/1875], d_loss: 0.0273, g_loss: -0.0075\n",
      "Epoch [249/300], Step [400/1875], d_loss: 0.0124, g_loss: 0.0519\n",
      "Epoch [249/300], Step [600/1875], d_loss: 0.0123, g_loss: -0.0595\n",
      "Epoch [249/300], Step [800/1875], d_loss: 0.0228, g_loss: 0.1792\n",
      "Epoch [249/300], Step [1000/1875], d_loss: -0.0523, g_loss: -0.1126\n",
      "Epoch [249/300], Step [1200/1875], d_loss: 0.0273, g_loss: 0.2036\n",
      "Epoch [249/300], Step [1400/1875], d_loss: -0.0437, g_loss: -0.1064\n",
      "Epoch [249/300], Step [1600/1875], d_loss: -0.0083, g_loss: 0.0460\n",
      "Epoch [249/300], Step [1800/1875], d_loss: -0.0043, g_loss: -0.0308\n",
      "Epoch [250/300], Step [200/1875], d_loss: -0.0121, g_loss: -0.0175\n",
      "Epoch [250/300], Step [400/1875], d_loss: 0.0007, g_loss: -0.0038\n",
      "Epoch [250/300], Step [600/1875], d_loss: -0.0322, g_loss: -0.0283\n",
      "Epoch [250/300], Step [800/1875], d_loss: -0.0466, g_loss: -0.0307\n",
      "Epoch [250/300], Step [1000/1875], d_loss: -0.0086, g_loss: 0.0363\n",
      "Epoch [250/300], Step [1200/1875], d_loss: 0.0448, g_loss: -0.1579\n",
      "Epoch [250/300], Step [1400/1875], d_loss: -0.0358, g_loss: 0.0639\n",
      "Epoch [250/300], Step [1600/1875], d_loss: -0.0293, g_loss: 0.1082\n",
      "Epoch [250/300], Step [1800/1875], d_loss: -0.0791, g_loss: 0.2228\n",
      "Epoch [251/300], Step [200/1875], d_loss: -0.1955, g_loss: 0.6143\n",
      "Epoch [251/300], Step [400/1875], d_loss: 0.1233, g_loss: -0.3987\n",
      "Epoch [251/300], Step [600/1875], d_loss: -0.0941, g_loss: -0.3392\n",
      "Epoch [251/300], Step [800/1875], d_loss: 0.1768, g_loss: 0.3633\n",
      "Epoch [251/300], Step [1000/1875], d_loss: 0.0011, g_loss: 0.2317\n",
      "Epoch [251/300], Step [1200/1875], d_loss: -0.1630, g_loss: -0.2983\n",
      "Epoch [251/300], Step [1400/1875], d_loss: 0.0565, g_loss: 0.4814\n",
      "Epoch [251/300], Step [1600/1875], d_loss: 0.1669, g_loss: -0.3570\n",
      "Epoch [251/300], Step [1800/1875], d_loss: 0.0066, g_loss: 0.0928\n",
      "Epoch [252/300], Step [200/1875], d_loss: -0.1041, g_loss: 0.3444\n",
      "Epoch [252/300], Step [400/1875], d_loss: -0.1458, g_loss: -0.4284\n",
      "Epoch [252/300], Step [600/1875], d_loss: 0.1232, g_loss: 0.2679\n",
      "Epoch [252/300], Step [800/1875], d_loss: 0.0324, g_loss: -0.1313\n",
      "Epoch [252/300], Step [1000/1875], d_loss: -0.0274, g_loss: -0.0871\n",
      "Epoch [252/300], Step [1200/1875], d_loss: -0.1340, g_loss: 0.5267\n",
      "Epoch [252/300], Step [1400/1875], d_loss: -0.0387, g_loss: -0.5237\n",
      "Epoch [252/300], Step [1600/1875], d_loss: 0.0743, g_loss: 0.2239\n",
      "Epoch [252/300], Step [1800/1875], d_loss: 0.1010, g_loss: -0.1643\n",
      "Epoch [253/300], Step [200/1875], d_loss: -0.0569, g_loss: 0.0419\n",
      "Epoch [253/300], Step [400/1875], d_loss: 0.0054, g_loss: -0.2004\n",
      "Epoch [253/300], Step [600/1875], d_loss: -0.0131, g_loss: 0.2717\n",
      "Epoch [253/300], Step [800/1875], d_loss: 0.0084, g_loss: -0.0953\n",
      "Epoch [253/300], Step [1000/1875], d_loss: -0.0468, g_loss: -0.1668\n",
      "Epoch [253/300], Step [1200/1875], d_loss: 0.0061, g_loss: 0.2144\n",
      "Epoch [253/300], Step [1400/1875], d_loss: -0.0093, g_loss: -0.1199\n",
      "Epoch [253/300], Step [1600/1875], d_loss: -0.0084, g_loss: -0.0073\n",
      "Epoch [253/300], Step [1800/1875], d_loss: -0.0606, g_loss: 0.0124\n",
      "Epoch [254/300], Step [200/1875], d_loss: 0.0292, g_loss: -0.0142\n",
      "Epoch [254/300], Step [400/1875], d_loss: -0.0076, g_loss: -0.1209\n",
      "Epoch [254/300], Step [600/1875], d_loss: -0.0142, g_loss: 0.1330\n",
      "Epoch [254/300], Step [800/1875], d_loss: -0.0038, g_loss: 0.0142\n",
      "Epoch [254/300], Step [1000/1875], d_loss: -0.0186, g_loss: -0.0487\n",
      "Epoch [254/300], Step [1200/1875], d_loss: -0.0265, g_loss: 0.0831\n",
      "Epoch [254/300], Step [1400/1875], d_loss: -0.0360, g_loss: -0.1193\n",
      "Epoch [254/300], Step [1600/1875], d_loss: -0.0107, g_loss: 0.1647\n",
      "Epoch [254/300], Step [1800/1875], d_loss: 0.0696, g_loss: -0.0860\n",
      "Epoch [255/300], Step [200/1875], d_loss: -0.0658, g_loss: 0.1698\n",
      "Epoch [255/300], Step [400/1875], d_loss: -0.0048, g_loss: 0.0642\n",
      "Epoch [255/300], Step [600/1875], d_loss: -0.0222, g_loss: -0.1548\n",
      "Epoch [255/300], Step [800/1875], d_loss: -0.0147, g_loss: 0.0379\n",
      "Epoch [255/300], Step [1000/1875], d_loss: -0.0227, g_loss: 0.0006\n",
      "Epoch [255/300], Step [1200/1875], d_loss: -0.0234, g_loss: -0.0800\n",
      "Epoch [255/300], Step [1400/1875], d_loss: -0.0709, g_loss: 0.0640\n",
      "Epoch [255/300], Step [1600/1875], d_loss: -0.0275, g_loss: -0.0479\n",
      "Epoch [255/300], Step [1800/1875], d_loss: 0.0424, g_loss: 0.1510\n",
      "Epoch [256/300], Step [200/1875], d_loss: -0.0323, g_loss: -0.0369\n",
      "Epoch [256/300], Step [400/1875], d_loss: -0.0227, g_loss: 0.1155\n",
      "Epoch [256/300], Step [600/1875], d_loss: -0.0415, g_loss: -0.1116\n",
      "Epoch [256/300], Step [800/1875], d_loss: -0.0320, g_loss: 0.0196\n",
      "Epoch [256/300], Step [1000/1875], d_loss: 0.0198, g_loss: 0.1002\n",
      "Epoch [256/300], Step [1200/1875], d_loss: -0.0136, g_loss: -0.0590\n",
      "Epoch [256/300], Step [1400/1875], d_loss: -0.0745, g_loss: 0.0872\n",
      "Epoch [256/300], Step [1600/1875], d_loss: 0.0059, g_loss: -0.0495\n",
      "Epoch [256/300], Step [1800/1875], d_loss: 0.0152, g_loss: 0.0841\n",
      "Epoch [257/300], Step [200/1875], d_loss: -0.0195, g_loss: 0.0057\n",
      "Epoch [257/300], Step [400/1875], d_loss: 0.0084, g_loss: -0.0241\n",
      "Epoch [257/300], Step [600/1875], d_loss: 0.0423, g_loss: 0.0818\n",
      "Epoch [257/300], Step [800/1875], d_loss: -0.0255, g_loss: -0.0124\n",
      "Epoch [257/300], Step [1000/1875], d_loss: 0.0213, g_loss: -0.0936\n",
      "Epoch [257/300], Step [1200/1875], d_loss: -0.0292, g_loss: 0.0123\n",
      "Epoch [257/300], Step [1400/1875], d_loss: -0.0776, g_loss: -0.0372\n",
      "Epoch [257/300], Step [1600/1875], d_loss: -0.0267, g_loss: 0.0910\n",
      "Epoch [257/300], Step [1800/1875], d_loss: -0.0605, g_loss: -0.0789\n",
      "Epoch [258/300], Step [200/1875], d_loss: -0.0262, g_loss: 0.0016\n",
      "Epoch [258/300], Step [400/1875], d_loss: -0.0513, g_loss: 0.1637\n",
      "Epoch [258/300], Step [600/1875], d_loss: 0.0257, g_loss: -0.2425\n",
      "Epoch [258/300], Step [800/1875], d_loss: -0.0006, g_loss: 0.1498\n",
      "Epoch [258/300], Step [1000/1875], d_loss: -0.0345, g_loss: -0.0731\n",
      "Epoch [258/300], Step [1200/1875], d_loss: -0.0969, g_loss: -0.0019\n",
      "Epoch [258/300], Step [1400/1875], d_loss: -0.0364, g_loss: 0.0684\n",
      "Epoch [258/300], Step [1600/1875], d_loss: -0.0320, g_loss: -0.1147\n",
      "Epoch [258/300], Step [1800/1875], d_loss: -0.0625, g_loss: 0.0106\n",
      "Epoch [259/300], Step [200/1875], d_loss: -0.0015, g_loss: 0.1490\n",
      "Epoch [259/300], Step [400/1875], d_loss: -0.0013, g_loss: -0.0492\n",
      "Epoch [259/300], Step [600/1875], d_loss: -0.0570, g_loss: 0.0741\n",
      "Epoch [259/300], Step [800/1875], d_loss: -0.0290, g_loss: -0.0297\n",
      "Epoch [259/300], Step [1000/1875], d_loss: -0.0050, g_loss: -0.0440\n",
      "Epoch [259/300], Step [1200/1875], d_loss: -0.0184, g_loss: -0.0679\n",
      "Epoch [259/300], Step [1400/1875], d_loss: -0.0036, g_loss: 0.1872\n",
      "Epoch [259/300], Step [1600/1875], d_loss: -0.0239, g_loss: -0.1906\n",
      "Epoch [259/300], Step [1800/1875], d_loss: -0.0234, g_loss: 0.0844\n",
      "Epoch [260/300], Step [200/1875], d_loss: -0.0294, g_loss: -0.0058\n",
      "Epoch [260/300], Step [400/1875], d_loss: -0.0502, g_loss: 0.0039\n",
      "Epoch [260/300], Step [600/1875], d_loss: -0.0058, g_loss: 0.0034\n",
      "Epoch [260/300], Step [800/1875], d_loss: -0.0198, g_loss: -0.1435\n",
      "Epoch [260/300], Step [1000/1875], d_loss: -0.0049, g_loss: 0.1056\n",
      "Epoch [260/300], Step [1200/1875], d_loss: -0.0252, g_loss: -0.0575\n",
      "Epoch [260/300], Step [1400/1875], d_loss: -0.0136, g_loss: -0.0266\n",
      "Epoch [260/300], Step [1600/1875], d_loss: -0.0297, g_loss: 0.2415\n",
      "Epoch [260/300], Step [1800/1875], d_loss: -0.0088, g_loss: -0.1191\n",
      "Epoch [261/300], Step [200/1875], d_loss: 0.0730, g_loss: -0.0130\n",
      "Epoch [261/300], Step [400/1875], d_loss: -0.0057, g_loss: 0.0708\n",
      "Epoch [261/300], Step [600/1875], d_loss: -0.0310, g_loss: -0.2874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/300], Step [800/1875], d_loss: 0.0107, g_loss: 0.2346\n",
      "Epoch [261/300], Step [1000/1875], d_loss: 0.0358, g_loss: -0.1461\n",
      "Epoch [261/300], Step [1200/1875], d_loss: -0.0480, g_loss: 0.1090\n",
      "Epoch [261/300], Step [1400/1875], d_loss: -0.0719, g_loss: 0.0257\n",
      "Epoch [261/300], Step [1600/1875], d_loss: -0.0431, g_loss: -0.0568\n",
      "Epoch [261/300], Step [1800/1875], d_loss: -0.0191, g_loss: 0.0120\n",
      "Epoch [262/300], Step [200/1875], d_loss: -0.0192, g_loss: -0.0701\n",
      "Epoch [262/300], Step [400/1875], d_loss: 0.0045, g_loss: 0.0478\n",
      "Epoch [262/300], Step [600/1875], d_loss: -0.0312, g_loss: -0.0160\n",
      "Epoch [262/300], Step [800/1875], d_loss: -0.0280, g_loss: 0.0114\n",
      "Epoch [262/300], Step [1000/1875], d_loss: -0.0020, g_loss: 0.0086\n",
      "Epoch [262/300], Step [1200/1875], d_loss: -0.0267, g_loss: -0.0184\n",
      "Epoch [262/300], Step [1400/1875], d_loss: -0.0510, g_loss: -0.0282\n",
      "Epoch [262/300], Step [1600/1875], d_loss: -0.0248, g_loss: 0.0370\n",
      "Epoch [262/300], Step [1800/1875], d_loss: -0.0177, g_loss: 0.1770\n",
      "Epoch [263/300], Step [200/1875], d_loss: -0.0479, g_loss: 0.0405\n",
      "Epoch [263/300], Step [400/1875], d_loss: 0.0252, g_loss: -0.0906\n",
      "Epoch [263/300], Step [600/1875], d_loss: 0.0032, g_loss: -0.0241\n",
      "Epoch [263/300], Step [800/1875], d_loss: -0.0388, g_loss: 0.0535\n",
      "Epoch [263/300], Step [1000/1875], d_loss: 0.0099, g_loss: -0.0068\n",
      "Epoch [263/300], Step [1200/1875], d_loss: -0.0664, g_loss: 0.0757\n",
      "Epoch [263/300], Step [1400/1875], d_loss: 0.0809, g_loss: -0.2567\n",
      "Epoch [263/300], Step [1600/1875], d_loss: 0.0049, g_loss: 0.1398\n",
      "Epoch [263/300], Step [1800/1875], d_loss: -0.0059, g_loss: -0.1101\n",
      "Epoch [264/300], Step [200/1875], d_loss: -0.0185, g_loss: 0.0389\n",
      "Epoch [264/300], Step [400/1875], d_loss: -0.0645, g_loss: -0.0296\n",
      "Epoch [264/300], Step [600/1875], d_loss: -0.0394, g_loss: 0.0951\n",
      "Epoch [264/300], Step [800/1875], d_loss: 0.0547, g_loss: -0.1026\n",
      "Epoch [264/300], Step [1000/1875], d_loss: -0.0123, g_loss: 0.1578\n",
      "Epoch [264/300], Step [1200/1875], d_loss: -0.0297, g_loss: -0.0539\n",
      "Epoch [264/300], Step [1400/1875], d_loss: -0.0475, g_loss: 0.0675\n",
      "Epoch [264/300], Step [1600/1875], d_loss: -0.0573, g_loss: -0.1448\n",
      "Epoch [264/300], Step [1800/1875], d_loss: -0.0056, g_loss: 0.0785\n",
      "Epoch [265/300], Step [200/1875], d_loss: -0.0480, g_loss: -0.1137\n",
      "Epoch [265/300], Step [400/1875], d_loss: -0.0295, g_loss: 0.0222\n",
      "Epoch [265/300], Step [600/1875], d_loss: -0.1202, g_loss: 0.0279\n",
      "Epoch [265/300], Step [800/1875], d_loss: 0.0141, g_loss: -0.0505\n",
      "Epoch [265/300], Step [1000/1875], d_loss: -0.0742, g_loss: 0.2766\n",
      "Epoch [265/300], Step [1200/1875], d_loss: 0.0131, g_loss: -0.2908\n",
      "Epoch [265/300], Step [1400/1875], d_loss: -0.0238, g_loss: 0.0350\n",
      "Epoch [265/300], Step [1600/1875], d_loss: -0.0369, g_loss: 0.0146\n",
      "Epoch [265/300], Step [1800/1875], d_loss: 0.0224, g_loss: 0.0352\n",
      "Epoch [266/300], Step [200/1875], d_loss: -0.0153, g_loss: 0.0661\n",
      "Epoch [266/300], Step [400/1875], d_loss: -0.0177, g_loss: -0.0107\n",
      "Epoch [266/300], Step [600/1875], d_loss: -0.0080, g_loss: -0.0764\n",
      "Epoch [266/300], Step [800/1875], d_loss: -0.0112, g_loss: 0.1092\n",
      "Epoch [266/300], Step [1000/1875], d_loss: -0.0404, g_loss: -0.1036\n",
      "Epoch [266/300], Step [1200/1875], d_loss: -0.0753, g_loss: 0.2945\n",
      "Epoch [266/300], Step [1400/1875], d_loss: -0.0425, g_loss: -0.2034\n",
      "Epoch [266/300], Step [1600/1875], d_loss: 0.0076, g_loss: 0.1206\n",
      "Epoch [266/300], Step [1800/1875], d_loss: 0.0099, g_loss: -0.1057\n",
      "Epoch [267/300], Step [200/1875], d_loss: -0.0494, g_loss: 0.0905\n",
      "Epoch [267/300], Step [400/1875], d_loss: 0.0075, g_loss: -0.1218\n",
      "Epoch [267/300], Step [600/1875], d_loss: -0.0178, g_loss: 0.0550\n",
      "Epoch [267/300], Step [800/1875], d_loss: -0.0431, g_loss: 0.0037\n",
      "Epoch [267/300], Step [1000/1875], d_loss: 0.0156, g_loss: -0.0762\n",
      "Epoch [267/300], Step [1200/1875], d_loss: -0.0237, g_loss: -0.0606\n",
      "Epoch [267/300], Step [1400/1875], d_loss: -0.0301, g_loss: 0.1709\n",
      "Epoch [267/300], Step [1600/1875], d_loss: -0.0205, g_loss: -0.1015\n",
      "Epoch [267/300], Step [1800/1875], d_loss: -0.0072, g_loss: 0.0388\n",
      "Epoch [268/300], Step [200/1875], d_loss: -0.0916, g_loss: 0.0498\n",
      "Epoch [268/300], Step [400/1875], d_loss: -0.0130, g_loss: -0.0598\n",
      "Epoch [268/300], Step [600/1875], d_loss: 0.0103, g_loss: 0.0221\n",
      "Epoch [268/300], Step [800/1875], d_loss: -0.0205, g_loss: -0.1451\n",
      "Epoch [268/300], Step [1000/1875], d_loss: 0.0101, g_loss: 0.0427\n",
      "Epoch [268/300], Step [1200/1875], d_loss: -0.0160, g_loss: -0.0685\n",
      "Epoch [268/300], Step [1400/1875], d_loss: -0.0496, g_loss: -0.0190\n",
      "Epoch [268/300], Step [1600/1875], d_loss: -0.0183, g_loss: 0.0782\n",
      "Epoch [268/300], Step [1800/1875], d_loss: -0.0129, g_loss: -0.0358\n",
      "Epoch [269/300], Step [200/1875], d_loss: -0.0221, g_loss: 0.0278\n",
      "Epoch [269/300], Step [400/1875], d_loss: -0.0029, g_loss: -0.1022\n",
      "Epoch [269/300], Step [600/1875], d_loss: -0.0897, g_loss: 0.2347\n",
      "Epoch [269/300], Step [800/1875], d_loss: -0.0146, g_loss: -0.1246\n",
      "Epoch [269/300], Step [1000/1875], d_loss: -0.0265, g_loss: -0.0200\n",
      "Epoch [269/300], Step [1200/1875], d_loss: 0.0003, g_loss: 0.1146\n",
      "Epoch [269/300], Step [1400/1875], d_loss: -0.0586, g_loss: -0.1248\n",
      "Epoch [269/300], Step [1600/1875], d_loss: -0.0639, g_loss: 0.1191\n",
      "Epoch [269/300], Step [1800/1875], d_loss: -0.0335, g_loss: -0.1488\n",
      "Epoch [270/300], Step [200/1875], d_loss: -0.0083, g_loss: -0.0154\n",
      "Epoch [270/300], Step [400/1875], d_loss: -0.0408, g_loss: 0.0691\n",
      "Epoch [270/300], Step [600/1875], d_loss: 0.0079, g_loss: -0.1148\n",
      "Epoch [270/300], Step [800/1875], d_loss: 0.0276, g_loss: 0.0816\n",
      "Epoch [270/300], Step [1000/1875], d_loss: -0.0105, g_loss: -0.1036\n",
      "Epoch [270/300], Step [1200/1875], d_loss: -0.0167, g_loss: 0.1013\n",
      "Epoch [270/300], Step [1400/1875], d_loss: 0.0097, g_loss: -0.0573\n",
      "Epoch [270/300], Step [1600/1875], d_loss: -0.0485, g_loss: -0.0196\n",
      "Epoch [270/300], Step [1800/1875], d_loss: -0.0349, g_loss: -0.0199\n",
      "Epoch [271/300], Step [200/1875], d_loss: -0.0254, g_loss: 0.0062\n",
      "Epoch [271/300], Step [400/1875], d_loss: -0.0253, g_loss: 0.0397\n",
      "Epoch [271/300], Step [600/1875], d_loss: 0.0269, g_loss: -0.0675\n",
      "Epoch [271/300], Step [800/1875], d_loss: 0.0363, g_loss: -0.0285\n",
      "Epoch [271/300], Step [1000/1875], d_loss: -0.0407, g_loss: -0.0002\n",
      "Epoch [271/300], Step [1200/1875], d_loss: -0.0190, g_loss: -0.0032\n",
      "Epoch [271/300], Step [1400/1875], d_loss: -0.0102, g_loss: -0.0946\n",
      "Epoch [271/300], Step [1600/1875], d_loss: -0.1140, g_loss: 0.3573\n",
      "Epoch [271/300], Step [1800/1875], d_loss: 0.0263, g_loss: -0.0974\n",
      "Epoch [272/300], Step [200/1875], d_loss: 0.0212, g_loss: -0.1784\n",
      "Epoch [272/300], Step [400/1875], d_loss: -0.0170, g_loss: 0.1381\n",
      "Epoch [272/300], Step [600/1875], d_loss: 0.0016, g_loss: -0.0890\n",
      "Epoch [272/300], Step [800/1875], d_loss: -0.0193, g_loss: 0.0850\n",
      "Epoch [272/300], Step [1000/1875], d_loss: -0.0171, g_loss: -0.0821\n",
      "Epoch [272/300], Step [1200/1875], d_loss: -0.0238, g_loss: 0.1442\n",
      "Epoch [272/300], Step [1400/1875], d_loss: -0.0819, g_loss: -0.0987\n",
      "Epoch [272/300], Step [1600/1875], d_loss: -0.0174, g_loss: 0.0545\n",
      "Epoch [272/300], Step [1800/1875], d_loss: -0.0037, g_loss: -0.1086\n",
      "Epoch [273/300], Step [200/1875], d_loss: -0.0097, g_loss: -0.0312\n",
      "Epoch [273/300], Step [400/1875], d_loss: -0.0353, g_loss: 0.1899\n",
      "Epoch [273/300], Step [600/1875], d_loss: -0.0353, g_loss: -0.0190\n",
      "Epoch [273/300], Step [800/1875], d_loss: -0.0425, g_loss: 0.0313\n",
      "Epoch [273/300], Step [1000/1875], d_loss: -0.0038, g_loss: -0.0251\n",
      "Epoch [273/300], Step [1200/1875], d_loss: -0.0012, g_loss: -0.0011\n",
      "Epoch [273/300], Step [1400/1875], d_loss: 0.0004, g_loss: 0.0226\n",
      "Epoch [273/300], Step [1600/1875], d_loss: -0.0731, g_loss: 0.0597\n",
      "Epoch [273/300], Step [1800/1875], d_loss: -0.0152, g_loss: -0.0807\n",
      "Epoch [274/300], Step [200/1875], d_loss: -0.1071, g_loss: -0.1410\n",
      "Epoch [274/300], Step [400/1875], d_loss: -0.0031, g_loss: 0.1187\n",
      "Epoch [274/300], Step [600/1875], d_loss: -0.0443, g_loss: 0.0752\n",
      "Epoch [274/300], Step [800/1875], d_loss: -0.0621, g_loss: -0.2149\n",
      "Epoch [274/300], Step [1000/1875], d_loss: 0.0075, g_loss: 0.3031\n",
      "Epoch [274/300], Step [1200/1875], d_loss: 0.1076, g_loss: -0.2657\n",
      "Epoch [274/300], Step [1400/1875], d_loss: -0.0231, g_loss: -0.0366\n",
      "Epoch [274/300], Step [1600/1875], d_loss: -0.0236, g_loss: 0.1602\n",
      "Epoch [274/300], Step [1800/1875], d_loss: -0.0328, g_loss: -0.0797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [275/300], Step [200/1875], d_loss: 0.0178, g_loss: 0.0497\n",
      "Epoch [275/300], Step [400/1875], d_loss: -0.0010, g_loss: 0.0838\n",
      "Epoch [275/300], Step [600/1875], d_loss: 0.0027, g_loss: -0.0174\n",
      "Epoch [275/300], Step [800/1875], d_loss: -0.0042, g_loss: 0.0244\n",
      "Epoch [275/300], Step [1000/1875], d_loss: -0.0211, g_loss: -0.0504\n",
      "Epoch [275/300], Step [1200/1875], d_loss: -0.0362, g_loss: -0.0057\n",
      "Epoch [275/300], Step [1400/1875], d_loss: 0.0696, g_loss: -0.0121\n",
      "Epoch [275/300], Step [1600/1875], d_loss: -0.0657, g_loss: 0.0495\n",
      "Epoch [275/300], Step [1800/1875], d_loss: 0.0341, g_loss: -0.0587\n",
      "Epoch [276/300], Step [200/1875], d_loss: -0.0419, g_loss: 0.0102\n",
      "Epoch [276/300], Step [400/1875], d_loss: -0.0362, g_loss: 0.0458\n",
      "Epoch [276/300], Step [600/1875], d_loss: -0.0669, g_loss: 0.0722\n",
      "Epoch [276/300], Step [800/1875], d_loss: -0.0033, g_loss: 0.0846\n",
      "Epoch [276/300], Step [1000/1875], d_loss: 0.0141, g_loss: 0.0001\n",
      "Epoch [276/300], Step [1200/1875], d_loss: 0.0027, g_loss: 0.0915\n",
      "Epoch [276/300], Step [1400/1875], d_loss: -0.0162, g_loss: -0.1430\n",
      "Epoch [276/300], Step [1600/1875], d_loss: -0.0348, g_loss: 0.1711\n",
      "Epoch [276/300], Step [1800/1875], d_loss: -0.0317, g_loss: 0.0536\n",
      "Epoch [277/300], Step [200/1875], d_loss: -0.0246, g_loss: 0.0862\n",
      "Epoch [277/300], Step [400/1875], d_loss: -0.0306, g_loss: -0.1032\n",
      "Epoch [277/300], Step [600/1875], d_loss: 0.0012, g_loss: 0.0353\n",
      "Epoch [277/300], Step [800/1875], d_loss: -0.0796, g_loss: -0.0109\n",
      "Epoch [277/300], Step [1000/1875], d_loss: -0.0595, g_loss: -0.0031\n",
      "Epoch [277/300], Step [1200/1875], d_loss: 0.0107, g_loss: -0.0022\n",
      "Epoch [277/300], Step [1400/1875], d_loss: 0.0100, g_loss: -0.0797\n",
      "Epoch [277/300], Step [1600/1875], d_loss: -0.0549, g_loss: 0.0103\n",
      "Epoch [277/300], Step [1800/1875], d_loss: -0.0307, g_loss: -0.0113\n",
      "Epoch [278/300], Step [200/1875], d_loss: -0.0093, g_loss: -0.0202\n",
      "Epoch [278/300], Step [400/1875], d_loss: -0.0306, g_loss: 0.0346\n",
      "Epoch [278/300], Step [600/1875], d_loss: 0.0132, g_loss: -0.1037\n",
      "Epoch [278/300], Step [800/1875], d_loss: -0.0397, g_loss: 0.0493\n",
      "Epoch [278/300], Step [1000/1875], d_loss: -0.0548, g_loss: -0.0260\n",
      "Epoch [278/300], Step [1200/1875], d_loss: 0.0406, g_loss: 0.0110\n",
      "Epoch [278/300], Step [1400/1875], d_loss: -0.0443, g_loss: 0.1084\n",
      "Epoch [278/300], Step [1600/1875], d_loss: -0.0331, g_loss: -0.1088\n",
      "Epoch [278/300], Step [1800/1875], d_loss: -0.0235, g_loss: 0.1499\n",
      "Epoch [279/300], Step [200/1875], d_loss: -0.0180, g_loss: 0.1581\n",
      "Epoch [279/300], Step [400/1875], d_loss: 0.0030, g_loss: -0.2582\n",
      "Epoch [279/300], Step [600/1875], d_loss: -0.0075, g_loss: 0.1148\n",
      "Epoch [279/300], Step [800/1875], d_loss: 0.0072, g_loss: -0.0372\n",
      "Epoch [279/300], Step [1000/1875], d_loss: -0.0357, g_loss: -0.0100\n",
      "Epoch [279/300], Step [1200/1875], d_loss: -0.0413, g_loss: 0.0954\n",
      "Epoch [279/300], Step [1400/1875], d_loss: -0.0470, g_loss: -0.0474\n",
      "Epoch [279/300], Step [1600/1875], d_loss: -0.0486, g_loss: -0.0457\n",
      "Epoch [279/300], Step [1800/1875], d_loss: -0.0095, g_loss: 0.0309\n",
      "Epoch [280/300], Step [200/1875], d_loss: -0.0072, g_loss: 0.0091\n",
      "Epoch [280/300], Step [400/1875], d_loss: -0.0154, g_loss: -0.0923\n",
      "Epoch [280/300], Step [600/1875], d_loss: -0.0732, g_loss: -0.0962\n",
      "Epoch [280/300], Step [800/1875], d_loss: -0.0039, g_loss: 0.1282\n",
      "Epoch [280/300], Step [1000/1875], d_loss: -0.0226, g_loss: -0.0748\n",
      "Epoch [280/300], Step [1200/1875], d_loss: -0.0179, g_loss: 0.0118\n",
      "Epoch [280/300], Step [1400/1875], d_loss: -0.0876, g_loss: 0.0628\n",
      "Epoch [280/300], Step [1600/1875], d_loss: -0.0199, g_loss: -0.0115\n",
      "Epoch [280/300], Step [1800/1875], d_loss: 0.0420, g_loss: -0.1774\n",
      "Epoch [281/300], Step [200/1875], d_loss: 0.0345, g_loss: 0.0353\n",
      "Epoch [281/300], Step [400/1875], d_loss: -0.0153, g_loss: 0.1157\n",
      "Epoch [281/300], Step [600/1875], d_loss: -0.0205, g_loss: -0.0776\n",
      "Epoch [281/300], Step [800/1875], d_loss: 0.0889, g_loss: 0.0873\n",
      "Epoch [281/300], Step [1000/1875], d_loss: 0.0118, g_loss: -0.1492\n",
      "Epoch [281/300], Step [1200/1875], d_loss: -0.0395, g_loss: 0.0791\n",
      "Epoch [281/300], Step [1400/1875], d_loss: -0.0324, g_loss: -0.0549\n",
      "Epoch [281/300], Step [1600/1875], d_loss: 0.0298, g_loss: -0.0440\n",
      "Epoch [281/300], Step [1800/1875], d_loss: -0.0209, g_loss: -0.0528\n",
      "Epoch [282/300], Step [200/1875], d_loss: 0.0028, g_loss: -0.0619\n",
      "Epoch [282/300], Step [400/1875], d_loss: 0.0249, g_loss: -0.0660\n",
      "Epoch [282/300], Step [600/1875], d_loss: -0.0085, g_loss: -0.1073\n",
      "Epoch [282/300], Step [800/1875], d_loss: -0.0404, g_loss: 0.2286\n",
      "Epoch [282/300], Step [1000/1875], d_loss: -0.0476, g_loss: -0.1436\n",
      "Epoch [282/300], Step [1200/1875], d_loss: -0.0071, g_loss: 0.1267\n",
      "Epoch [282/300], Step [1400/1875], d_loss: -0.0454, g_loss: -0.0861\n",
      "Epoch [282/300], Step [1600/1875], d_loss: -0.0205, g_loss: 0.0816\n",
      "Epoch [282/300], Step [1800/1875], d_loss: 0.0001, g_loss: -0.1007\n",
      "Epoch [283/300], Step [200/1875], d_loss: -0.0148, g_loss: 0.1332\n",
      "Epoch [283/300], Step [400/1875], d_loss: 0.0696, g_loss: -0.1966\n",
      "Epoch [283/300], Step [600/1875], d_loss: -0.0362, g_loss: 0.0472\n",
      "Epoch [283/300], Step [800/1875], d_loss: 0.0833, g_loss: -0.0828\n",
      "Epoch [283/300], Step [1000/1875], d_loss: -0.0590, g_loss: 0.0002\n",
      "Epoch [283/300], Step [1200/1875], d_loss: 0.0309, g_loss: 0.1509\n",
      "Epoch [283/300], Step [1400/1875], d_loss: -0.0287, g_loss: -0.0652\n",
      "Epoch [283/300], Step [1600/1875], d_loss: -0.0357, g_loss: 0.0559\n",
      "Epoch [283/300], Step [1800/1875], d_loss: -0.0630, g_loss: -0.0570\n",
      "Epoch [284/300], Step [200/1875], d_loss: -0.0622, g_loss: 0.0608\n",
      "Epoch [284/300], Step [400/1875], d_loss: -0.1401, g_loss: -0.1426\n",
      "Epoch [284/300], Step [600/1875], d_loss: -0.0506, g_loss: 0.0568\n",
      "Epoch [284/300], Step [800/1875], d_loss: -0.0007, g_loss: 0.1355\n",
      "Epoch [284/300], Step [1000/1875], d_loss: -0.0033, g_loss: -0.1191\n",
      "Epoch [284/300], Step [1200/1875], d_loss: 0.0315, g_loss: 0.0104\n",
      "Epoch [284/300], Step [1400/1875], d_loss: -0.0201, g_loss: 0.0419\n",
      "Epoch [284/300], Step [1600/1875], d_loss: -0.0065, g_loss: -0.0544\n",
      "Epoch [284/300], Step [1800/1875], d_loss: -0.0257, g_loss: 0.0668\n",
      "Epoch [285/300], Step [200/1875], d_loss: 0.0221, g_loss: -0.0329\n",
      "Epoch [285/300], Step [400/1875], d_loss: -0.0477, g_loss: 0.0367\n",
      "Epoch [285/300], Step [600/1875], d_loss: -0.0313, g_loss: 0.0094\n",
      "Epoch [285/300], Step [800/1875], d_loss: 0.0556, g_loss: -0.1056\n",
      "Epoch [285/300], Step [1000/1875], d_loss: -0.0076, g_loss: 0.0030\n",
      "Epoch [285/300], Step [1200/1875], d_loss: -0.0259, g_loss: 0.1605\n",
      "Epoch [285/300], Step [1400/1875], d_loss: -0.0207, g_loss: -0.1996\n",
      "Epoch [285/300], Step [1600/1875], d_loss: -0.0045, g_loss: 0.0069\n",
      "Epoch [285/300], Step [1800/1875], d_loss: -0.1320, g_loss: 0.3508\n",
      "Epoch [286/300], Step [200/1875], d_loss: -0.0309, g_loss: 0.3282\n",
      "Epoch [286/300], Step [400/1875], d_loss: -0.0713, g_loss: -0.4589\n",
      "Epoch [286/300], Step [600/1875], d_loss: -0.0109, g_loss: 0.0388\n",
      "Epoch [286/300], Step [800/1875], d_loss: -0.1013, g_loss: 0.2399\n",
      "Epoch [286/300], Step [1000/1875], d_loss: 0.0224, g_loss: -0.2500\n",
      "Epoch [286/300], Step [1200/1875], d_loss: 0.0485, g_loss: 0.1705\n",
      "Epoch [286/300], Step [1400/1875], d_loss: -0.0638, g_loss: 0.0533\n",
      "Epoch [286/300], Step [1600/1875], d_loss: -0.0665, g_loss: 0.0374\n",
      "Epoch [286/300], Step [1800/1875], d_loss: -0.0775, g_loss: -0.0853\n",
      "Epoch [287/300], Step [200/1875], d_loss: 0.0123, g_loss: 0.0586\n",
      "Epoch [287/300], Step [400/1875], d_loss: -0.0370, g_loss: -0.0563\n",
      "Epoch [287/300], Step [600/1875], d_loss: 0.0003, g_loss: -0.0310\n",
      "Epoch [287/300], Step [800/1875], d_loss: -0.0127, g_loss: 0.0244\n",
      "Epoch [287/300], Step [1000/1875], d_loss: -0.0043, g_loss: -0.0821\n",
      "Epoch [287/300], Step [1200/1875], d_loss: -0.0238, g_loss: -0.0106\n",
      "Epoch [287/300], Step [1400/1875], d_loss: -0.0192, g_loss: 0.0237\n",
      "Epoch [287/300], Step [1600/1875], d_loss: -0.0175, g_loss: 0.0002\n",
      "Epoch [287/300], Step [1800/1875], d_loss: 0.0156, g_loss: -0.0049\n",
      "Epoch [288/300], Step [200/1875], d_loss: -0.0230, g_loss: -0.0554\n",
      "Epoch [288/300], Step [400/1875], d_loss: -0.0194, g_loss: 0.0973\n",
      "Epoch [288/300], Step [600/1875], d_loss: -0.0002, g_loss: -0.1936\n",
      "Epoch [288/300], Step [800/1875], d_loss: -0.0343, g_loss: 0.0877\n",
      "Epoch [288/300], Step [1000/1875], d_loss: -0.0034, g_loss: -0.0093\n",
      "Epoch [288/300], Step [1200/1875], d_loss: 0.0051, g_loss: 0.0816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [288/300], Step [1400/1875], d_loss: -0.0547, g_loss: 0.0109\n",
      "Epoch [288/300], Step [1600/1875], d_loss: -0.0034, g_loss: -0.0043\n",
      "Epoch [288/300], Step [1800/1875], d_loss: -0.0302, g_loss: 0.0625\n",
      "Epoch [289/300], Step [200/1875], d_loss: -0.0139, g_loss: 0.0954\n",
      "Epoch [289/300], Step [400/1875], d_loss: 0.0010, g_loss: -0.1298\n",
      "Epoch [289/300], Step [600/1875], d_loss: 0.0156, g_loss: -0.0459\n",
      "Epoch [289/300], Step [800/1875], d_loss: -0.0035, g_loss: 0.1671\n",
      "Epoch [289/300], Step [1000/1875], d_loss: -0.1012, g_loss: -0.2031\n",
      "Epoch [289/300], Step [1200/1875], d_loss: -0.0718, g_loss: 0.2584\n",
      "Epoch [289/300], Step [1400/1875], d_loss: -0.0055, g_loss: -0.1499\n",
      "Epoch [289/300], Step [1600/1875], d_loss: 0.0364, g_loss: 0.1119\n",
      "Epoch [289/300], Step [1800/1875], d_loss: -0.0051, g_loss: -0.1001\n",
      "Epoch [290/300], Step [200/1875], d_loss: 0.0028, g_loss: 0.0776\n",
      "Epoch [290/300], Step [400/1875], d_loss: 0.0028, g_loss: -0.0987\n",
      "Epoch [290/300], Step [600/1875], d_loss: -0.0513, g_loss: 0.0668\n",
      "Epoch [290/300], Step [800/1875], d_loss: -0.0426, g_loss: -0.1435\n",
      "Epoch [290/300], Step [1000/1875], d_loss: 0.0097, g_loss: 0.1111\n",
      "Epoch [290/300], Step [1200/1875], d_loss: -0.1369, g_loss: 0.1850\n",
      "Epoch [290/300], Step [1400/1875], d_loss: 0.0833, g_loss: -0.4401\n",
      "Epoch [290/300], Step [1600/1875], d_loss: -0.0195, g_loss: 0.1099\n",
      "Epoch [290/300], Step [1800/1875], d_loss: -0.0338, g_loss: 0.0236\n",
      "Epoch [291/300], Step [200/1875], d_loss: 0.0079, g_loss: 0.0845\n",
      "Epoch [291/300], Step [400/1875], d_loss: -0.0039, g_loss: -0.0403\n",
      "Epoch [291/300], Step [600/1875], d_loss: 0.0082, g_loss: 0.0972\n",
      "Epoch [291/300], Step [800/1875], d_loss: -0.0960, g_loss: -0.1461\n",
      "Epoch [291/300], Step [1000/1875], d_loss: -0.0081, g_loss: 0.2464\n",
      "Epoch [291/300], Step [1200/1875], d_loss: -0.0332, g_loss: -0.0586\n",
      "Epoch [291/300], Step [1400/1875], d_loss: -0.0055, g_loss: -0.0664\n",
      "Epoch [291/300], Step [1600/1875], d_loss: 0.0069, g_loss: -0.0149\n",
      "Epoch [291/300], Step [1800/1875], d_loss: -0.0380, g_loss: 0.0086\n",
      "Epoch [292/300], Step [200/1875], d_loss: 0.0440, g_loss: 0.0720\n",
      "Epoch [292/300], Step [400/1875], d_loss: -0.0419, g_loss: 0.0140\n",
      "Epoch [292/300], Step [600/1875], d_loss: -0.0232, g_loss: -0.1099\n",
      "Epoch [292/300], Step [800/1875], d_loss: 0.0277, g_loss: 0.0827\n",
      "Epoch [292/300], Step [1000/1875], d_loss: -0.0205, g_loss: -0.1362\n",
      "Epoch [292/300], Step [1200/1875], d_loss: -0.0278, g_loss: 0.1490\n",
      "Epoch [292/300], Step [1400/1875], d_loss: 0.0163, g_loss: -0.1119\n",
      "Epoch [292/300], Step [1600/1875], d_loss: -0.0199, g_loss: 0.0331\n",
      "Epoch [292/300], Step [1800/1875], d_loss: -0.0998, g_loss: 0.1637\n",
      "Epoch [293/300], Step [200/1875], d_loss: -0.0496, g_loss: 0.1801\n",
      "Epoch [293/300], Step [400/1875], d_loss: 0.0589, g_loss: -0.2947\n",
      "Epoch [293/300], Step [600/1875], d_loss: -0.0177, g_loss: 0.1422\n",
      "Epoch [293/300], Step [800/1875], d_loss: -0.0317, g_loss: -0.0530\n",
      "Epoch [293/300], Step [1000/1875], d_loss: -0.0909, g_loss: 0.0613\n",
      "Epoch [293/300], Step [1200/1875], d_loss: -0.0488, g_loss: 0.0610\n",
      "Epoch [293/300], Step [1400/1875], d_loss: 0.0087, g_loss: -0.0030\n",
      "Epoch [293/300], Step [1600/1875], d_loss: 0.0108, g_loss: -0.0569\n",
      "Epoch [293/300], Step [1800/1875], d_loss: 0.0391, g_loss: 0.0719\n",
      "Epoch [294/300], Step [200/1875], d_loss: -0.0390, g_loss: 0.1571\n",
      "Epoch [294/300], Step [400/1875], d_loss: -0.0256, g_loss: -0.1974\n",
      "Epoch [294/300], Step [600/1875], d_loss: -0.0453, g_loss: 0.1664\n",
      "Epoch [294/300], Step [800/1875], d_loss: -0.0379, g_loss: -0.0583\n",
      "Epoch [294/300], Step [1000/1875], d_loss: -0.0405, g_loss: 0.0223\n",
      "Epoch [294/300], Step [1200/1875], d_loss: -0.0549, g_loss: -0.1134\n",
      "Epoch [294/300], Step [1400/1875], d_loss: -0.0148, g_loss: 0.1373\n",
      "Epoch [294/300], Step [1600/1875], d_loss: -0.0528, g_loss: -0.1825\n",
      "Epoch [294/300], Step [1800/1875], d_loss: -0.0439, g_loss: 0.1583\n",
      "Epoch [295/300], Step [200/1875], d_loss: 0.0145, g_loss: -0.0976\n",
      "Epoch [295/300], Step [400/1875], d_loss: -0.0602, g_loss: 0.0458\n",
      "Epoch [295/300], Step [600/1875], d_loss: -0.0523, g_loss: -0.0202\n",
      "Epoch [295/300], Step [800/1875], d_loss: -0.0398, g_loss: 0.0208\n",
      "Epoch [295/300], Step [1000/1875], d_loss: -0.0252, g_loss: -0.0314\n",
      "Epoch [295/300], Step [1200/1875], d_loss: -0.0412, g_loss: 0.0069\n",
      "Epoch [295/300], Step [1400/1875], d_loss: -0.0015, g_loss: -0.0089\n",
      "Epoch [295/300], Step [1600/1875], d_loss: -0.0106, g_loss: -0.0664\n",
      "Epoch [295/300], Step [1800/1875], d_loss: -0.0387, g_loss: 0.0343\n",
      "Epoch [296/300], Step [200/1875], d_loss: -0.0422, g_loss: -0.0435\n",
      "Epoch [296/300], Step [400/1875], d_loss: -0.0419, g_loss: 0.0177\n",
      "Epoch [296/300], Step [600/1875], d_loss: -0.0265, g_loss: 0.0498\n",
      "Epoch [296/300], Step [800/1875], d_loss: -0.0134, g_loss: 0.0009\n",
      "Epoch [296/300], Step [1000/1875], d_loss: -0.0716, g_loss: -0.1184\n",
      "Epoch [296/300], Step [1200/1875], d_loss: -0.0212, g_loss: -0.0387\n",
      "Epoch [296/300], Step [1400/1875], d_loss: -0.0620, g_loss: 0.1515\n",
      "Epoch [296/300], Step [1600/1875], d_loss: 0.0041, g_loss: -0.1262\n",
      "Epoch [296/300], Step [1800/1875], d_loss: -0.0371, g_loss: -0.1487\n",
      "Epoch [297/300], Step [200/1875], d_loss: 0.0050, g_loss: -0.1489\n",
      "Epoch [297/300], Step [400/1875], d_loss: -0.0515, g_loss: 0.2918\n",
      "Epoch [297/300], Step [600/1875], d_loss: -0.0550, g_loss: -0.2090\n",
      "Epoch [297/300], Step [800/1875], d_loss: 0.0661, g_loss: 0.2396\n",
      "Epoch [297/300], Step [1000/1875], d_loss: 0.0151, g_loss: -0.0176\n",
      "Epoch [297/300], Step [1200/1875], d_loss: -0.0374, g_loss: -0.1458\n",
      "Epoch [297/300], Step [1400/1875], d_loss: -0.0575, g_loss: 0.2487\n",
      "Epoch [297/300], Step [1600/1875], d_loss: -0.0795, g_loss: -0.1320\n",
      "Epoch [297/300], Step [1800/1875], d_loss: -0.0322, g_loss: 0.2448\n",
      "Epoch [298/300], Step [200/1875], d_loss: -0.0204, g_loss: -0.0407\n",
      "Epoch [298/300], Step [400/1875], d_loss: -0.0231, g_loss: 0.0125\n",
      "Epoch [298/300], Step [600/1875], d_loss: -0.0793, g_loss: 0.2069\n",
      "Epoch [298/300], Step [800/1875], d_loss: -0.0244, g_loss: -0.3102\n",
      "Epoch [298/300], Step [1000/1875], d_loss: 0.1068, g_loss: 0.4756\n",
      "Epoch [298/300], Step [1200/1875], d_loss: -0.0854, g_loss: -0.3197\n",
      "Epoch [298/300], Step [1400/1875], d_loss: -0.0125, g_loss: 0.0372\n",
      "Epoch [298/300], Step [1600/1875], d_loss: -0.1055, g_loss: 0.1892\n",
      "Epoch [298/300], Step [1800/1875], d_loss: 0.0110, g_loss: -0.1776\n",
      "Epoch [299/300], Step [200/1875], d_loss: 0.0432, g_loss: 0.1971\n",
      "Epoch [299/300], Step [400/1875], d_loss: 0.1390, g_loss: -0.5942\n",
      "Epoch [299/300], Step [600/1875], d_loss: -0.0429, g_loss: 0.2287\n",
      "Epoch [299/300], Step [800/1875], d_loss: -0.0116, g_loss: -0.0645\n",
      "Epoch [299/300], Step [1000/1875], d_loss: -0.0086, g_loss: -0.0417\n",
      "Epoch [299/300], Step [1200/1875], d_loss: 0.0086, g_loss: 0.0305\n",
      "Epoch [299/300], Step [1400/1875], d_loss: -0.0147, g_loss: -0.0983\n",
      "Epoch [299/300], Step [1600/1875], d_loss: -0.0542, g_loss: 0.1658\n",
      "Epoch [299/300], Step [1800/1875], d_loss: -0.0196, g_loss: 0.0139\n"
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        \n",
    "        # 1. Flatten image\n",
    "        images = images.view(batch_size, -1).to(device)\n",
    "        images = Variable(images, requires_grad = True)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 1: TRAIN THE CRITIC\n",
    "        \"\"\"\n",
    "\n",
    "        # 2. Compute mean of critic decisions using real images\n",
    "        outputs_real = f(images)\n",
    "        \n",
    "        # 2.bis. Compute mean of critic decisions using fake images\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs_fake = f(fake_images)\n",
    "        \n",
    "        # 3. Compute gradient regularization\n",
    "        real_grad_out = Variable(Tensor(images.size(0), 1).fill_(1.0), requires_grad = False).to(device)\n",
    "        real_grad = autograd.grad(outputs_real, images, real_grad_out, create_graph = True, \\\n",
    "                                  retain_graph = True, only_inputs = True)[0]\n",
    "        real_grad_norm = real_grad.view(real_grad.size(0), -1).pow(2).sum(1)**3\n",
    "        fake_grad_out = Variable(Tensor(fake_images.size(0), 1).fill_(1.0), requires_grad = False).to(device)\n",
    "        fake_grad = autograd.grad(outputs_fake, fake_images, fake_grad_out, create_graph = True, \\\n",
    "                                  retain_graph = True, only_inputs = True)[0]\n",
    "        fake_grad_norm = fake_grad.view(fake_grad.size(0), -1).pow(2).sum(1)**3\n",
    "        reg_term = torch.mean(real_grad_norm + fake_grad_norm)\n",
    "        \n",
    "        # 4. Backprop and optimize for f\n",
    "        # Loss is simply the difference between means, plus regularization term\n",
    "        # Remember to reset gradients for both optimizers!\n",
    "        d_loss = -torch.mean(outputs_real) + torch.mean(outputs_fake) + reg_term\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # 4.bis. Optional, weight clipping on critic\n",
    "        # (Mentioned in WGAN paper)\n",
    "        for p in f.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 2: TRAIN THE GENERATOR\n",
    "        \"\"\"\n",
    "\n",
    "        # 5. Generate fresh noise samples and produce fake images\n",
    "        z = torch.randn(batch_size, latent_size).cuda()\n",
    "        z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = f(fake_images)\n",
    "        \n",
    "        # 6. Loss for G\n",
    "        g_loss = - torch.mean(outputs)\n",
    "        \n",
    "        # 7. Backprop and optimize G\n",
    "        # Remember to reset gradients for both optimizers!\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        PART 3: UPDATE STATISTICS FOR VISUALIZATION LATER\n",
    "        \"\"\"\n",
    "        \n",
    "        # 8. Update the losses and scores for mini-batches\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) \\\n",
    "            + d_loss.item()*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) \\\n",
    "            + g_loss.item()*(1./(i+1.))\n",
    "        \n",
    "        # 9. Display\n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e17b8",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2436479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display losses for both the generator and discriminator\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), d_losses, label = 'd loss')\n",
    "plt.plot(range(1, num_epochs + 1), g_losses, label = 'g loss')    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac98d1",
   "metadata": {},
   "source": [
    "The Wassestein GANs, while easier to train and capable of better samples, need more cautious control on the training and will usually strongly benefit from additional layers in both the critic and generator.\n",
    "\n",
    "More control on the initialization and the interleaved training is also needed.\n",
    "\n",
    "These advanced practices will be discussed in an upcoming homework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0162145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVcklEQVR4nO3dXYxc5XkH8P8zH/vh3fV6F4JtbBcIpRRKVKdaua2CKqooEeGikBsUpEZUQnUugkSkXBTRi3CJqiYRF1Ukp6A4VUqEmiC4QG0IikS5iVioMQaHGIgRNv426/WuvfP59GKHaAN7/s9yznwl7/8nrXZ33jnnvHPmPHNm5jnv85q7Q0T+8JUG3QER6Q8Fu0giFOwiiVCwiyRCwS6SiEo/N1YdnfDRidn8K+hl5sCsd+sOux3cIepbkf3Sy8ddVPS4iuyXXj/uAT0nteXzaNSW111BoWA3s9sBPAqgDODf3f0Rdv/RiVl85gsPZK8v2D+lRu+CvTXCdzDrmwfPTanF263NH1e7wjdQarLO8W23q8UO+uixM0Wf79Yof2Narrezlx0J3tQWPLGU6/mXL/KcHPz5o5ltud/Gm1kZwL8B+BKAmwHcY2Y3512fiPRWkc/sewC85e7vuHsdwI8B3NmdbolItxUJ9h0A3lvz/7HObb/DzPaa2byZzTdqSwU2JyJF9PzbeHff5+5z7j5XHZ3s9eZEJEORYD8OYNea/3d2bhORIVQk2F8CcIOZXWdmIwC+AuCZ7nRLRLotd+rN3Ztmdj+A/8Fq6u1xd389WAhllk7p5QC8IJsRpYHa5ewVhKmzMl93OTtDBCBOb7VIqiZ6XJEo7Vdd5p138tjZPgXi1FqY9iOPvVzj/S6akoyOtyJoSpKkDAvl2d39WQDPFlmHiPSHLpcVSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBF9Hc8OM5oTpjl4oFAePhwmGmybtXupt2OjS03e7uQlu9QKhokGQz3Ltd4Nv42GbZeawQUIAbbt5hh/3HTYMNDTa0J6NZRbZ3aRRCjYRRKhYBdJhIJdJBEKdpFEKNhFEtHf1FsgSgOxoaRRuqJIFVSAV5+trBRLlViQHmuO5x9mGg5RrQWlb4PTQTQUlO03i4b2BinNKD3GHnvlUjDENag2HFUjjtKlbRJ5YWXanMeyzuwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJELBLpKI/ubZ3WkOsTXKE4gsVx7lPaPxlCzvCfCZWJtjQb+DfHFlpdhQzvpU9mt2tF+am3h7YzL/cwIAI4vZz/coaVtdll8DUA6uEWClqhub+RMeXfsQ5cI9KJPNrs1g5bdX7xC0Z9CZXSQRCnaRRCjYRRKhYBdJhIJdJBEKdpFEKNhFEjFU49nZdLMAz21GuWwvBXnR4GWPLR2Ny47GozcmeGI1ymU3Nmff4fJW/rjtumXa/pmr36ftzWA+6lff2ZnZtuWlUbpslGevXKzT9nY1u2+tcd7vlS28fWSJP+lRnp7VAQin+M5ZarpQsJvZUQAXAbQANN19rsj6RKR3unFm/1t3P9uF9YhID+kzu0giiga7A/iZmb1sZnvXu4OZ7TWzeTObb9b450MR6Z2ib+NvdffjZnYVgOfM7Ffu/sLaO7j7PgD7AGByZmcPZ8gSEabQmd3dj3d+nwbwFIA93eiUiHRf7mA3swkzm/rwbwBfBHCoWx0Tke4q8jZ+K4CnbHWceAXAf7r7f9MlzGh+0aI3+STfbEGO3oLy6N4OxruTftemoxrjfNssTw4ArSpfvj6TnfMdv36RLvv3f/wSbf+7qVdp+1hwkcFj03+d2fbkiVvpspMng+mkJ/mOjcaUM1FN+mjMeXTdB6tpH9aNzyl3sLv7OwD+vIt9EZEeUupNJBEKdpFEKNhFEqFgF0mEgl0kEX0vJc1SGq1g+l+WroiGgUZpvWjK5+ZY9utiNDw2KpEdpQURpN6YmU2XafutE2/S9ptGNuXfOIDZSvYl0mE6NMqcBe3tav4S29Hx0hjnT3pUHpy1F0nbsZLpOrOLJELBLpIIBbtIIhTsIolQsIskQsEukggFu0gihquUdDCtMivPW2oXG+LaDPKmbNvlWrEpmcN8czCccoHk8c8t8Tz5mdZm2t5yPkR2sb1C2x97M3uI69RRuiim3r5I2+0yLyVd2zmd2ebloHx3cBosFSgVDfDy49G26RBYMtRbZ3aRRCjYRRKhYBdJhIJdJBEKdpFEKNhFEqFgF0lEf/PsZnQsbjSmvE16W61FUzLzvGdUOrjUJG11nkevLpGFAVQ/4GPOV7ZN0Pblq7NLKi8tjNNlf77wZ7T92soLtP2/LvwlbW8fzM51T/+mRpe1d47x9qlJ2g5kbzsqzx0dLxZc1xFO6Uyao2s+WBxoPLuIKNhFUqFgF0mEgl0kEQp2kUQo2EUSoWAXSUTfx7PTWuDBuG1Wy7uxKajjfTkoBB40l0kuvboY5NHPLvGVN/jy9c18zHmDpeGDx3X4wlba/r+b/oS2v3j6eto+dia7bfQkH6/evnSJtpd2bqPtjansAyoabx7tt+qloH4CT7PTuvXlGl84qnmfJTyzm9njZnbazA6tuW3WzJ4zsyOd3zO5ti4ifbORt/E/AHD7R257EMDz7n4DgOc7/4vIEAuD3d1fAHD+IzffCWB/5+/9AO7qbrdEpNvyfkG31d1PdP4+CSDzg5+Z7TWzeTObb9SCz64i0jOFv413dwf5OsPd97n7nLvPVUejgQsi0it5g/2UmW0HgM7v093rkoj0Qt5gfwbAvZ2/7wXwdHe6IyK9EubZzewJALcBuNLMjgH4FoBHADxpZvcBeBfA3RvamjuteR3lJlluNJpP24NHaqTe9uoKsptKNZ4nj+rhN3Zsoe2L1/ALEBpT2TvOqnynloIdd7bJP3qdW+Z16ScXyPbrDbps6YpZ2r6yk19/UJ/I/yk1qm/QHM9fFx7gdefDsfTBoZolDHZ3vyej6fP5Nikig6DLZUUSoWAXSYSCXSQRCnaRRCjYRRLR91LSbHhelFJg6YyotG+Y1iMlrgGgVM+eV9nL/DWzOc3LOV/cOUrb6zNBie3J7L5FgyGbbd73M/Up2n5pifd9M8lKtmZ5Ws+v4qm1y1fyw5cda5WVoHR4NI12cJqMhtCWSNYxmqKbpgU1ZbOIKNhFEqFgF0mEgl0kEQp2kUQo2EUSoWAXSUTfS0kz0ZTNTFReN8zhR3nVSvbrYnssGII6wXdzbZq/5rbGgosEyvn3m9Pa3rFyhfdtaXv2Y2uN8KmoI82x/LlsNtQa4ENQAaAV5dGD46kIek2IpmwWEQW7SCIU7CKJULCLJELBLpIIBbtIIhTsIonoe56d5bvDqWhZDjEo/RuNd2+X+bZbJKfbGuW7MZpOus2HhIfjm9HO7pvX+cK1Fm+frS7T9lt2vE/b/++m6zLbLi/wbVcX+XMyskCbUV3OvgagcolfH+DB8YDoWA1Kk7PS5RZUJndWmpyVPOerFZE/FAp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRLR3zy7e1DzOlxBZkvRuvBRXrVF2tvBXgzHPvOZi1FZDvrWJPnqYLy67+DtN43zPHrUXillPzFHzn2KLnvh2DRtLwXXENg5smyDHzDt6DwY5NFbo3y/lmvZbeEcCDRQCtSNN7PHzey0mR1ac9vDZnbczA50fu6I1iMig7WRt/E/AHD7Ord/1913d36e7W63RKTbwmB39xcAnO9DX0Skh4p8QXe/mR3svM2fybqTme01s3kzm2/W+HXWItI7eYP9ewCuB7AbwAkA3866o7vvc/c5d5+rjBYrMCgi+eUKdnc/5e4td28D+D6APd3tloh0W65gN7Pta/79MoBDWfcVkeEQ5tnN7AkAtwG40syOAfgWgNvMbDdWk3pHAXxtw1vMX+KcTjZetG58ON822VNRDj9SWeadGz8ZPDYynt2C+uf1G3mueltlgbZfUbpE28/MZM/vfqHG562/MME/9nmZ9z2q/c5ExwurrQDE130UOZbLOedXCIPd3e9Z5+bHcm1NRAZGl8uKJELBLpIIBbtIIhTsIolQsIskor9DXM3ictFscTY6NlhtVCo6Wt5L+cr3AnGZ60qNt286y9tHFrLHyF78I16nulXi676xeoG2X2jz9NeJ+pbMtvOXN9Flvc7PReU6bUZ5hdVV5k940XRquRbk3sjqy1HaLmdGUWd2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJxFBN2VwKhu61RrNfm8r1oDRwkJtsBqV/WXnfSpDvrS63aPvIB3wFlXO8nJfVs/Pstmt7ZhsA7JjiefQtJX6IvB9M+Xx4cVtm27nzk3TZkTN822PB9Qfllez9HpYOD46HaEg0vS4DfMrmqPQ4XzGZ1jz/WkXk94mCXSQRCnaRRCjYRRKhYBdJhIJdJBEKdpFE9D3PzsaNt4P8YuVSdi6d5S0BYGULzweXgzHlJZIqry4Vy6NXj56i7e2lYNqsrVdmNjUm+D7dM3OUtleN77f3GlfQ9l+fyp6WuXKMj7Wf+g1txsQpPtc1K+fcGuPnuXCK7yAVHh2PLA9fYePwATTH8uXhdWYXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEKdpFE9DfP7o5ynYzjjWrKk+ZmkDeNcpcRVvs9qhFeWeDTGjdPnOQbj6YHvvGazLbaDF/2lvH3aPuKN2n70+d20/ba2expma94my6KqeN82+XL/PqGxubsw7sdHGvOLy/A6Ad82+H6yeEajaWnUzaT/H54ZjezXWb2CzN7w8xeN7MHOrfPmtlzZnak83smWpeIDM5G3sY3AXzT3W8G8FcAvm5mNwN4EMDz7n4DgOc7/4vIkAqD3d1PuPsrnb8vAjgMYAeAOwHs79xtP4C7etRHEemCT/QFnZldC+CzAH4JYKu7n+g0nQSwNWOZvWY2b2bzzVpwjbeI9MyGg93MJgH8BMA33H1xbZu7OzKmm3P3fe4+5+5zldGJQp0Vkfw2FOxmVsVqoP/I3X/aufmUmW3vtG8HcLo3XRSRbghTb2ZmAB4DcNjdv7Om6RkA9wJ4pPP76XBr0ZTNQYrJy/nTZyzlB8TDBlmqJJzeN6hjbdUR2l6anqLty9uypz5u8lmRsaOyQNvfbfLHdnaFl4MeJeWgq2TIMhCXa65PV2l7izyn0RDVKFXbGuedi8qisyHVUeqNlpomMbSRPPvnAHwVwGtmdqBz20NYDfInzew+AO8CuHsD6xKRAQmD3d1fRPblLJ/vbndEpFd0uaxIIhTsIolQsIskQsEukggFu0gi+j/EleYfg9zmSPZrE5tSeSPtpSCfzHLpzQk+HnJl1zRtr878KW2/PM3z8IvXZD+NtU+v0GV/VedTOp9p8hz/sQv8sbFrI+pTwT6vBodncNkFu7aiEgxLLlxKmq+erj/K0Ucl1zPXm2spEfm9o2AXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBH9zbOboV0mY4yDlx5WsplNgbsRrFQ0ADTJGGPWBgDtWT7u+tK2oP0qvmOWd2Xvl6uvWqDLvrKUXYYaAN69NEvbL37AB8yPkesXorH2Ub65EkyzbazicnC8sOMUAEqtIMkfNZPVxyXVlWcXEULBLpIIBbtIIhTsIolQsIskQsEukggFu0gi+ptnB8+l87HuPP9Y4rP78lrbG9g2my86qvPdDF5SW3y4OtpBe6mRvf333/4UXfapI7y9ssQ7P3meP/aRC2RM+WW6aFiDIKztTp7zKIdvQR49Gq8eTflM1x2m8PPNn6Azu0giFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJGIj87PvAvBDAFuxOkp3n7s/amYPA/hHAGc6d33I3Z8N10dShFGtbrZslJMtN2hzuG2W0x1Z4knX+iR/TbVW/m0DwPjp7DY3vu1o3dH1B6VmMMc6m0o8yFVHufAiojy4BddtRMsXOZajmvSsHj6cXNfAVwsAaAL4pru/YmZTAF42s+c6bd9193/dwDpEZMA2Mj/7CQAnOn9fNLPDAHb0umMi0l2f6DO7mV0L4LMAftm56X4zO2hmj5vZTMYye81s3szmG7WlYr0Vkdw2HOxmNgngJwC+4e6LAL4H4HoAu7F65v/2esu5+z53n3P3ueroZPEei0guGwp2M6tiNdB/5O4/BQB3P+XuLXdvA/g+gD2966aIFBUGu5kZgMcAHHb376y5fe30n18GcKj73RORbtnIt/GfA/BVAK+Z2YHObQ8BuMfMdmM1HXcUwNfCNbmHJZt7puBm2dDcKA0TPeZSK0eH1m6fpbeCxx2lt0YWeQ4qnNqYTXU9xs817aikcoFyzaxfAOC8uneYsgzThmzzwaK01DQpM72Rb+NfxPpdC3PqIjI8dAWdSCIU7CKJULCLJELBLpIIBbtIIhTsIonoaylpc8BITjnKV7PSwGH53WjYYJQXLTA0lw5JRFyKushQz3AoJxkSCQCtKBcelOhmz3c4xDW4PiGa2phdGxEdL0Wfs+ix0SHZ0YzNOQ8HndlFEqFgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQR5kGetasbMzsD4N01N10J4GzfOvDJDGvfhrVfgPqWVzf7do27rzsPd1+D/WMbN5t397mBdYAY1r4Na78A9S2vfvVNb+NFEqFgF0nEoIN934C3zwxr34a1X4D6lldf+jbQz+wi0j+DPrOLSJ8o2EUSMZBgN7PbzexNM3vLzB4cRB+ymNlRM3vNzA6Y2fyA+/K4mZ02s0Nrbps1s+fM7Ejn97pz7A2obw+b2fHOvjtgZncMqG+7zOwXZvaGmb1uZg90bh/oviP96st+6/tndjMrA/g1gC8AOAbgJQD3uPsbfe1IBjM7CmDO3Qd+AYaZ/Q2AJQA/dPdbOrf9C4Dz7v5I54Vyxt3/aUj69jCApUFP492ZrWj72mnGAdwF4B8wwH1H+nU3+rDfBnFm3wPgLXd/x93rAH4M4M4B9GPoufsLAM5/5OY7Aezv/L0fqwdL32X0bSi4+wl3f6Xz90UAH04zPtB9R/rVF4MI9h0A3lvz/zEM13zvDuBnZvayme0ddGfWsdXdT3T+Pglg6yA7s45wGu9++sg040Oz7/JMf16UvqD7uFvd/S8AfAnA1ztvV4eSr34GG6bc6Yam8e6XdaYZ/61B7ru8058XNYhgPw5g15r/d3ZuGwrufrzz+zSApzB8U1Gf+nAG3c7v0wPuz28N0zTe600zjiHYd4Oc/nwQwf4SgBvM7DozGwHwFQDPDKAfH2NmE50vTmBmEwC+iOGbivoZAPd2/r4XwNMD7MvvGJZpvLOmGceA993Apz93977/ALgDq9/Ivw3gnwfRh4x+fRrAq52f1wfdNwBPYPVtXQOr323cB+AKAM8DOALg5wBmh6hv/wHgNQAHsRpY2wfUt1ux+hb9IIADnZ87Br3vSL/6st90uaxIIvQFnUgiFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJOL/AYcxKzyLk3UnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a fake sample for visualization\n",
    "n_samples = 5\n",
    "z = torch.randn(n_samples, latent_size).cuda()\n",
    "z = Variable(z)\n",
    "fake_images = G(z)\n",
    "fake_images = fake_images.cpu().detach().numpy().reshape(n_samples, 28, 28)\n",
    "print(fake_images.shape)\n",
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[0])\n",
    "plt.show()\n",
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[1])\n",
    "plt.show()\n",
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[2])\n",
    "plt.show()\n",
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[3])\n",
    "plt.show()\n",
    "# Display\n",
    "plt.figure()\n",
    "plt.imshow(fake_images[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03abfd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
